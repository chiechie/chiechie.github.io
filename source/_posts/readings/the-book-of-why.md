---
title: the book of why
author: chiechie
mathjax: true
date: 2021-03-06 08:33:38
tags:
- 因果推断
- 人工智能
- 哲学
- 科普
categories: 阅读清单
---
> 《the book of why》（中文版《为什么》）是一本关于因果关系的科普书，作者是因果推断领域专家-judea pearl，该书于2019年出版。
>
> 最近工作正好涉及根因分析，加上我对因果推断领域比较感兴趣，所以将本书作为入门读物。打算以此为基础，再看专门的技术paper。

# 引言-思维胜于数据

## 因果推断引擎

1. "知识"指的是reasoning agent过去的经历，包括过去的观察（observation），过去的行为（actions），教育和文化（hearsay）等跟目标问题有关的内容。知识的虚线框表示，它仍存在于agent的心智中，是隐式的，而不是显示地在表达在模型中。
2. 科学研究经常需要简化假设（assumptions），即值得显式表达的statements。
   虽然大部分研究人员的知识都隐式地存在于他脑中，只有assumptions得见天日，并且被encapsulated 在模型之中。assumptions可以从模型中读到，这让一些罗辑学家得到一些结论：模型不过是一堆assumptions而已。计算机学习对此观点持有异议，需要主义assumptions呈现的方式，因为不同人的解读能力而区别很大。
3. 因果模型有多种表达语言：因果图，结构方程，逻辑论断（statements）等。以因果图为例，如果X是Y的cause，也说Y听从X，如果我们suspect一个病人的寿命 听从于 他有没有服药，就会在因果图种，画一个D到L的箭头。
4. 因果图中的听从模式，会导致数据中的观测模式和依赖性。这些模式叫testable implications，因为他们可以用于测试这个模型。论断（statements），eg"D和L不连接"，翻译成统计statement，"D和L是独立的"，即出现D并不会改变L出现的概率。
如果数据违背了这个implication，我们就许哟啊修正我们的模型了。这些修正需要其他引擎，输入4和7，并且计算fitness度，即，数据和模型assumptions的相容性。为了简化，我们在图1中没有展示第二个引擎。
5，提交到推荐引擎的queries，是一个科学的问题我们要回答的，他们可以用一个因果词汇来表达，例如，P（L | do(D)）是多少，eg我努力了的话成功的概率是多少？因果革命的一个主要的成就是，使得这个因果语言和数学语言一样科学，透明。
6. "estimand"表示待估计量。这是一个统计量，需要从数据中酸楚，一旦估计出来了，就可以代表对query的回答了。虽然他可以被写成概率公式，例如P（L｜ D，Z）*P（Z），他也可以被认为是一个配方，来回答因果query，从我们有的数据类型，假设他可以回答。
   意识到这点很重要，跟统计学中的传统的参数估计相反，一些查询并不是可以回答的，，在当前的因果模型中，即使收集了足够多的数据。例如，如果我们的模型显示，药物德和寿命都依赖于第三个变量--z，疾病的阶段，如果我们没有任何方式去估计Z，，那么这个查询--P（L｜ do（D））就不知道，这这种情况下，收集数据就是浪费时间。
   相安，我们应该回去修正我们的模型，要么增加信的知识--允许我们估计Z，要么简化assumptions（有出错的风险），例如，假设Z对D的影响忽略不计。
   
7. 数据是"estimand"的原料，需要意识到，数据对因果关系是非常愚蠢的。 他们告诉我们关于P（L｜D），或者P（L｜D，Z）。这个是estimand的共奏。告诉我们怎么去bake这些统计量进去一个表达式--基于模型的assumption，是逻辑上等价于这个因果查询，P(L|do(D)).
 注意，"estimand"并不存在于统计分析的传统方法中。estimand和query是一致的。。
   举个例子，如果我们想寿命L的人中服用了D的比例，我们可以将query写作P（D｜L），相同的quantity就是我们的estimand， 这个已经确定了数据中那一部分需要被估计，并且不需要因果关系。
所以，一些统计学家直到现在仍然觉得很难理解，为什么一些知识（knowledge）存在于统计证明之外，并且只靠数据，并不能弥补科学知识的缺失。
8. 这个estimate就是出炉的东西，然而，仅仅是一个估计值，
因为有一个事实：他们仅仅只是一个理论上无限总体的有限样本。
   在我们的例子中，这个样本包括了我们想要研究的病人。 即使我们是随机挑的，他们仍然总是又啃呢个，样本中观察到的比例不能代表整体中的比例。幸运的事。统计学的定理给了我们很多方法来管理这个不确定性--MLE，propensity分数，置信区间，统计检验。
   
9. 最后，如果我们的模型是对的，我们的数据是充足的，我们可以得到因果query的答案，例如 药物提升了糖尿病人的寿命30%+/-20%，
这一回答，也会增加我们的科学的知识（BOX1）。如果事情真相不是我们推断的那样，这个流程图建议我们提升因果模型（BOX 3）
   
这个流程图看起来很复杂，我们在日常生活和工作中处理因果问题时使用直觉就可以，而不用按照这个流程来。
但是如果我们要教会一个机器人懂得因果推断，我们就必须审视自己的因果推断的流程，并且形成一门科学的语言，先模拟自己，然后再教会机器。


   

   

![因果推断引擎](inference_engine.png)

## 深度学习 和 因果推断

1. 人工智能和大数据和因果模型：当今很多人工智能的研究者只依赖数据解决所有的认知难题。他们希望在因果问题出现时，数据能指引他们找到答案。换句话说，他们坚信数据是万能的，也可以称这类人--信仰「数据教」。这种想法通常是秘而不宣。
   
2. 作者对"数据万能"的趋势表示质疑，因为，对因果关系的知识，数据没有发言权。举个例子，关于「行动」或「干预结果」的信息，根本无法从原始数据中获取，这些信息只能从对照实验中收集。

3.反事实问题比如"如果当时我采取了相反的行动会发生什么"，是人工智能最具挑战性的问题。想要回答反事实问题，因果模型的作用很重要。

4.因果模型相对深度学习的特有优势--适应性。
因果模型研究的是更本质，更稳固，适用范围更广的知识，相对来说深度学习是一个肤浅的学习者，和拙劣的模仿者。
    - 假设我们面临一个一个问题，新冠疫苗的药效的评估者，通过观察硬度的情况--病患注射疫苗后的存活时间，得到了关于疫苗有效性的结论；接下来想评估疫苗在中国的有效性，但是中国和印度的卫生情况，饮食习惯，工作习惯，人均寿命寿命都不一样。
    - 「深度学习流派」的做法是：重新获取中国的病患数据，重新训练模型和做预测，本质上深度学习就是将函数和数据拟合。
    -「因果推断流派」的做法是：该研究者首先掌握疫苗的作用机制（regime），如果中国疫苗作用机制跟印度一致，那么在印度得到的估计参数仍然有效，可生成一个新的中国总体的预测函数。



## 参考
1.[在线试读-引言])(http://bayes.cs.ucla.edu/WHY/why-intro.pdf)