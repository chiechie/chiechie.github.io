<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Chiechie&#39;s Mini World</title>
  
  <subtitle>Set your course by the stars, not by the lights of passing ships. —— Omar Bradley</subtitle>
  <link href="https://chiechie.github.io/atom.xml" rel="self"/>
  
  <link href="https://chiechie.github.io/"/>
  <updated>2021-06-03T00:58:35.711Z</updated>
  <id>https://chiechie.github.io/</id>
  
  <author>
    <name>Chiechie</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>汇率机制</title>
    <link href="https://chiechie.github.io/2021/06/03/economics/huilv/"/>
    <id>https://chiechie.github.io/2021/06/03/economics/huilv/</id>
    <published>2021-06-03T00:28:28.000Z</published>
    <updated>2021-06-03T00:58:35.711Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>中国可以无限印钞购买美国的东西吗？</p></blockquote><p>蒙代尔三角：本国货币政策的独立性（印钞权），汇率的稳定性，资本自由流动，3选2，必须放弃一个。</p><p>蒙代尔三角短期可以三种都实行，但是最终会提供套利机会，导致三者里面必须放弃一个。 例如92-98年的泰国，三者都要导致外汇掏空，固定汇率无法维持，引起亚洲金融危机。</p><table><thead><tr class="header"><th></th><th>货币主权</th><th>汇率的稳定性</th><th>资本自由流动</th></tr></thead><tbody><tr class="odd"><td>英国/希腊等欧盟国家</td><td>No</td><td>Yes</td><td>Yes</td></tr><tr class="even"><td>中国香港</td><td>No</td><td>Yes</td><td>Yes</td></tr><tr class="odd"><td>中国大陆</td><td>Yes</td><td>有限</td><td>有限</td></tr><tr class="even"><td>美国</td><td>有限</td><td>有限</td><td>Yes</td></tr></tbody></table><h2 id="香港政府怎么发币的">香港政府怎么发币的？</h2><p>法律规定，香港的发钞银行在发行钞票时，需要找7.8:1的汇率向金管局提交等值美元，并计入外汇基金账目，作为所发钞票的支持。</p><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.zhihu.com/question/21611592/answer/18777171">一种货币和美元挂钩是怎样实现的？-知乎</a></li><li><a href="https://www.zhihu.com/question/67928805/answer/257923560">中国为什么不直接印大量的人民币去买美国的东西?知乎</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;中国可以无限印钞购买美国的东西吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;蒙代尔三角：本国货币政策的独立性（印钞权），汇率的稳定性，资本自由流动，3选2，必须放弃一个。&lt;/p&gt;
&lt;p&gt;蒙代尔三角短期可以三种都实行，但是最终会提供套利机会，导致三</summary>
      
    
    
    
    <category term="经济学" scheme="https://chiechie.github.io/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6/"/>
    
    
    <category term="经济学" scheme="https://chiechie.github.io/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6/"/>
    
    <category term="货币" scheme="https://chiechie.github.io/tags/%E8%B4%A7%E5%B8%81/"/>
    
    <category term="汇率" scheme="https://chiechie.github.io/tags/%E6%B1%87%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>强化学习5 蒙特卡洛树搜索</title>
    <link href="https://chiechie.github.io/2021/06/02/AI/reinforcement_learning/rl5-monte-calo/"/>
    <id>https://chiechie.github.io/2021/06/02/AI/reinforcement_learning/rl5-monte-calo/</id>
    <published>2021-06-02T08:58:05.000Z</published>
    <updated>2021-06-03T08:48:27.853Z</updated>
    
    <content type="html"><![CDATA[<h1 id="总结">总结</h1><ol type="1"><li>蒙特卡洛树搜索（MCTS）是一种基于模型的强化学习方法。</li><li>蒙特卡洛树搜索比价值学习和策略学习更难。</li><li>AlphaGp是一个围棋AI，依靠MCTS做决策，决策过程中需要策略网络和价值网络辅助。</li><li>AlphaGo真正跟人下棋的时候，做决策的不是策略网络或者价值网络，而是MCTS。</li><li>MCTS不需要训练，可以直接做决策，训练策略网络和价值网络的目的是辅助MCTS。</li></ol><h2 id="mcts的基本思想">MCTS的基本思想</h2><ol type="1"><li>高手是怎么下棋的？高手一般都会往前多看几步。</li><li>高手下棋，一般是动态看待局势，确保自己几步之后占据优势。如果只根据当前格局做判断，不考虑长远，肯定赢不了高手。</li><li>同理，AI下棋也应该跟高手一样，多往前看几步，枚举所有可能发生的情况，从而判断当前执行什么动作的胜算最大，这样远浩宇用策略网络输出一个动作。</li><li>AlphaGo每走一步，就要用MCTS做成千上万次模拟，基本思想如下：假设当前有3种可选的动作，每次模拟从三种动作中选出一种，然后将游戏进行到底，从而拿到最终结果。 重复成千上万次模拟，统计每种动作的胜负概率，发现胜率分别是48%、56%、52%。那么 AlphaGo 应当执行第二种动作，因为 它的胜算最大。然而实际做起来还有很多难点需要解决。</li></ol><h2 id="mcts的四个步骤">MCTS的四个步骤</h2><p>MCTS每次模拟都要经历四个步骤：选择（selection），扩展（expansion），估值（evaluation），回溯（backup）</p><h3 id="选择">选择</h3><ol type="1"><li><p>观察当前局势，找出符合规则的所有走位中最有胜算的那部分走位。 如何评估走位优劣？综合两方面：</p></li><li><p>看走位的胜率，就是动作价值</p></li><li><p>看策略网络给a的评分</p></li></ol><h3 id="扩展">扩展</h3><p>接下来，ALphaGo需要考虑：对方会怎么走？只能靠猜，使用"推己及人"的方式。使用策略网络模拟对手的策略， 策略网络站在对手角度，根据观测到的棋局，给出多个走位的概率，ALphaGo采样一个动作。 这个时候对手落下的子就是ALphaGo的新状态了。</p><p>上面的所有的走位都不是真实发生的，而是在AlphaGo的脑袋中推演的，</p><p>ALphaGo专门执行推演的模块就叫模拟器（就是环境，牛逼的很，自己构建出与现实平行的虚拟世界），</p><p>在模拟器中，ALphaGo每执行一个动作，模拟器就会返回一个新的状态。</p><p>如何搭建一个好的模拟器？关键在于构建的正确的状态转移函数，如果其跟事实偏离太远，那么模拟器就是一个废物。</p><p>AlphaGo如何构建好的模拟器呢？他利用了围棋的对称性：即我方视角的状态转移，等价于对方视角的真实策略--可以复用已经训练好的策略网络。</p><blockquote><p>有点类似理性市场假设，每个人都是同样聪明的人，市场不存在套利机会。</p></blockquote><p>在围棋场景，搭建模拟器很简单，但是其他场景就没有这么简单了。</p><p>比如机器人、无人车等应用，状态转移的构造需要物理模型，要考虑到力、运动、以及外部世界的干扰。 如果物理模型不够准确，导致状态转移函数偏离事实太远，那么 MCTS的模拟结果就不可靠。</p><h3 id="求值">求值</h3><p>AlphaGo在模拟器中交替落子，直到分出胜负，把结果记为r.但是r只是众多平行世界中的一个，把r就作为评判第一个走位的依据，未免过于随机。</p><p>有没有更加稳定的方法？AlphaGo的解决方案，把r与价值网络对下个状态的评价进行求和，得到了下一个状态的价值。</p><p>在实际实现的时候，AlphaGo在这一步训练了一个更小的策略网络。</p><p>为什么只在求值这一步使用小网络呢？因为这一步是连哥哥策略网络交替落子，并且通常要走一两百步，导致这步成为瓶颈。</p><p>用小的策略网络代替大的策略网络，可以大幅加速MCTS</p><h3 id="回溯">回溯</h3><p>对于下一步的每个状态，通过模拟都能得到多条记录--代表该状态的价值。</p><p>把假想走位的所有状态的所有价值记录，求平均，就能得到假想走位的价值。</p><p>将这个候选走位带回第一步，更新每个走位的分数，选出最高的，进行下一轮模拟</p><p><span class="math display">\[ \operatorname{score}(a) \triangleq Q(a)+\frac{\eta}{1+N(a)} \cdot \pi(a \mid s ; \boldsymbol{\theta}), \quad \forall a \]</span></p><h2 id="决策">决策</h2><p>一轮 选择-&gt;扩展-&gt;扩展-&gt;回溯只是执行了单次模拟。</p><p>实际上做一次决策之前，需要做成千上万次模拟。</p><p>每次模拟时，更新每个候选走位的score，选择最高分score，在模拟器执行。</p><p>经过成千上万次模拟后，最经常被选中的走位，就作为最终的决策依据。</p><p>注意，每次在真实世界走完一步，上一步存的分数都要清零。</p><p>总结下，AlphaGo下棋非常暴力：每走一步，都要在虚拟世界模拟几万局。</p><p>计算量是机器战胜柯洁的秘密武器。</p><h1 id="参考">参考</h1><ol type="1"><li><a href="https://netman.aiops.org/wp-content/uploads/2018/12/sunyq_IEEEAccess2018_HotSpot.pdf">HotSpot-英文paper</a></li><li><a href="https://mp.weixin.qq.com/s/Kj309bzifIv4j80nZbGVZw">HotSpot-中文</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;总结&quot;&gt;总结&lt;/h1&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;蒙特卡洛树搜索（MCTS）是一种基于模型的强化学习方法。&lt;/li&gt;
&lt;li&gt;蒙特卡洛树搜索比价值学习和策略学习更难。&lt;/li&gt;
&lt;li&gt;AlphaGp是一个围棋AI，依靠MCTS做决策，决策过程中需要策略</summary>
      
    
    
    
    <category term="AI" scheme="https://chiechie.github.io/categories/AI/"/>
    
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="强化学习" scheme="https://chiechie.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>强化学习4 使用gym构建股票交易机器人</title>
    <link href="https://chiechie.github.io/2021/05/31/AI/reinforcement_learning/rl4-tradingrobot/"/>
    <id>https://chiechie.github.io/2021/05/31/AI/reinforcement_learning/rl4-tradingrobot/</id>
    <published>2021-05-31T07:01:49.000Z</published>
    <updated>2021-06-03T08:58:37.779Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>现在进行强化学习第2个实践项目--构建交易机器人，</p></blockquote><h2 id="思路">思路</h2><p>老路子，先构建environment 再构建agent：</p><ul><li>environment需要定义state，action类型，以及step和render方法。</li><li>agent需要定义策略函数，即每个state下最优action</li></ul><p>下面从0到构建一个,</p><p>为了构建environment，先简化问题:</p><ul><li>state: 过去3天close/open/high/low/volume5个指标的数据, shape = &lt;3, 5&gt;</li><li>action: 买/卖/持仓 + 数量(基于目前仓位的百分比), shape = &lt;2, &gt; ,</li><li>step方法返回<ul><li>state2: 第二天的close/open/high/low/volume5个指标的数据, shape = &lt;3, 5&gt;</li><li>reward：变动仓位 * 变化的股价</li></ul></li></ul><p>为了构建agent:</p><ul><li>随机策略</li><li>Q-table不行，因为state不连续了</li><li>naive策略：趋势策略，短期有上升趋势就买入，否则卖出。</li></ul><h2 id="实施">实施</h2><h3 id="step-1-自定义一个environment">step 1 自定义一个environment</h3><p>自定义一个environment，需要继承gym的标准环境类--gym.Env, 并实现类的关键方法，有step和reset</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomEnv</span>(<span class="params">gym.Env</span>):</span></span><br><span class="line">    metadata = &#123;<span class="string">&#x27;render.modes&#x27;</span>: [<span class="string">&#x27;human&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, arg1, arg2, ...</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CustomEnv, self).__init__()</span><br><span class="line">        self.action_space = <span class="literal">None</span></span><br><span class="line">        self.observation_space = <span class="literal">None</span></span><br><span class="line">                                       </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span>(<span class="params">self, action</span>):</span>                                               </span><br><span class="line">        <span class="keyword">return</span> observation, reward, done, info</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> observation  <span class="comment"># reward, done, info can&#x27;t be included</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">render</span>(<span class="params">self, mode=<span class="string">&#x27;human&#x27;</span></span>):</span></span><br><span class="line">                                       </span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span> (<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="step1-1-定义环境类的构造函数">step1-1: 定义环境类的构造函数</h4><p>在构造函数中，定义state空间，和 action空间 state是连续的，action因为涉及到具体买卖多少份额，所以也有部分是连续的， 可以用gyn.space.Box来定义，需要指定上下界。 此外，为了简化问题，直接把一个df当作成员给这个子类</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StockEnv</span>(<span class="params">gym.Env</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, df</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(StockEnv, self).__init__()</span><br><span class="line">        self.action_space = spaces.Box(low=-<span class="number">1</span>, high=<span class="number">1</span>,shape=(<span class="number">1</span>, ), dtype=np.float16)</span><br><span class="line">        self.observation_space = spaces.Box(low=<span class="number">0</span>, high=<span class="number">1</span>, shape=(<span class="number">3</span>, <span class="number">5</span>), dtype=np.float16)</span><br><span class="line">        self.df = df</span><br></pre></td></tr></table></figure><h4 id="step1-2-定义环境类的reset方法">step1-2: 定义环境类的reset方法</h4><p>定义环境类的reset方法，reset用来重置一局游戏。需要返回游戏的初始状态，收益为0， 计算收益的几个变量，账户净值，持股数量，余额，以及游戏开始的时间戳（这个可以随机设置的）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reset</span>(<span class="params">self</span>):</span></span><br><span class="line">    self.net_worth = <span class="number">10000</span></span><br><span class="line">    self.share_hold = <span class="number">0</span></span><br><span class="line">    self.current_step = <span class="number">2</span></span><br><span class="line">    self.cash = <span class="number">10000</span></span><br><span class="line">    observation = self.df.loc[self.current_step - WINDOW_SIZE + <span class="number">1</span>: self.current_step,  [<span class="string">&quot;open&quot;</span>, <span class="string">&quot;close&quot;</span>, <span class="string">&quot;high&quot;</span>, <span class="string">&quot;low&quot;</span>, <span class="string">&quot;volume&quot;</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> observation  <span class="comment"># reward, done, info can&#x27;t be included</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="step1-3-定义环境类的step方法">step1-3: 定义环境类的step方法</h4><p>定义step方法，step是标准环境类的标准方法，输入输出的格式是固定的，输入一个state，输出下一个state, reward, done, info。</p><p>这里涉及到交易的常识，补充下几个概念：</p><ul><li>net value：账户净值，也就是说账户当前现金+股票折现价值</li><li>cash：这里叫现金是为了方便理解。专业的叫法是balance。</li><li>action amount：一个百分比，基于当前账户余额（balance）可以买卖的比例。</li><li>done：什么时候一轮游戏结束？时间到了或者爆仓了，即net value &lt; 0了</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">step</span>(<span class="params">self, action</span>):</span></span><br><span class="line">    current_price = self.df.loc[self.current_step, <span class="string">&quot;close&quot;</span>]</span><br><span class="line">    <span class="comment"># action_type, action_percent = action</span></span><br><span class="line">    <span class="comment"># action = action[0]</span></span><br><span class="line">    action_amount = <span class="built_in">abs</span>(action)</span><br><span class="line">    buy = action &gt; <span class="number">0</span></span><br><span class="line">    sell = action &lt; <span class="number">0</span></span><br><span class="line">    <span class="comment"># 0表示买     </span></span><br><span class="line">    action_amount = self.cash * action_amount / current_price</span><br><span class="line">    reward = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> sell <span class="keyword">and</span> self.share_hold &lt; action_amount:</span><br><span class="line">        <span class="comment"># 不允许做空</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">elif</span> buy:</span><br><span class="line">        self.share_hold += action_amount</span><br><span class="line">        self.cash -= action_amount * current_price</span><br><span class="line">        reward = (self.df.loc[self.current_step + <span class="number">1</span>, <span class="string">&quot;close&quot;</span>] - current_price) * action_amount</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self.share_hold -= action_amount</span><br><span class="line">        self.cash += action_amount *  current_price</span><br><span class="line">        reward = - (self.df.loc[self.current_step + <span class="number">1</span>, <span class="string">&quot;close&quot;</span>] - current_price) * action_amount</span><br><span class="line"></span><br><span class="line">    self.current_step += <span class="number">1</span></span><br><span class="line">    observation = self._next_observation()</span><br><span class="line">    next_price = self.df.loc[self.current_step, <span class="string">&quot;close&quot;</span>]</span><br><span class="line">                                   </span><br><span class="line">    self.net_worth = self.cash + self.share_hold * next_price</span><br><span class="line">    done = self.net_worth &lt;= <span class="number">0.01</span></span><br><span class="line">                                         </span><br><span class="line">                                           </span><br><span class="line">    <span class="keyword">return</span> observation, reward, done, &#123;&#125;</span><br></pre></td></tr></table></figure><h3 id="step-2--定义策略policy">step 2- 定义策略policy</h3><h4 id="step-2-1-定义一个静态策略">step 2-1 定义一个静态策略</h4><p>这里先用一个简单的趋势策略作为baseline，如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def pi(obs):</span><br><span class="line">    close_list &#x3D; obs[&quot;close&quot;].values</span><br><span class="line">    ma &#x3D; close_list[:-1].mean()</span><br><span class="line">    price &#x3D;  close_list[-1]</span><br><span class="line"></span><br><span class="line">    if price &#x2F; ma &gt; 1.02:</span><br><span class="line">        action &#x3D; 0.2</span><br><span class="line">    elif price &#x2F; ma &lt; 0.98:</span><br><span class="line">        action &#x3D; -0.2</span><br><span class="line">    else:</span><br><span class="line">        action &#x3D; 0</span><br><span class="line">    return action</span><br><span class="line">    </span><br></pre></td></tr></table></figure><h4 id="step-2-2-使用ppo算法构建策略">step 2-2 使用PPO算法构建策略</h4><p>PPO（Proximal Policy Optimization）算法结合了A2C和TRPO的idea，主要思路是， 每次更新策略时，新的策略不能离旧的策略太远，具体的做法是对梯度做截断（clipping）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">env_PPO = DummyVecEnv([<span class="keyword">lambda</span>: StockEnv(df)])</span><br><span class="line">model = PPO2(MlpPolicy, env_PPO, verbose=<span class="number">0</span>)</span><br><span class="line">model.learn(total_timesteps=<span class="number">100</span>)</span><br></pre></td></tr></table></figure><h4 id="step2-3-对比">step2-3 对比</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">&#x27;./stockdata/train/sh.600004.白云机场.csv&#x27;</span>)</span><br><span class="line">df = df.sort_values(<span class="string">&#x27;date&#x27;</span>)</span><br><span class="line">df[<span class="string">&quot;volume&quot;</span>] = df[<span class="string">&quot;volume&quot;</span>].<span class="built_in">map</span>(np.log)</span><br><span class="line"></span><br><span class="line">env_PPO = DummyVecEnv([<span class="keyword">lambda</span>: StockEnv(df)])</span><br><span class="line">env_basis = StockEnv(df)</span><br><span class="line">env_PPO1 = StockEnv(df)</span><br><span class="line"></span><br><span class="line">model = PPO2(MlpPolicy, env_PPO, verbose=<span class="number">0</span>)</span><br><span class="line">model.learn(total_timesteps=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">obs_PPO1 = env_PPO1.reset()</span><br><span class="line">obs_basis = env_basis.reset()</span><br><span class="line">env_PPO1.current_step = env_basis.current_step</span><br><span class="line">obs_PPO1 = obs_basis</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">    action_PPO1, _ = model.predict(obs_PPO1)</span><br><span class="line">    action_basis = pi(obs_basis)</span><br><span class="line">    <span class="comment"># print(env_PPO1.current_step, env_basis.current_step)</span></span><br><span class="line">    obs_PPO, rewards_PPO, done_PPO, info_PPO = env_PPO1.step(action_PPO1)</span><br><span class="line">    obs_basis, rewards_basis, done_basis, info_basis = env_basis.step(action_basis)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">20</span> ==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">&quot;****&quot;</span>*<span class="number">5</span>, <span class="string">&quot;PPO&quot;</span>, <span class="string">&quot;***&quot;</span>*<span class="number">5</span>)</span><br><span class="line">        env_PPO1.render()</span><br><span class="line">        print(<span class="string">&quot;****&quot;</span>*<span class="number">5</span>,<span class="string">&quot;Basis&quot;</span>,<span class="string">&quot;***&quot;</span>*<span class="number">5</span>)</span><br><span class="line">        env_basis.render()</span><br><span class="line">        </span><br></pre></td></tr></table></figure><p>还凑活吧，能用</p><figure><img src="img.png" alt="img.png" /><figcaption aria-hidden="true">img.png</figcaption></figure><h2 id="总结">总结</h2><ol type="1"><li>牛刀初试，强化学习实际效果不算离谱，凑活能用。</li><li>现有的强化学习算法框架比较成熟了, like stable-baselines，接口简单易用。</li><li>股票交易的Environment，github上还没有找到比较好用的工具，这个只能自己靠自己写了。上面写的一个简单的env，没有考虑交易费用/允许做空等情况，还要进一步细化。</li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://github.com/chiechie/quantML/blob/master/gym_rl.py">quantML-github-chiechie</a></li><li><a href="https://github.com/hill-a/stable-baselines">强化学习算法框架-stable-baselines</a></li><li><a href="https://www.oreilly.com/radar/introduction-to-reinforcement-learning-and-openai-gym/">强化学习环境框架-gym</a></li><li><a href="https://towardsdatascience.com/creating-a-custom-openai-gym-environment-for-stock-trading-be532be3910e">构建交易环境-medium</a></li><li><a href="https://github.com/wangshub/RL-Stock">构建交易环境和交易策略-github</a></li><li><a href="https://www.youtube.com/watch?v=5P7I-xPq8u8">PPO-youtube</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;现在进行强化学习第2个实践项目--构建交易机器人，&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;思路&quot;&gt;思路&lt;/h2&gt;
&lt;p&gt;老路子，先构建environment 再构建agent：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;environment需要定义</summary>
      
    
    
    
    <category term="AI" scheme="https://chiechie.github.io/categories/AI/"/>
    
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="强化学习" scheme="https://chiechie.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="量化交易" scheme="https://chiechie.github.io/tags/%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93/"/>
    
  </entry>
  
  <entry>
    <title>十三邀-采访李安</title>
    <link href="https://chiechie.github.io/2021/05/30/reading_notes/shisanyao-lian/"/>
    <id>https://chiechie.github.io/2021/05/30/reading_notes/shisanyao-lian/</id>
    <published>2021-05-30T04:02:44.000Z</published>
    <updated>2021-05-31T00:46:04.218Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>看了昨天看十三邀采访李安那一期，关于如何面对恐惧，作为旁观者如何深入一个领域，李安分享了一些自己的经验</p><p>这些也是我比较困惑的地方，有一些触动，但是要完全解答我的困惑，还得考自己去实践吧</p></blockquote><h3 id="勤能补拙的旁观者">勤能补拙的旁观者</h3><p>许知远：你说你总是一个旁观者，旁观者可以进入不同的领域，通过研究理解事物，但它的劣势是什么？</p><p>李安：劣势就是不够地道，你只能用将心比心和勤快去弥补；另一个弥补就是电影不是我一个人拍的，这么多人参与，我总是可以跟他们商量，看看对不对，试试风向。</p><p>电影总是人家看嘛，只要你够勤快，天分到，你合作的伙伴愿意投入，入木三分是做得到的。</p><p>局外人的好处是看得比较准，而且一看就能看到； 局内人的话，你的成长经验、成见都会产生影响。</p><p>我觉得让局外人去做一个东西比较简单，但局内人的话，你要把自己的肉拿出来拧的话，有更大的难度。</p><p>事不关己，关己则乱。</p><p>chiechie: 我在研究一个新领域时，也经常会经常怀疑自己，所以要相信勤能补拙，做不到100分，80分总是可以的</p><h3 id="面对不安假装我是谁">面对不安"假装我是谁"</h3><p>许知远：被上了这么多次不同的“身”，面对不安全感、恐惧、挣扎，然后走出来，你觉得人变得更安全了吗？</p><p>李安：我想我们的成长不必靠电影去修炼，你可以用别的方式。我觉得我可能很像演员吧，年轻的时候我想过做演员，做不成，英文不会讲，就做了导演，所以我跟演员扮演角色的感觉很像。我记得梁朝伟跟我讲了一句话，他说“我们做演员很痛苦”，当然，好的演员才会这样讲。因为我每天都在说服他相信一些东西，他自己也相信了，然后就变成了那个人。拍完以后，又要说服自己不要去相信那个东西，要走出来，好累。而我可能就是用电影来扮演不同的角色吧。我觉得就像《色戒》里的主题一样，<strong>透过假装一件事情，你才会有胆量去触摸真实</strong>。<strong>我想人生倒是不可能没有一些好奇心，我们有自己的课业要学，这一辈子有很多东西要学，而这是一个很好的学习方式——“假装是谁”</strong>。</p><p>chiechie： 对于局内人，比如我工作中，要把我的亲身经验拿出来，反复的批判自己，让我感觉很痛苦，但是透过假装一件事情--假装我是谁，做产品的时候可以更有胆量去触摸真实。</p><h3 id="人生就像剥洋葱">人生就像剥洋葱</h3><p>李安：我觉得我也需要去摸自己不同的面向。</p><p>根据成长经验，你到了某一个面向，又到了某一个时间，你会对其他的主题产生兴趣，会遭遇一个困境，需要去触摸它，如果不去触摸的话，它会骚扰不休的。</p><p><strong>首先是要面对，然后去处理它，去处理它以后就可以把它 rationalize（理性化）了，你就定型了</strong>。</p><p>可是一个议题处理以后，你又会有新的会骚扰你的东西，你又要去面对它、处理它，然后把它理性化，<strong>这就跟剥洋葱一样，我想人生是剥不尽的</strong>。</p><h3 id="摸着石头过河">摸着石头过河</h3><p>许知远：那你现在最想剥的是哪块“洋葱”？你最想处理的是哪个主题？</p><p>李安：我不晓得，看下部电影吧。我可能会处理不同议题，也可能是用不同的角度来看同样的事情，这都很难讲，我不是天天思索这种问题的人，我不是搞哲学的。对，哲学有这个需要，它一定要有道理，而<strong>我是拍出来再制作道理</strong>。</p><p>我相信道家的玄之又玄，因为真的就是这样，摸不透，<strong>我只能在我可以触摸的地方去感受它</strong>。有时候触动别人的心的时候，也是有感应的，毕竟我们不是单独的存在嘛；感应多了有时候也有烦的时候，也有想独自一人的时候，<strong>人生也没有什么太大需要解答的东西，摸摸石头过河</strong>。</p><h3 id="命运的安排">命运的安排</h3><p>许知远：如果当时没有去美国，留在台湾，会是什么样？</p><p>李安：不晓得，我的命就是那个时候该离开。我说年纪到了，跟我的朋友冯光远一起去了，后来我们在纽约的人，大部分都回了台湾，很多人到了北京和上海，留在纽约的其实已经很少了。我那时候其实也想回来，可是刚好申请了绿卡，因为美国有一个经纪人签了我。学校刚毕业，太太还在读书，小孩生了，于是就在那边耗着。申请绿卡又好几年不能离开，也不能回台湾找工作，就这么耗着。说真的，我在念书的时候，从来没有想过可能在美国拍电影，这个事情在我脑子还不构成一个想象，连“梦想”都还没有。后来我得了台湾的一个奖，非拍那个片子不可，故事写的是美国，我才开始。后来那个片子又得奖了，一得国际奖，我又进了美国的艺术院线。</p><p>这也不是我设计出来的，好像是命运规定我这么走。现在好像<strong>东西两方我都沾到，有时候也会落到“缝隙”里面</strong>，这种经验也不少。</p><h3 id="失败的经历">失败的经历</h3><p>许知远：落到“缝隙”里是什么感觉？怎样描述这个“缝隙”？</p><p>李安：有一种黑暗无助的感觉。我不是每部电影都那么卖座成功的，我也受过好多打击，刚开始的时候也吃过很多苦头。</p><p>许知远：印象最深的打击是什么？</p><p>李安：不一而足啦，片子不卖座，没人看。但我觉得那片子也挺好，跟我成功的片子一样，<strong>我一样的拍，觉得差不多，可为什么别人不看呢</strong>？</p><p>电影有时真的是<strong>人算不如天算</strong>。</p><p>有的电影中西方都有市场，比如《断背山》这样的，突然大家都喜欢上了，这是没有国界的，我也不晓得为什么，我让一个台湾人看，他为什么会感动，我真的是不晓得。</p><p>我第一次受打击其实是拍完《冰风暴》，真没人看，《绿巨人》也是受打击的。</p><p>其实我受到的打击，我自己也不太知道，即便大约知道是什么，我也不敢肯定，所以会有一种惶恐的感觉，我也不是习惯受打击的。</p><h3 id="参考">参考</h3><ol type="1"><li><a href="https://www.sohu.com/a/349695818_563941">十三邀-许知远采访李安-文字稿</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;看了昨天看十三邀采访李安那一期，关于如何面对恐惧，作为旁观者如何深入一个领域，李安分享了一些自己的经验&lt;/p&gt;
&lt;p&gt;这些也是我比较困惑的地方，有一些触动，但是要完全解答我的困惑，还得考自己去实践吧&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="许知远" scheme="https://chiechie.github.io/tags/%E8%AE%B8%E7%9F%A5%E8%BF%9C/"/>
    
    <category term="李安" scheme="https://chiechie.github.io/tags/%E6%9D%8E%E5%AE%89/"/>
    
    <category term="十三邀" scheme="https://chiechie.github.io/tags/%E5%8D%81%E4%B8%89%E9%82%80/"/>
    
    <category term="访谈录" scheme="https://chiechie.github.io/tags/%E8%AE%BF%E8%B0%88%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>关于雷蛇的个股研究</title>
    <link href="https://chiechie.github.io/2021/05/28/investment/about-leishe/"/>
    <id>https://chiechie.github.io/2021/05/28/investment/about-leishe/</id>
    <published>2021-05-28T05:31:24.000Z</published>
    <updated>2021-06-03T09:23:29.189Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>试着分析下</p><p>行业--&gt;护城河--&gt;未来增长--&gt;风险</p><p>分析不出啥？？？电脑主机？</p></blockquote><h2 id="行业分析">行业分析</h2><p>雷蛇属于电子消费行业，在2017-11-13 在港交所上市。</p><p>雷蛇卖什么？卖游戏周边，包括：</p><ul><li>硬件：游戏周边设备，鼠标键盘耳机，游戏笔记本</li><li>软件：？？</li><li>服务：支付服务。</li></ul><p>雷蛇的竞争对手，罗技</p><h3 id="关于显卡的产业链">关于显卡的产业链</h3><p>显卡供应商： <span class="math inline">\(AMD(AMD)\)</span> <span class="math inline">\(英伟达(NVDA)\)</span><br />显卡消费者：矿工和游戏玩家</p><p>近半年，受到疫情影响，供应减少， 同时需求增多（主要是加密货币火爆行情刺激了矿机需求）</p><p>两种原因导致显卡涨价</p><figure><img src="./img.png" alt="英伟达股价" /><figcaption aria-hidden="true">英伟达股价</figcaption></figure><figure><img src="./img_1.png" alt="AMD股价" /><figcaption aria-hidden="true">AMD股价</figcaption></figure><figure><img src="./img_2.png" alt="雷蛇股价" /><figcaption aria-hidden="true">雷蛇股价</figcaption></figure><h2 id="未来增长">未来增长</h2><p>集團更進一步拓展移動╱雲端遊戲、主機遊戲、直播產品及電競椅等增長領域</p><h2 id="其他新闻">其他新闻</h2><ol type="1"><li>雷蛇于5月12日在联交所回购855万股，每股价格介乎2.62至2.66846元，涉资约2,281.53万元。</li><li>2021年初至今雷蛇已回购约1.71亿股，占已发行股本约1.9229%。</li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://doc.irasia.com/listco/hk/razer/annual/2020/crespress.pdf">雷蛇2020年财报</a></li><li><a href="https://news.futunn.com/post/9452174?lang=zh-cn&amp;src=2&amp;report_type=stock&amp;report_id=17625226&amp;level=1&amp;data_ticket=1615555035779921">雷蛇(01337.HK)斥约2,281万元回购855万股</a></li><li><a href="https://news.futunn.com/report/821714?lang=zh-cn&amp;src=43&amp;level=1&amp;data_ticket=1615555035779921">广发证券</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;试着分析下&lt;/p&gt;
&lt;p&gt;行业--&amp;gt;护城河--&amp;gt;未来增长--&amp;gt;风险&lt;/p&gt;
&lt;p&gt;分析不出啥？？？电脑主机？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;行业分析&quot;&gt;行业分析&lt;/h2&gt;
&lt;p&gt;雷蛇属于电子消费行业，在201</summary>
      
    
    
    
    <category term="投资" scheme="https://chiechie.github.io/categories/%E6%8A%95%E8%B5%84/"/>
    
    
    <category term="行业研究" scheme="https://chiechie.github.io/tags/%E8%A1%8C%E4%B8%9A%E7%A0%94%E7%A9%B6/"/>
    
    <category term="投资" scheme="https://chiechie.github.io/tags/%E6%8A%95%E8%B5%84/"/>
    
  </entry>
  
  <entry>
    <title>强化学习3 使用gym规划出租车行车路线的demo</title>
    <link href="https://chiechie.github.io/2021/05/27/AI/reinforcement_learning/rl3-gym/"/>
    <id>https://chiechie.github.io/2021/05/27/AI/reinforcement_learning/rl3-gym/</id>
    <published>2021-05-27T12:33:14.000Z</published>
    <updated>2021-05-31T07:07:22.467Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>看完了强化学习的理论，现在来动手试一试</p></blockquote><h2 id="场景介绍">场景介绍</h2><p>以出租车司机路线规划为背景，下面演示一下如何由强化学习解决这个问题</p><p>为了将问题进一步简化，基于已有的强化学习框架gym，我就可以更关注在策略实现了</p><p>首先强化学习将问题建模为两个部分：环境（environment）和 决策主体（agent）。 环境基于state，action给出反馈（reward），以及下一个时刻的reward。 agent基于state，给出最佳的action。</p><p>对于「出租车路线规划问题」，state就是给定区域：出租车坐标，行人坐标，行人目的地，障碍物（墙）的坐标，出租车当前是否已经载人</p><p>action就4个方向（东南西北），2个动作（载人，下客）</p><h2 id="开始编程实现啦">开始编程实现啦</h2><h3 id="step1-加载出租车路线规划这个环境">step1: 加载「出租车路线规划」这个环境</h3><p>因为gym已经带有这个环境，直接可用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gym</span><br><span class="line"></span><br><span class="line">env = gym.make(<span class="string">&quot;Taxi-v3&quot;</span>)</span><br><span class="line">env.reset()</span><br><span class="line"><span class="comment"># visulize current state</span></span><br><span class="line">env.render()</span><br></pre></td></tr></table></figure><figure><img src="img.png" alt="environment" /><figcaption aria-hidden="true">environment</figcaption></figure><p>上图环境渲染的图中</p><ul><li>黄色方块代表出租车当前的位置</li><li>“|”代表一堵墙，不能穿透</li><li>蓝色的字母表示载人地方</li><li>紫色的字母表示下客的地方</li><li>出租车接到人之后会编程绿色</li></ul><p>注意，这些颜色，形状只是方便人理解，算法内部只关心有5个状态</p><h3 id="step2-看一下action的6个状态">step2： 看一下action的6个状态</h3><p>看一下action的6个状态， down (0), up (1), right (2), left (3), pick-up (4), and drop-off (5). <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(env.action_space)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    print(env.action_space.sample())</span><br></pre></td></tr></table></figure> <img src="img_1.png" alt="img_1.png" /></p><h3 id="step3-跟env交互一次">step3: 跟env交互一次</h3><p>跟env交互一次，拿到反馈和最新的状态</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">state, reward, done, info = env.step(action=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p><img src="img_3.png" alt="img_3.png" /> 注意：每个Gym环境的step方法都返回state, reward, done, info这四个变量，输入某个action</p><h3 id="step4-使用某个简单策略随机策略">step4： 使用某个简单策略（随机策略）</h3><p>使用某个简单策略（随机策略），让出租车跑完一轮</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">state = env.reset()</span><br><span class="line">env.render()</span><br><span class="line">n = <span class="number">0</span></span><br><span class="line">r = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    state, reward, done, info = env.step(action=env.action_space.sample())</span><br><span class="line">    r += reward</span><br><span class="line">    n = n + <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> done:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">print(<span class="string">&quot;totally make %d decisions&quot;</span> % (n+<span class="number">1</span>), <span class="string">&quot;total reward&quot;</span>, r)</span><br><span class="line">env.render()</span><br></pre></td></tr></table></figure><figure><img src="img_4.png" alt="img_4.png" /><figcaption aria-hidden="true">img_4.png</figcaption></figure><h3 id="step5-升级策略-q-table-跑多轮">step5: 升级策略-Q-table, 跑多轮</h3><p>Q-table使用bellman方程迭代更新策略，并且存放到一张表中（这个表就是Q-table），即每个状态，每个action对应的Q-value</p><p><span class="math display">\[Q_{t+1}\left(s_{t}, a_{t}\right)=\underbrace{Q_{t}\left(s_{t}, a_{t}\right)}_{\text {old value }}+\underbrace{\alpha_{t}\left(s_{t}, a_{t}\right)}_{\text {learning rate }} \times[\overbrace{\underbrace{R_{t+1}}_{\text {reward }}+\underbrace{\gamma}_{\text {discount factor }} \underbrace{\max _{a} Q_{t}\left(s_{t+1}, a_{t}\right)}_{\text {estimate of optimal future value }}}^{\text {learned value }}-\underbrace{Q_{t}\left(s_{t}, a_{t}\right)}_{\text {old value }}]\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">n_state = env.observation_space.n</span><br><span class="line">n_action = env.action_space.n</span><br><span class="line">Q_table = np.zeros((n_state, n_action))</span><br><span class="line">alpha = <span class="number">0.615</span></span><br><span class="line">gamma = <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    state = env.reset()</span><br><span class="line">    <span class="comment">#env.render()</span></span><br><span class="line">    n = <span class="number">0</span></span><br><span class="line">    r = <span class="number">0</span></span><br><span class="line">    done = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">while</span> done <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">        best_action = np.argmax(Q_table[state, :])</span><br><span class="line">        state2, reward, done, info = env.step(action=best_action)</span><br><span class="line">        Q_table[state, best_action] = Q_table[state, best_action] + alpha *(reward + gamma * np.<span class="built_in">max</span>(Q_table[state2]) - Q_table[state, best_action])</span><br><span class="line">        r += reward</span><br><span class="line">        n = n + <span class="number">1</span></span><br><span class="line">        <span class="comment"># 别漏了</span></span><br><span class="line">        state = state2 </span><br><span class="line">    <span class="keyword">if</span> episode % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">&#x27;Episode &#123;&#125; Total Reward: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(episode,r))</span><br></pre></td></tr></table></figure><figure><img src="img_6.png" alt="img_6.png" /><figcaption aria-hidden="true">img_6.png</figcaption></figure><h2 id="遗留问题">遗留问题</h2><ol type="1"><li>策略函数要设置约束，比如不能撞墙</li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.oreilly.com/radar/introduction-to-reinforcement-learning-and-openai-gym/">强化学习环境框架-gym</a>)</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;看完了强化学习的理论，现在来动手试一试&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;场景介绍&quot;&gt;场景介绍&lt;/h2&gt;
&lt;p&gt;以出租车司机路线规划为背景，下面演示一下如何由强化学习解决这个问题&lt;/p&gt;
&lt;p&gt;为了将问题进一步简化，基于已有的强化</summary>
      
    
    
    
    <category term="AI" scheme="https://chiechie.github.io/categories/AI/"/>
    
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="强化学习" scheme="https://chiechie.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>道德经1-反者道之动, 弱者道之用</title>
    <link href="https://chiechie.github.io/2021/05/26/reading_notes/daodejing1/"/>
    <id>https://chiechie.github.io/2021/05/26/reading_notes/daodejing1/</id>
    <published>2021-05-26T01:23:01.000Z</published>
    <updated>2021-05-26T02:33:51.506Z</updated>
    
    <content type="html"><![CDATA[<p>守弱：如婴儿般的柔和与可塑。</p><p>任何属性，操性，仁则都有其正负两面，也就是阴与阳。而属性明显曰「强」，属性混沌曰「弱」。如果根据一己之经验，认为一种属性，操性，仁则只有好处，没有缺陷，而拼命发展，必致「阴」「阳」失调而进入危境。</p><p>二十三章:「希言自然。故飘风不终朝，骤雨不终日。孰为此者?天地。天地尚不能久，而况于人乎。」</p><p>以飘风骤雨为天候中「阴」「阳」不调之例子。这就隐喻到「雷厉风行」，偏执一「仁」一「义」之治事方法是不能长久的;无论在当事人看来他的「政治理想」是多么完美或吸引人。</p><p>五十五章:「含德之厚，比于赤子……知和曰常，知常曰明。益生曰祥。心使气曰强。物壮则老，谓之不道，不道早巳。」</p><p>以婴儿为「合乎自然」的例子，也就是阴阳调和之例子。婴儿柔和，乃负阴抱阳之象，合于大道。但人一旦成长启智之后，就慢慢的开始过分发展某种属性，操性，或仁则，其原因可是功利的，也可是欲望驱使的。而过分发展某种属性之结果就是「老」。</p><p>三十章:「……果而勿矜，果而勿伐，果而勿骄。果而不得已，果而勿强。物壮则老，是谓不道，不道早巳。」</p><p>人之「老」在躯体也在头脑，最大的特征在失去思想之柔韧与变通---这些都是过分发展某一属性之「果」。人会变得过于执着固定事物，或过于刚猛，或过于退怯;百象皆有，不一而足;總之，都不合道。从老子之道来看就是失去「负阴抱阳」之特性。</p><p>十一章： 三十辐共一毂，当其无，有车之用。埏埴以为器，当其无，有器之用。凿户牖以为室，当其无，有室之用。故有之以为利，无之以为用。</p><p>任何器具、房室、或机械要发生作用，都要有一「容纳」其他事物之「空间」，老子以此「空间」喻道之「无」，而容万物之性使万物发生作用。</p><p>四十章:「反者道之动;弱者道之用。天下万物生于有，有生于无」。</p><p>王弼的诠释:「高以下为基，贵以贱为本，有以无为用，此其反也，动皆知其所无，则物通矣」。「此其反也，动皆知其所无(道之本体)」一段有双关之意，即「相反相成」与「返于道之本体[无]」。「动皆知其所无」指要明白大道之运作，一定要对万事万物追溯至「无」之起源处。</p><p>这个道理对古之君王重要，对于一般人或短时间却不尽然。一般人在一时空下可有某一操性，或行某一仁则而畅通无阻，甚至终生得志。但这只是从一人或一团体来看;对整体国家来说则大不相同。毫无疑问的，治道要讲求整体国家之长治久安，所以明了[弱者道之用]是必要的</p><blockquote><p>对做平台也很重要。</p></blockquote><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.aisixiang.com/data/37674.html">反者道之动, 弱者道之用”之詮釋</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;守弱：如婴儿般的柔和与可塑。&lt;/p&gt;
&lt;p&gt;任何属性，操性，仁则都有其正负两面，也就是阴与阳。而属性明显曰「强」，属性混沌曰「弱」。如果根据一己之经验，认为一种属性，操性，仁则只有好处，没有缺陷，而拼命发展，必致「阴」「阳」失调而进入危境。&lt;/p&gt;
&lt;p&gt;二十三章:「希言自</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="哲学" scheme="https://chiechie.github.io/tags/%E5%93%B2%E5%AD%A6/"/>
    
    <category term="道家" scheme="https://chiechie.github.io/tags/%E9%81%93%E5%AE%B6/"/>
    
    <category term="道德经" scheme="https://chiechie.github.io/tags/%E9%81%93%E5%BE%B7%E7%BB%8F/"/>
    
  </entry>
  
  <entry>
    <title>风控领域的图挖掘场景</title>
    <link href="https://chiechie.github.io/2021/05/24/technology/visualize-graph/"/>
    <id>https://chiechie.github.io/2021/05/24/technology/visualize-graph/</id>
    <published>2021-05-24T01:08:21.000Z</published>
    <updated>2021-05-26T01:18:16.313Z</updated>
    
    <content type="html"><![CDATA[<h1 id="几个场景">几个场景</h1><h2 id="攻防对抗">攻防对抗</h2><p>一般都会有下述风控规则：</p><ul><li>7天内在注册账户数超过**的设备号</li><li>1天内某IP关联超过xx个账户</li></ul><p>虽然规则简单，但由于实时性和贴近业务的特点，可以拦截不少黑产, 但也会造成一定误杀，特别是IP类的规则。</p><p>同时因为风控是攻防对抗的过程，黑产也会升级，比如通过伪造设备、LBS、频繁更换IP等手段尽可能伪装成一个真人，隐蔽聚集性等显性特征，绕过风控规则。</p><p>相应风控技术也在进化，如使用设备指纹、IP画像、验证码对抗等。</p><h2 id="基于关联关系识别团伙">基于关联关系识别团伙</h2><p>可以定义设备-账户的Graph如下：</p><ul><li>节点：账户 + 设备</li><li>边：近xx天账户与设备出现在同一事件中，则它们之间有一条边。</li></ul><p>识别方法：</p><ul><li>无监督方法：通过「连通子图算法」识别出一个个连通的社区，如果社区规模较大，可能背后业务含义是黑产控制一批账户。定义社区规模为score，通过调节阈值来控制误杀、召回。</li><li>有监督方法-传统：等价为节点分类问题，通过提取节点业务特征、拓扑特征、所属社区特征，训练一个分类器去预测。</li><li>有监督方法-图神经网络：将节点业务特征X与网络拓扑结构A作为输入学习函数，用于对未知数据的预测.相比规则来说，此类方法不仅用到了更复杂的关系，同时也考虑了节点业务和拓扑特征。故防控能力会更强一些。</li></ul><h2 id="基于相似度识别团伙">基于相似度识别团伙</h2><p>如果黑产成功避开设备指纹、聚集性规则等风控措施，把自己伪装成一个真人，如何检测？——只要作案了，总会留下蛛丝马迹。</p><ul><li>垃圾文本：比如留下了垃圾文本，那么利用文本之间相似度（Jaccard、semi-hash）构建账户之间相似关系，然后使用图分割+连通子图查找技术识别，具体可<a href="https://zhuanlan.zhihu.com/p/23385044">参考这里</a></li><li>行为相似度：facebook针对刷量的行为，通过计算账户之间行为度来构建graph，<a href="https://zhuanlan.zhihu.com/p/58334765">详见这里</a>.此类方法最大问题是, 两两节点相似度计算性能问题。一般会做下约束，如限制在某个事件场景下、限制在某段事件内以及如何分段计算+合并，并且往往是通过spark分布式计算。</li></ul><h2 id="基于共享特征识别团伙">基于共享特征识别团伙</h2><p>因为黑产控制大量的账户通过软件进行攻击，而不是手工操作，故这些账户某些共同属性上会有Pattern。</p><p>大概的解题思路是“搜集证据”，将共享的某特征/字段作为，判断证据强弱，如共享设备是强证据，可以仅凭此条直接断案。 但是像共用某品牌手机是弱证据，需要多个弱证据结合一起断案。</p><p>再抽象一点是有点像「层次社区划分算法」：</p><ol type="1"><li>定义证据：通过业务经验定义共享特征集，不通场景特征集应该是不同的。</li><li>找证据：分别对每个/每组特征进行聚类/社区划分算法，得到一个个簇.</li><li>组合证据：将2得到的簇作为节点，簇之间共有账户数作为连边，构建graph，再进一步划分得到最终的社区，每个社区中的节点共享多个特征。</li></ol><h1 id="总结">总结</h1><ol type="1"><li>上述三种类型方法的主要区别在于graph的不同，在整个图挖掘体系中最核心也最难一点在于，如何将业务经验抽象成Graph。</li><li>社区发现算法以图分割+连通子图查找为主，一方面可解释强，另外可以通过调节阈值权衡召回和误差，以满足运营人员需要。这也是 "拿算法适配业务，而不是业务适配算法"的工作准则。</li></ol><h1 id="参考">参考</h1><ol type="1"><li><a href="https://scikit-network.readthedocs.io/en/latest/">scikit-network的doc</a></li><li><a href="https://www.zhihu.com/search?type=content&amp;q=%E5%9B%BE%E6%8C%96%E6%8E%98">zhihu-风控</a></li><li><a href="https://zhuanlan.zhihu.com/p/62750137">GCN</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;几个场景&quot;&gt;几个场景&lt;/h1&gt;
&lt;h2 id=&quot;攻防对抗&quot;&gt;攻防对抗&lt;/h2&gt;
&lt;p&gt;一般都会有下述风控规则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;7天内在注册账户数超过**的设备号&lt;/li&gt;
&lt;li&gt;1天内某IP关联超过xx个账户&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虽然规则简单</summary>
      
    
    
    
    <category term="技术" scheme="https://chiechie.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
    <category term="图数据" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE/"/>
    
    <category term="图挖掘" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E6%8C%96%E6%8E%98/"/>
    
    <category term="连通子图算法" scheme="https://chiechie.github.io/tags/%E8%BF%9E%E9%80%9A%E5%AD%90%E5%9B%BE%E7%AE%97%E6%B3%95/"/>
    
    <category term="层次社区划分算法" scheme="https://chiechie.github.io/tags/%E5%B1%82%E6%AC%A1%E7%A4%BE%E5%8C%BA%E5%88%92%E5%88%86%E7%AE%97%E6%B3%95/"/>
    
    <category term="社区发现算法" scheme="https://chiechie.github.io/tags/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>随机游走</title>
    <link href="https://chiechie.github.io/2021/05/23/AI/cause-effect/randomwalking/"/>
    <id>https://chiechie.github.io/2021/05/23/AI/cause-effect/randomwalking/</id>
    <published>2021-05-23T04:52:46.000Z</published>
    <updated>2021-05-24T01:56:27.155Z</updated>
    
    <content type="html"><![CDATA[<h2 id="介绍">介绍</h2><p>已知因果图时，随机游走可以用来做因果推断。</p><p>原理是，基于因果关系，构建概率转移矩阵，通过模拟故障传播路径，得到故障根因。</p><h2 id="随机游走算法-详细">随机游走算法-详细</h2><ul><li>Step 1. 生成一个关系图G. <span class="math inline">\(e_{ij} = 1\)</span> 表示节点i是节点j的原因（之一）</li><li>Step 2. 计算转移矩阵Q:<ol type="1"><li>向前游走：从result节点到 the cause节点.理论上，跟异常节点越相关的节点，就越有可能是根因. 也就是说 <span class="math inline">\(Q_{ij} = R(v_{abnormal}, v_j)\)</span>, <span class="math inline">\(R(v_{abnormal}, v_j)\)</span>表示异常节点<span class="math inline">\(v_{abnormal}\)</span> 和 $ v_j$之间的相关系数, and <span class="math inline">\(e_{ji} = 1\)</span></li><li>向后游走：从cause节点到result节点. 为了避免算法陷入跟异常不相关或者低相关的节点，随机游走允许从cause节点跳出到result节点。 如果 <span class="math inline">\(e_{j i} \in E\)</span>且 <span class="math inline">\(e_{ij} \notin E\)</span>, 那么 <span class="math display">\[Q_{ji} =\rho R\left(v_{abnormal}, v_{i}\right),\rho \in[0,1]\]</span>.</li><li>维持原状：如果一个节点，它的邻居们都跟异常节点的相关性很低，这个节点很有可能就是根因了，所以游走者应该停留在这里， <span class="math display">\[Q_{i i}=\max \left[ 0, R\left(v_{abnormal}, v_{i}\right)- \max _{k: e_{k i} \in E} R\left(v_{abnormal}, v_{k}\right) \right]\]</span></li></ol></li><li>Step 3. 对行做归一化，得到转移概率矩阵 <span class="math display">\[\bar{Q}_{i j}=\frac{Q_{i j}}{\sum_{j} Q_{i j}}\]</span></li><li>Step 4. 在G上面随机游走，使转移概率<span class="math inline">\(\bar{Q}\)</span></li></ul><p>采用类似pagerank的方法，得到每个节点的得分。</p><h2 id="参考">参考</h2><ol start="4" type="1"><li><a href="https://netman.aiops.org/wp-content/uploads/2020/06/%E5%AD%9F%E5%AA%9B.pdf">Page3,4 -paper</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;介绍&quot;&gt;介绍&lt;/h2&gt;
&lt;p&gt;已知因果图时，随机游走可以用来做因果推断。&lt;/p&gt;
&lt;p&gt;原理是，基于因果关系，构建概率转移矩阵，通过模拟故障传播路径，得到故障根因。&lt;/p&gt;
&lt;h2 id=&quot;随机游走算法-详细&quot;&gt;随机游走算法-详细&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;St</summary>
      
    
    
    
    <category term="技术" scheme="https://chiechie.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
    <category term="贝叶斯" scheme="https://chiechie.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    
    <category term="因果推断" scheme="https://chiechie.github.io/tags/%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD/"/>
    
    <category term="因果分析" scheme="https://chiechie.github.io/tags/%E5%9B%A0%E6%9E%9C%E5%88%86%E6%9E%90/"/>
    
    <category term="根因分析" scheme="https://chiechie.github.io/tags/%E6%A0%B9%E5%9B%A0%E5%88%86%E6%9E%90/"/>
    
    <category term="AIOps" scheme="https://chiechie.github.io/tags/AIOps/"/>
    
  </entry>
  
  <entry>
    <title>PageRank算法</title>
    <link href="https://chiechie.github.io/2021/05/22/technology/pagerank/"/>
    <id>https://chiechie.github.io/2021/05/22/technology/pagerank/</id>
    <published>2021-05-22T10:07:11.000Z</published>
    <updated>2021-05-24T01:56:27.164Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>最近需要对图数据进行分析，了解下PageRank的原理</p><p>BTW, PageRank还可以做社区划分？</p></blockquote><h2 id="总结一下">总结一下</h2><p>pagerank: 假设，网上冲浪的人都是漫无目的的人，他们在网页一个链接接一个链接点下去，但是，整个互联网的节点，最终流量可能的分布能达到一个稳态。 也就是说，随机分布于各网页的流量经过次数足够多的转移之后，会达到一个稳定的状态，这个也代表每个网页的信息度。</p><p>基于这个假设，可以构建一个模型， <span class="math display">\[V_n = M ^n * V_0\]</span></p><p>一般来说，可以拿到网页之间调用拓扑，经过转换，可以将这个拓扑变为概率转移矩阵M，最终算出稳定态的V_n</p><p>给定点之间的连接关系，输出每个节点的分数，</p><p>补充下，最naive的方法存在终止点问题，也就是说，一个网站它不链接任何别的网站，或者一个微服务，它不调用其他任何微服务 按照上面的思路很可能出现一种情况，最终的流量全到这个自大狂网页那里去了，所以有一个改进的思路，假设冲浪着有一点点聪明，他并不是一味的接受灌输的链接，而是有一定概率，主动跳出去，到达一个新的站点，这个方式可以用下面的式子建模：</p><p><span class="math display">\[V_n = d * M * V_{n-1} + (1-d) * e \]</span></p><p>e = [1/n,...1/n]</p><p>d表示按照当前页面推荐的链接继续点下去的概率 1-d表示从当前网页跳出来，主动输入一个新网页重新开始的概率</p><h2 id="代码">代码</h2><p>用代码验证一下，理解没有问题</p><p>https://github.com/chiechie/BasicAlgo/blob/main/pagerank.py</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ground truth</span><br><span class="line"> [[0.25419178], [0.13803151], [0.13803151], [0.20599017], [0.26375504]]</span><br><span class="line">result</span><br><span class="line"> [0.25419178 0.13803151 0.13803151 0.20599017 0.26375504]</span><br></pre></td></tr></table></figure><h2 id="参考">参考</h2><ol type="1"><li><a href="https://blog.csdn.net/gamer_gyt/article/details/47443877">pagerank-csdn</a></li><li><a href="https://scikit-network.readthedocs.io/en/latest/tutorials/ranking/pagerank.html">scikit-network-pagerank</a></li><li><a href="https://zh.wikipedia.org/wiki/PageRank">wiki-PageRank</a></li><li>https://blog.csdn.net/google19890102/article/details/48660239</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;最近需要对图数据进行分析，了解下PageRank的原理&lt;/p&gt;
&lt;p&gt;BTW, PageRank还可以做社区划分？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;总结一下&quot;&gt;总结一下&lt;/h2&gt;
&lt;p&gt;pagerank: 假设，网上冲浪的人都是</summary>
      
    
    
    
    <category term="技术" scheme="https://chiechie.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
    <category term="图算法" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E7%AE%97%E6%B3%95/"/>
    
    <category term="拓扑数据" scheme="https://chiechie.github.io/tags/%E6%8B%93%E6%89%91%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>chapter2.1.2 基于拓扑的根因定位-CauseInfer2</title>
    <link href="https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-2_1_2-topo-rca-causeinfer-notes2/"/>
    <id>https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-2_1_2-topo-rca-causeinfer-notes2/</id>
    <published>2021-05-21T14:50:18.000Z</published>
    <updated>2021-06-02T09:43:09.250Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录">目录</h2><ul><li><a href="../AIOps-0-summary/">chapter0 概览</a></li><li><a href="../AIOps-1-event-generate/">chapter1 故障发现</a><ul><li><a href="../AIOps-1_1-kpi-detector/">chapter1.1 单指标异常检测</a></li><li><a href="../AIOps-1_2-fault-prediction/">chapter1.3 故障预测</a></li><li><a href="../AIOps-1_4-kpi-correlation/">chapter1.4 指标异常关联</a></li><li><a href="../AIOps-1_5-log-analysis/">chapter1.5 日志聚类</a><ul><li><a href="../AIOps-1_5_1-log-analysis_logmine/">chapter1.5.1 使用logmine加强版做日志聚类</a></li><li><a href="../AIOps-1_5_2-log-analysis_meituan/">chapter1.5.2 美团日志聚类</a></li></ul></li></ul></li><li><a href="../AIOps-2-event-analysis/">chapter2 故障定位</a><ul><li><a href="../AIOps-2_1-topo-rca/">chapter2.1 微服务系统的故障定位</a><ul><li><a href="../AIOps-2_1_1-topo-rca-causeinfer-notes1/">chapter2.1.1 CauseInfer1</a></li><li><a href="../AIOps-2_1_2-topo-rca-causeinfer-notes2/">chapter2.1.2 CauseInfer2</a></li><li><a href="../AIOps-2_1_3-topo-rca-aiops2020/">chapter2.1.3 AIOps挑战赛2020-获奖方案分享</a></li><li><a href="../AIOps-2_1_4-topo-rca-aiops2021/">chapter2.1.4 AIOps挑战赛2021-demo方案</a></li><li><a href="../AIOps-2_1_5-topo-rca-cnsoftbei2020/">chapter2.1.5 N-Softbei2020比赛</a></li><li><a href="../AIOps-2_1_6-topo-rca-MicroCause">chapter2.1.6 MicroCause</a></li></ul></li><li><a href="../AIOps-2_2-multi-dimensional-rca/">chapter2.2 多维下钻根因定位</a></li><li><a href="../AIOps-2_3-trace_rca/">chapter2.3 调用链根因分析</a></li><li><a href="../AIOps-2_4-metric_event_correlation/">chapter2.4 时间序列关联性分析</a></li></ul></li><li>chapter3 故障恢复</li></ul><blockquote><p>本文是《CauseInfer论文笔记》的第二篇，<a href="https://chiechie.github.io/2021/03/02/technology/causeinfer-notes1/">《CauseInfer论文笔记1》</a>，从high-level的角度描述了causeinfer的工作流。这里要开始涉及到方案的具体的实现了，所以内容比较硬核</p><p>不做方案实现的话，可以不用看这篇文章</p></blockquote><h2 id="因果建模">因果建模</h2><h3 id="构建服务依赖图">构建服务依赖图</h3><p>服务依赖图长什么样？一个DAG：</p><ul><li>节点（node）：一个服务。</li><li>边（edge）：代表服务依赖关系。</li></ul><p>这块主要是工程性工作，需要数据采集。</p><ul><li><p>服务依赖图是什么？以服务为节点，服务间的调用关系为边，构造出来的DAG。</p></li><li><p>针对本方案的应用场景，有3个假设前提：</p><ol type="a"><li>所有服务都是使用TCP作为传输层的协议，</li><li>本文的方法依赖网络统计工具，和kprobe来探测系统调用（system call）。根据观察，大部分应用都是采用TCP协议来通信，如mysql，tomcat等；几乎所有主流的操作系统-如linux-都已经跟网络统计工具集成了，例如netstat，tcpdump 和 kprobe。</li><li>利用流量延迟，来决定服务依赖图中的依赖的方向，而不是用分析结果来确定图的结构， 这一部分可以大大减少错误风险， 以及减少计算复杂度。</li></ol></li><li><p>本文用tuple来表示一个服务，即 (ip, service name)，chiechie： 为什么作者能抽象出来，我抽象不出来啊？为什么不像有的文章那样，用three-tuple表示(ip, port, proto)，因为考虑到一个服务可能占用多个端口。举一个例子，在一个三层的系统中，一个web server可以通过任意一个端口访问application server的。如果，使用端口作为唯一服务的属性，这个服务依赖图，就会变得非常之大，即使所有请求都是由同一个服务发起的。</p></li></ul><blockquote><p>补充：</p><p>在分布式系统中，IP表示一台唯一的主机，服务名称表示 运行在该主机上的 唯一的服务。</p></blockquote><ul><li><p>服务依赖的定义：如果服务A需要服务B提供特定功能，来满足 客户端的请求。就说A-&gt;B. 箭头表示「依赖」的意思。举个例子，一个web service需要获取一些数据库的内容，就依赖db服务，就可以说web服务-&gt;db服务。本文只考虑client-server类型的应用（还有什么类型的应用?）</p></li><li><p>怎么获取服务依赖图？</p><ul><li>第一步是搭架子：使用服务间的连接信息来构建 服务依赖图 的骨架（skeleton）。通过运行工具-netstat（有点像一个采集器，类似istatus，小米手环），在一个主机中，我们可以拿到关于一个网络连接的 一堆信息，包括协议，来源，目的地，连接状态。提取来源和目的地信息，每一个连接可以表示为这个形式：source_ip:port -&gt; desination_ip:port. 这一组信息叫一个channel。channel类似，服务依赖pair，除了一点：channel不包含服务名称，只包含port。</li><li>第二步是端口映射：将第一步获取到的服务的端口映射为一个服务的名称。本地服务名称可以通过查询端口信息获取（netstats）。但是对于一个remote端口，需要传输一个查询请求给remote的主机，来获取。将端口映射为服务名之后，一个本地主机的服务依赖图的架子就搭好了。</li><li>第三步是调整依赖方向：由于client和server是双向传递的，即，在不同的主机中观察时，我们可能拿到一个反向的服务依赖。举个例子：<ul><li>当在192.168.1.117中观察时，可以获取一个连接：(192.168.1.117,httpd) → (192.168.1.115, tomcat)，即httpd调用了tomcat。</li><li>但是在192.168.1.115中观察时，又能得到这个连接：(192.168.1.115,tomcat) → (192.168.1.117, httpd), 即tomcat调用了 httpd。</li></ul></li></ul><p>为了解决这个问题，使用流量滞后关联的方法：</p><p>X是服务A的出流量的，Y是服务B的出流量 衡量X和Y之间的滞后的相关性可以用这个指标，k</p></li></ul><p><span class="math display">\[\rho_{X Y}(k)=\frac{\sum_{t=0}^{N-1}\left(Y_{t}-\bar{Y}\right)\left(X_{t-k}-\bar{X}\right)}{\sqrt{\sum_{t=0}^{N-1}\left(X_{t}-\bar{X}\right)^{2} \sum_{t=0}^{N-1}\left(Y_{t}-\bar{Y}\right)^{2}}} k \in Z\]</span> k取什么值合适呢？平移后两个序列的相关性最大，如下，即为最优的<span class="math inline">\(k^{*}\)</span> <span class="math display">\[k^{*}=\left\{\operatorname{argmax}\left(\left|\rho_{X Y}(k)\right|\right), k \in[-30,30]\right\}\]</span></p><p>如果<span class="math inline">\(k^{*}&gt;0\)</span>,则A是B的因（cause），A导致了B, 记为 <span class="math display">\[A \rightarrow B \]</span> 如果<span class="math inline">\(k^{*}&lt;0\)</span>,则B是A的因（cause），B导致了A，记为 <span class="math display">\[B \rightarrow A \]</span></p><h3 id="构建指标因果图">构建指标因果图</h3><p>如何指标因果图？需要用到「因果推断」技术，从数据得到因果关系。这里使用的是<a href="https://chiechie.github.io/2021/03/09/technology/PC-algo/">PC算法</a> &gt; pc算法是一种发现因果关系的算法，在满足一定的假设前提下，使用的基于统计的方法，推导出因果关系。</p><ol type="1"><li>构建因果图的架子</li><li>确定因果关系的方向</li></ol><p>基于PC算法，我们提出了两种方法：保守的 和 激进的。 激进的意思是不使用任何先验知识，来构建因果图。 保守的意思是，使用一些先验知识初始化。</p><p>先验知识是什么呢？ 比如哪些变量没有父母--根因指标，哪些变量没有孩子--表象指标。 比如本地服务的网络延迟（TCP_LATENCY）指标就没有孩子，只是表象指标，因为网络延迟不会导致其他指标的变化。背后的原因可能是 工作负载（workload），配置错误，依赖服务的延迟。</p><h4 id="激进派算法">激进派算法</h4><p>如果一个服务（比如db服务）只会被别人调用，那么指标因果图就只会使用该服务的本地性能指标（服务依赖图依赖的数据一起采集了）。</p><p>但是一个服务，会调用别人，如web service，这个因果图的构建，不仅仅需要本地的性能指标，还需要它调用的服务的TCP LATENCY指标。</p><p>训练数据的长度取的是默认值200，然后使用PC算法，来构建因果图，可以得到一个DAG。</p><p>激进派构建出来的因果图中，会有反直觉的因果关系和双向links；可能包含多个独立的子图，由于缺乏evidence，统计错误， 或者 压根儿就没有因果关系。</p><p>举个例子，Figure 6 (a)(下图左边)的因果图是激进派算法构建的： - M5是一个孤立的服务 - M4 → M2 的因果关系是反直觉的 - M1 和 M4的因果关系是双向的。</p><figure><img src="inference.png" alt="图2-激进法构建出来的因果图" /><figcaption aria-hidden="true">图2-激进法构建出来的因果图</figcaption></figure><p>所以激进派构建出来的因果图需要进一步的加工：根据以下限制条件，从DAG中选择最大的子图</p><ol type="a"><li>子图裁剪：TCP LATENCY指标是表象指标，他不可能是别的指标的cause了</li><li>表象指标通过图中的每条路径都可以达到。</li><li>预设的根因指标没有父母。</li><li>对于一个双向的连接，随机选择一个方向。（这就是随机游走的意思？）</li></ol><h4 id="保守派算法">保守派算法</h4><p>保守派算法，跟激进派很像。区别在于，使用PC算法之前，保守派会利用先验信息做初始化DAG。 和激进算法比，保守算法可以捕捉更多的因果关系，减少反直觉的因果关系。</p><p>举个例子(下图右边)，M1 → SLO的因果关系，激进算法会丢失，但是保守算法会保留。同时 反直觉的因果关系，M4 → M2也被消除了</p><figure><img src="inference.png" alt="图3-保守派构建出来的因果图-右边" /><figcaption aria-hidden="true">图3-保守派构建出来的因果图-右边</figcaption></figure><h2 id="因果推断">因果推断</h2><p>因果模型构建好了，接下来就需要根据这个因果图去做因果推断了。</p><h3 id="整体思路">整体思路</h3><p>当前端的服务可用性指标（SLO）出现异常，就会触发根因分析：</p><ul><li>首先找自己的问题：使用指标因果图 推断本地， 导致服务性能问题的根因指标。</li><li>其次，如果问题是别人造成的，就去找别人的问题：如果根因指标是依赖服务的SLO（注意，用到了调用链关系），这个推断就会继续，传播到远程的依赖的服务。 一直追本溯源，一直到最底层的被调用方，即物理层。</li></ul><h3 id="指标因果图根因推断">指标因果图根因推断</h3><p>指标因果图</p><p>如何定位一个节点上哪个指标的是故障根因？</p><ul><li><p>使用了DFS算法--深度优先搜索，对指标因果图进行遍历。</p></li><li><p>访问到一个节点，对它进行异常检测（cusum）：</p><ul><li>如果异常，继续访问他的后继（descendants）节点，</li><li>如果正常，就去访问的邻居节点。</li></ul></li><li><p>如果一个异常节点没有后继节点，无法再溯源了，或者它的后继节点都正常时，他就是根因。</p></li></ul><figure><img src="inference.png" alt="图3-推断.png" /><figcaption aria-hidden="true">图3-推断.png</figcaption></figure><p>如果SLO异常，从SLO节点开始推断，有两个推断路径</p><ul><li>路径1： 检测M1，如果M1正常的，就访问M1的邻居M2，如果M2异常，就是根因。</li><li>路径2.：接下来M3如果异常，我们就去检测M2，因为M2是异常的，所以我们就输出根因M2。</li></ul><p>最后，我们只找到了一个根因M2，虽然M2和M3都是异常的。</p><p>然而，在某些情况下，因为多个因果路径存在，可能得到一系列的潜在根因集合。 因此，必须把这些根因进行排序，然后输出概率最大的根因。</p><p>如何去给根因进行排序呢？找异常程度最大的那个指标，也就是对异常贡献度最大的指标，就是根因。 这里基于z-score方法提出了一个指标，来衡量性能指标的异常程度，这个评估指标是</p><p><span class="math display">\[\operatorname{violation}(X)=\frac{X(t)-\overline{X_{t-60, t-1}}}{\sigma_{t-60, t-1}+\varepsilon}, \varepsilon=0.001\]</span></p><ul><li><span class="math inline">\(\overline{X_{t-60, t-1}}\)</span> ：滑动窗口的均值</li><li><span class="math inline">\(\sigma_{t-60, t-1}\)</span> ：滑动窗口的标准差</li><li><span class="math inline">\(\varepsilon\)</span> : 扰动项</li></ul><h2 id="参考文献">参考文献</h2><ol type="1"><li><a href="https://netman.aiops.org/~peidan/ANM2016/RootCauseAnalysis/ReadingLists/2014INFOCOM_CauseInfer.pdf">2014-INFOCOM_CauseInfer</a></li><li><a href="https://www.jmlr.org/papers/volume8/kalisch07a/kalisch07a.pdf">2007-The Journal of MachineLearning Research-pc算法</a></li><li><a href="https://saruagithub.github.io/2020/04/13/20200413CauseInfer%E8%AE%BA%E6%96%871/">别人对CauseInfer论文的解读</a></li><li><a href="https://chiechie.github.io/2021/03/09/technology/PC-algo/">chiechie对PC算法的总结</a></li><li><a href="https://chiechie.github.io/2021/03/02/technology/causeinfer-notes1/">CauseInfer论文笔记1</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-0-summary/&quot;&gt;chapter0 概览&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-1-event-generate/&quot;&gt;chapter1 故障发现&lt;/a&gt;
&lt;</summary>
      
    
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/categories/AIOps/"/>
    
    
    <category term="图数据" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE/"/>
    
    <category term="根因分析" scheme="https://chiechie.github.io/tags/%E6%A0%B9%E5%9B%A0%E5%88%86%E6%9E%90/"/>
    
    <category term="AIOps" scheme="https://chiechie.github.io/tags/AIOps/"/>
    
    <category term="微服务" scheme="https://chiechie.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>chapter2.1.5 基于拓扑的根因定位-MicroCause</title>
    <link href="https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-2_1_6-topo-rca-MicroCause/"/>
    <id>https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-2_1_6-topo-rca-MicroCause/</id>
    <published>2021-05-21T14:43:57.000Z</published>
    <updated>2021-06-02T09:43:09.298Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录">目录</h2><ul><li><a href="../AIOps-0-summary/">chapter0 概览</a></li><li><a href="../AIOps-1-event-generate/">chapter1 故障发现</a><ul><li><a href="../AIOps-1_1-kpi-detector/">chapter1.1 单指标异常检测</a></li><li><a href="../AIOps-1_2-fault-prediction/">chapter1.3 故障预测</a></li><li><a href="../AIOps-1_4-kpi-correlation/">chapter1.4 指标异常关联</a></li><li><a href="../AIOps-1_5-log-analysis/">chapter1.5 日志聚类</a><ul><li><a href="../AIOps-1_5_1-log-analysis_logmine/">chapter1.5.1 使用logmine加强版做日志聚类</a></li><li><a href="../AIOps-1_5_2-log-analysis_meituan/">chapter1.5.2 美团日志聚类</a></li></ul></li></ul></li><li><a href="../AIOps-2-event-analysis/">chapter2 故障定位</a><ul><li><a href="../AIOps-2_1-topo-rca/">chapter2.1 微服务系统的故障定位</a><ul><li><a href="../AIOps-2_1_1-topo-rca-causeinfer-notes1/">chapter2.1.1 CauseInfer1</a></li><li><a href="../AIOps-2_1_2-topo-rca-causeinfer-notes2/">chapter2.1.2 CauseInfer2</a></li><li><a href="../AIOps-2_1_3-topo-rca-aiops2020/">chapter2.1.3 AIOps挑战赛2020-获奖方案分享</a></li><li><a href="../AIOps-2_1_4-topo-rca-aiops2021/">chapter2.1.4 AIOps挑战赛2021-demo方案</a></li><li><a href="../AIOps-2_1_5-topo-rca-cnsoftbei2020/">chapter2.1.5 N-Softbei2020比赛</a></li><li><a href="../AIOps-2_1_6-topo-rca-MicroCause">chapter2.1.6 MicroCause</a></li></ul></li><li><a href="../AIOps-2_2-multi-dimensional-rca/">chapter2.2 多维下钻根因定位</a>:</li><li><a href="../AIOps-2_3-trace_rca/">chapter2.3 调用链根因分析</a></li><li><a href="../AIOps-2_4-metric_event_correlation/">chapter2.4 时间序列关联性分析</a></li></ul></li><li>chapter3 故障恢复</li></ul><blockquote><p>清华阿里合作paper《基于因果分析的微服务内根因定位》, Localizing Failure Root Causes in a Microservice through Causality Inferenc</p><p><strong>MicroCause</strong>，可以定位到导致微服务故障的根因指标，原理是，先使用路径条件时间序列算法（PCTS）挖掘时间序列之间的因果关系，然后使用随机游走方法（TCORW）来推断因果。TCORW方法综合分析了因果关系，指标异常程度和优先级信息。</p><p>在86个实际故障实例中，MicroCause给出的top 5根因的准确性（AC @ 5）为98.7％。</p></blockquote><h2 id="背景介绍">背景介绍</h2><p>在微服务架构中，一个「应用程序」往往被分解为多个「微服务」。例如，图1展示了，在淘宝购物时，完成用户下单操作需要调用多个微服务。当前针对微服务系统的故障根因问题，学术界已有一些成熟的工作。这些工作主要是通过学习故障如何在微服务之间传播，并找到根因的微服务，例如，图1中Address微服务是导致支付异常的根因。但是，更进一步的根因信息尚不得而知，也就是说是什么导致这个微服务故障？运维人员还是没法明确知道下一步要怎么响应故障。</p><p><img src="./image-20200622132926186.png" /></p><p>图1：在线购物平台中，当接收到用户下单指令后，Order Creation微服务，将调用Inventory，Discount Coupon，Freight，Address这几个微服务来完成用户下单的需求。</p><p>怎么进一步定位微服务故障根因？ 上游组件，下游组件，部署环境。</p><p>对于一个微服务来说，通常有上游组件（例如，微服务，中间件）调用它，并且它可以调用某些下游组件（例如，微服务，中间件）。如图2所示，用户在淘宝下了一个订单后，”Order Creation“微服务将调用“Discount Coupon”微服务查看可用的优惠券，“Discount Coupon”微服务将调用“Inventory”微服务，针对不同的库存计算不同的优惠金额。此外，微服务通常部署在一个或多个容器或虚拟机。</p><figure><img src="./image-20200622132951991.png" alt="图2：““Discount Coupon”微服务实现细节" /><figcaption aria-hidden="true">图2：““Discount Coupon”微服务实现细节</figcaption></figure><p>对每个微服务需要配置监控指标（如图2所示），包括用户可感知的KPI，上游组件相关的指标，下游组件相关的指标，与部署环境相关的指标（例如CPU）。当KPI异常时，通常表示微服务故障，</p><p>运维人员通常会配置一系列监控指标以持续监视每个微服务的性能（如图2所示）。这些指标包括用户可感知的指标KPI，例如用户响应时间(RT)和指标Metrics. Metrics包括与上游组件相关的指标（例如，Web用户的每秒查询（QPS）），下游组件相关指标（例如中间件的RT），与部署环境相关的指标（例如CPU）。</p><p>当KPI异常时表示微服务故障，到底是组件异常还是部署环境异常，可通过观察指标是否异常得到。</p><p>因此，微服务故障的根本原因可以用异常metrics表示。例如，如图2中，由Web RT异常标明的微服务故障是由Web QPS异常引起的。</p><p>因此在该问题中，我们将针对一个微服务故障实例，给出N个metrics，作为故障的Top N根因。通常一个故障实例由三部分信息组成：异常的KPI，异常的微服务ID和异常时间点。</p><h2 id="已有方法">已有方法</h2><p>如表1中所示，目前已有的解决方法主要是利用微服务之间的故障传播关系（cross），通常分为两个阶段：</p><ol type="1"><li>构造依赖关系（relationship learning）：适用pc算法学习微服务之间依赖关系，或者采用系统工具获取依赖关系</li><li>推断根因（rcf）：通过随机游走等基于相关性的方法推断根本原因。</li></ol><figure><img src="./image-20200622133032479.png" alt="表1：微服务系统中已有解决方法" /><figcaption aria-hidden="true">表1：微服务系统中已有解决方法</figcaption></figure><h2 id="研究挑战">研究挑战</h2><p>针对本问题的研究，主要有以下两个挑战：</p><h3 id="挑战一没有现成的方法学习时序间的因果关系">挑战一：没有现成的方法学习时序间的因果关系</h3><p>总结一下：已有的pc算法是基于iid的假设，不能捕捉延迟的因果关系，所以不适合指标因果图构建。</p><p>已有的方法，要解决的问题比较简单，即只用分析微服务间的因果关系，相应的解决方案要么通过系统工具获取依赖关系，要么通过pc算法学习因果关系。</p><p>但是现在，要解决的为问题更有挑战性，除了微服务之间的因果，还想知道一个微服务的指标之间的因果。 所以，提出了一种PC加强版因果挖掘的方法--PCTS。</p><p>PC算法假设不同时刻，指标之间的因果关系是独立的， 以下图为例，PC算法假设17：17和17：18之间，4个指标的因果关系是独立</p><p>但是，时序不是符合这个假设的，经常会有时间差， 以下图为例，如17:17分Web QPS会影响17:18的Web RT</p><p><img src="./img.png" alt="图3：四个时间序列的因果关系图" /> 图中的每一个节点代表了时间序列的某一个时间点，两个节点之间的箭头，标明了两个时间点的数据之间的因果关系</p><p>所以PC算法，学习不到延迟的因果关系</p><h3 id="挑战二因果推断还要考虑指标本身含义">挑战二：因果推断还要考虑指标本身含义</h3><p>做因果推断，除了从数据出发，考虑指标异常相关性，还要考虑指标本身的含义。同一类别指标比不同类别的相关更强。</p><p>现在看一个不失一般性的故障案例：web请求次数过多导致的的响应时间变长</p><figure><img src="./image-20200622132951991.png" alt="图2：Discount Coupon微服务的实现细节" /><figcaption aria-hidden="true">图2：Discount Coupon微服务的实现细节</figcaption></figure><p>以图2为例， 从数据上看，微服务的KPI异常了，也就是Web RT异常了。</p><p>现在把上下游的metric全部load过来， 使用随机游走的方法，分析到的根因是Middleware1 Consumer RT。</p><p><img src="./img_1.png" alt="图4：微服务中的4个监控指标" /> 其中Web RT是KPI，Web QPS, Middleware1 Consumer RT和JVM FGC Time是metrics。</p><p>但实际上，对这个故障实例，根本原因应是上游组件的指标Web QPS。</p><p>随机游走的视野太狭隘了，还应该考虑指标本身含义，同一类别指标比不同类别的相关更强。 也就是说Web RT和Web QPS的相关性更强，和Middleware1 Consumer RT的相关性更弱</p><h2 id="架构设计">架构设计</h2><p>MicroCause的架构图如下（图5），</p><figure><img src="./image-20200622134206479.png" alt="图5:MicroCause架构图" /><figcaption aria-hidden="true">图5:MicroCause架构图</figcaption></figure><ul><li>stage1-指标监控：当KPI异常时，MicroCause将被激活，将故障前数小时的监控指标将用作MicroCause的输入。</li><li>stage2-构建因果图：生成故障因果图&amp;异常检测，可并行<ul><li>使用PCTS算法，从故障kpi和相关指标学习出该故障的故障因果图，</li><li>将故障前数小时的监控指标对metrics做异常检测，并生成异常事件序列。</li></ul></li><li>stage3-因果推断：使用TCORW，输出N个可能的根原。</li></ul><h3 id="故障因果图学习">故障因果图学习</h3><p>针对挑战一，使用PCTS算法学习基于指标的故障因果图。该算法算法分为两步:</p><ol type="1"><li><p>第一步，得到每个时刻指标之间的因果图<span class="math inline">\(G_C\)</span>，基于PC算法的改进，该算法用于学习时间序列的因果图。该算法的结果如图3所示。但是由于我们需要利用指标之间的因果关系进行根因定位，我们对于改进的PC算法的结果进行了调整。 <img src="./img.png" alt="图3：四个时间序列的因果关系图- G_C" /></p></li><li><p>第二步，将<span class="math inline">\(G_C\)</span>转化为节点为指标的因果图<span class="math inline">\(G_{FCG}\)</span>，这样才能做根因定位。理论上，如果<span class="math inline">\(G_C\)</span>中时序A和时序B的时间点中存在一条边，那么<span class="math inline">\(G_{FCG}\)</span>中, 时列A到时序B就有一条边。</p><figure><img src="./image-20200622140031849.png" alt="图8：针对故障实例A,基于PCTS算法生成的因果图" /><figcaption aria-hidden="true">图8：针对故障实例A,基于PCTS算法生成的因果图</figcaption></figure><figure><img src="./image-20200622135001778.png" alt="图6：四个指标间的故障因果图-G_FCG" /><figcaption aria-hidden="true">图6：四个指标间的故障因果图-G_FCG</figcaption></figure></li></ol><h3 id="异常检测">异常检测</h3><p>由于需要对KPI和指标进行异常检测，这里采用的方法是SPOT，可以检测徒增突降。</p><p><span class="math display">\[\eta_{\max}^{i}=\max _{k \in O} \frac{| M_{k}^{i}-\phi_{M_{k}^{i}}|}{\phi_{M^{i}}}\]</span></p><p>其中是时间序列 在时刻的值，是时间序列 在时刻SPOT拟合的阈值。</p><h3 id="面向时间因果的随机游走tcorw">面向时间因果的随机游走(TCORW)</h3><p>总结一下 先构建一个指标(潜在根因得分) = 随机游走的根因概率 + 指标的异常程度 相关指标分为3层，每一层找出top2的两个指标，一起得到6个 按照时间排序，得到前3个或者5个输出</p><p>TCORW算法主要分为三步：</p><ul><li>面向因果的随机游走，</li><li>潜在根因得分</li><li>根因排序</li></ul><h4 id="随机游走">随机游走</h4><p>这一步我们主要利用监控指标之间的因果关系进行分析。首先我们利用模块一中生成的故障因果图进行随机游走。不同于传统的随机游走算法，在此算法中，我们利用偏相关系数（Partial Correlation)来计算转移概率矩阵。与Pearson相关性不同的是，和异常KPI因果性更强的metric指标将具有更高的偏相关系数，而Pearson相关性更注重两个指标之间的相关性。因此和异常KPI因果性更强的metric将在随机游走中获得更高的访问次数。</p><h4 id="潜在根因得分">潜在根因得分</h4><p>这一步中我们利用，随机游走的结果和指标的异常程度对于异常的metric计算潜在根因得分，计算方式如下所示：</p><p><span class="math display">\[\gamma_{i}=\lambda \bar{c}_{i}+(1-\lambda) \bar{\eta}_{\max }^{i}\]</span></p><p>其中是归一化后的随机游走访问次数，是归一化后的异常程度，作为参数，将用于控制着两部分的贡献比例。</p><h4 id="根因排序">根因排序</h4><p>在这一步中，我们首先利用指标间可能的故障传播关系，将指标分为三个级别Level1，Level2，Level3。</p><p>如表2所示，当Level1和Level2中的指标同时发生异常时，我们认为Level1中的指标更有可能是根因。</p><figure><img src="./image-20200622135235013.png" alt="表2：指标分级" /><figcaption aria-hidden="true">表2：指标分级</figcaption></figure><p>基于指标分级信息，指标的异常时间和指标的潜在异常得分我们设计了如下算法给出最后的根因排序。 <img src="./image-20200622135254320.png" /></p><h2 id="数据集和评估指标">数据集和评估指标</h2><p>在此工作中，从2019年9月份到2020年1月份，我们一直某大型在线购物平台中监控超过400种微服务状态。我们收集了86**个真实的在线故障实例作为评估数据集。根据过去的根因分析工作，我们使用AC@k和avg<span class="citation" data-cites="k评估算法给出的Top">@k评估算法给出的Top</span> K个根因的准确性。</p><p><span class="math display">\[ AC@ k=\frac{1}{|A|} \sum_{a \in A}\frac{\sum_{i&lt; k} R^{a}[i] \in V_{r c}^{a}}{\min (k,|\mathrm{V^a}|)} \]</span></p><p><span class="math display">\[A v g @ k=\frac{1}{k} \sum_{1 \leq j \leq k} A C @ j\]</span></p><h2 id="案例分析">案例分析</h2><p>CauseInfer[INFOCOM14]中提到，使用PC算法来学习基于时间序列的因果图时容易生成的孤立子图。在那篇论文中，作者使用领域知识来弥补这一缺陷。 在我们的工作中，同样观察到了这种现象。从图7中，由PC生成的因果图可以看出，异常KPI与根因之间没有路径。</p><p><img src="./image-20200622140008064.png" /> 图7：针对故障实例A,基于PC算法生成的因果图</p><p>但是PCTS可解决这个问题，因为它可以表达时序之间的延迟因果关系（图8）。</p><figure><img src="./image-20200622140031849.png" alt="图8：针对故障实例A,基于PCTS算法生成的因果图" /><figcaption aria-hidden="true">图8：针对故障实例A,基于PCTS算法生成的因果图</figcaption></figure><h2 id="参考">参考</h2><ol type="1"><li><a href="https://wemp.app/posts/6013f2da-c11a-4f6f-b393-2b631c45172a">清华阿里AIOps新作：基于因果分析的微服务内根因定位</a></li><li><a href="https://netman.aiops.org/wp-content/uploads/2020/06/%E5%AD%9F%E5%AA%9B.pdf">causeinfer--paper</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-0-summary/&quot;&gt;chapter0 概览&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-1-event-generate/&quot;&gt;chapter1 故障发现&lt;/a&gt;
&lt;</summary>
      
    
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/categories/AIOps/"/>
    
    
    <category term="图数据" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE/"/>
    
    <category term="因果推断" scheme="https://chiechie.github.io/tags/%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD/"/>
    
    <category term="因果分析" scheme="https://chiechie.github.io/tags/%E5%9B%A0%E6%9E%9C%E5%88%86%E6%9E%90/"/>
    
    <category term="根因分析" scheme="https://chiechie.github.io/tags/%E6%A0%B9%E5%9B%A0%E5%88%86%E6%9E%90/"/>
    
    <category term="AIOps" scheme="https://chiechie.github.io/tags/AIOps/"/>
    
    <category term="微服务" scheme="https://chiechie.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>chapter1.4 指标异常关联</title>
    <link href="https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-1_4-kpi-correlation/"/>
    <id>https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-1_4-kpi-correlation/</id>
    <published>2021-05-21T14:32:17.000Z</published>
    <updated>2021-06-02T09:43:09.266Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目录">目录</h1><ul><li><a href="../AIOps-0-summary/">chapter0 概览</a></li><li><a href="../AIOps-1-event-generate/">chapter1 故障发现</a><ul><li><a href="../AIOps-1_1-kpi-detector/">chapter1.1 单指标异常检测</a></li><li><a href="../AIOps-1_2-fault-prediction/">chapter1.3 故障预测</a></li><li><a href="../AIOps-1_4-kpi-correlation/">chapter1.4 指标异常关联</a></li><li><a href="../AIOps-1_5-log-analysis/">chapter1.5 日志聚类</a><ul><li><a href="../AIOps-1_5_1-log-analysis_logmine/">chapter1.5.1 使用logmine加强版做日志聚类</a></li><li><a href="../AIOps-1_5_2-log-analysis_meituan/">chapter1.5.2 美团日志聚类</a></li></ul></li></ul></li><li><a href="../AIOps-2-event-analysis/">chapter2 故障定位</a><ul><li><a href="../AIOps-2_1-topo-rca/">chapter2.1 微服务系统的故障定位</a><ul><li><a href="../AIOps-2_1_1-topo-rca-causeinfer-notes1/">chapter2.1.1 CauseInfer1</a></li><li><a href="../AIOps-2_1_2-topo-rca-causeinfer-notes2/">chapter2.1.2 CauseInfer2</a></li><li><a href="../AIOps-2_1_3-topo-rca-aiops2020/">chapter2.1.3 AIOps挑战赛2020-获奖方案分享</a></li><li><a href="../AIOps-2_1_4-topo-rca-aiops2021/">chapter2.1.4 AIOps挑战赛2021-demo方案</a></li><li><a href="../AIOps-2_1_5-topo-rca-cnsoftbei2020/">chapter2.1.5 N-Softbei2020比赛</a></li><li><a href="../AIOps-2_1_6-topo-rca-MicroCause">chapter2.1.6 MicroCause</a></li></ul></li><li><a href="../AIOps-2_2-multi-dimensional-rca/">chapter2.2 多维下钻根因定位</a></li><li><a href="../AIOps-2_3-trace_rca/">chapter2.3 调用链根因分析</a></li><li><a href="../AIOps-2_4-metric_event_correlation/">chapter2.4 时间序列关联性分析</a></li></ul></li><li>chapter3 故障恢复</li></ul><blockquote><p>CoFlux挖掘KPI之间的异常波动关联, 是清华和阿里巴巴公司的合作成果。</p><p>波动关联关系结果结果可应用于：报警压缩、推荐TOP-N的可能原因、构建异常波动传播链。</p></blockquote><h1 id="问题描述">问题描述</h1><p>在实际的运维管理工作中，当服务发生故障时，与故障原因相关的许多KPI数据也会出波动。如果可以自动挖掘KPI之间的异常波动关系，就可以帮助运维进行更加高效地排查故障。</p><p>CoFlux的目的是挖掘两个KPI之间的波动关联关系，这种关系包括三个具体问题： 1. 两个KPI的波动是否相关？如果相关， 2. 波动的先后顺序如何（同时发生或者某根曲线的波动先发生）？ 3. 波动的方向是否一致（波动方向一致或者相反）？</p><h1 id="方案介绍">方案介绍</h1><h2 id="符号说明">符号说明</h2><ul><li><span class="math inline">\(S = [s_1, s_2,…, s_m]\)</span>：表示对于一个时间序列S，<span class="math inline">\(s_i\)</span>是KPI S在时刻i的数据，m是KPI的长度。</li><li><span class="math inline">\(P = [p_1, p_2, …, p_m]\)</span>：表示KPI S的预测序列，<span class="math inline">\(p_i\)</span>是<span class="math inline">\(s_i\)</span>的预测值。</li><li><span class="math inline">\(F = [f_1, f_2, …, f_m]\)</span>：表示预测残差序列，<span class="math inline">\(f_i = s_i – *p_i\)</span></li></ul><p>CoFlux使用KPI的预测误差序列来表示该KPI的波动特征。如果两个KPI的波动特征曲线相关（即波动同时发生或者发生时有一定的相位差），那么两个KPI的波动相关。</p><h2 id="难点">难点</h2><p>分析判断KPI的波动关联关系，主要的难点为，KPI曲线数据众多且曲线特征各异（例如不同的周期性、平稳性、趋势等），因此，没有通用的方法可以对所有的KPI进行波动特征提取。</p><h2 id="方法">方法</h2><p>CoFlux的输入是两根KPI曲线，输出结果是波动关联关系：两个KPI是否波动相关，如果相关，同时输出波动的先后顺序和波动的方向。</p><p>算法整体分为两个大的部分：特征工程和相关性计算。</p><figure><img src="img_1.png" alt="CoFlux架构" /><figcaption aria-hidden="true">CoFlux架构</figcaption></figure><h3 id="特征工程">特征工程</h3><p>特征工程主要包括两个步骤，特征提取、特征放大。</p><p>特征放大：一个KPI大部分时间范围内都是正常的，没有很大波动，只有随机的噪声。只有当服务受到影响时，才会产生波动。因此，波动的数量是远远小于正常数据的。为了削弱噪声的影响，我们采用改进版的激励函数：一个KPI的波动程度越大，波动特征也就会被放大的越大，这样就使得我们的波动特征更具区别度，对最后的相关性判断也更有帮助。</p><h3 id="相关性判断">相关性判断</h3><p>对两个KPI的波动特征进行相关性判断时，需要考虑到KPI波动的轻微形变以及相位差。因此，我们挑选Cross-Correlation来测量两个波动特征的相关性结果。</p><figure><img src="img_2.png" alt="相关性判断" /><figcaption aria-hidden="true">相关性判断</figcaption></figure><h3 id="应用实例">应用实例</h3><p>CoFlux的结果可以在以下三个方面助力故障排查：</p><ul><li>报警压缩：对于大量的KPI，我们首先利用CoFlux计算所有KPI的两两之间的波动相关程度，然后使用K-means进行聚类（K可以使用轮廓系数方法选择）。每一类内的KPI可以当成一个报警簇，在报警的时候当成一个整体进行报警。</li><li>推荐TOP N的可能原因：对于任一KPI X，通过CoFlux可找到该KPI的TOP N相关的KPI曲线。在进行故障排查时，运维人员可以优先检查这TOP N个指标。</li><li>构建异常波动传播链：我们可以利用KPI之间的波动传播关系来构建异常波动传播链，这个异常波动传播链可以反映不同KPI之间的波动是如何关联在一起的。相比较人工的方式，CoFlux在不需要专家领域知识的情况下可以自动准确的构建异常波动传播链。</li></ul><h1 id="参考">参考</h1><ol type="1"><li><a href="https://netman.aiops.org/wp-content/uploads/2019/05/CoFlux_camera-ready1.pdf">CoFlux英文paper</a></li><li><a href="https://mp.weixin.qq.com/s/SpiIquuz-8Ud_C3e4oVyaQ">CoFlux中文介绍</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;目录&quot;&gt;目录&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-0-summary/&quot;&gt;chapter0 概览&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-1-event-generate/&quot;&gt;chapter1 故障发现&lt;/a&gt;
&lt;</summary>
      
    
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/categories/AIOps/"/>
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/tags/AIOps/"/>
    
    <category term="异常检测" scheme="https://chiechie.github.io/tags/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"/>
    
    <category term="异常分类" scheme="https://chiechie.github.io/tags/%E5%BC%82%E5%B8%B8%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>chapter2.1.4 基于拓扑的根因定位-AIOps挑战赛2021-demo方案</title>
    <link href="https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-2_1_4-topo-rca-aiops2021/"/>
    <id>https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-2_1_4-topo-rca-aiops2021/</id>
    <published>2021-05-21T14:04:42.000Z</published>
    <updated>2021-06-02T09:43:09.257Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录">目录</h2><ul><li><a href="../AIOps-0-summary/">chapter0 概览</a></li><li><a href="../AIOps-1-event-generate/">chapter1 故障发现</a><ul><li><a href="../AIOps-1_1-kpi-detector/">chapter1.1 单指标异常检测</a></li><li><a href="../AIOps-1_2-fault-prediction/">chapter1.3 故障预测</a></li><li><a href="../AIOps-1_4-kpi-correlation/">chapter1.4 指标异常关联</a></li><li><a href="../AIOps-1_5-log-analysis/">chapter1.5 日志聚类</a><ul><li><a href="../AIOps-1_5_1-log-analysis_logmine/">chapter1.5.1 使用logmine加强版做日志聚类</a></li><li><a href="../AIOps-1_5_2-log-analysis_meituan/">chapter1.5.2 美团日志聚类</a></li></ul></li></ul></li><li><a href="../AIOps-2-event-analysis/">chapter2 故障定位</a><ul><li><a href="../AIOps-2_1-topo-rca/">chapter2.1 微服务系统的故障定位</a><ul><li><a href="../AIOps-2_1_1-topo-rca-causeinfer-notes1/">chapter2.1.1 CauseInfer1</a></li><li><a href="../AIOps-2_1_2-topo-rca-causeinfer-notes2/">chapter2.1.2 CauseInfer2</a></li><li><a href="../AIOps-2_1_3-topo-rca-aiops2020/">chapter2.1.3 AIOps挑战赛2020-获奖方案分享</a></li><li><a href="../AIOps-2_1_4-topo-rca-aiops2021/">chapter2.1.4 AIOps挑战赛2021-demo方案</a></li><li><a href="../AIOps-2_1_5-topo-rca-cnsoftbei2020/">chapter2.1.5 N-Softbei2020比赛</a></li><li><a href="../AIOps-2_1_6-topo-rca-MicroCause">chapter2.1.6 MicroCause</a></li></ul></li><li><a href="../AIOps-2_2-multi-dimensional-rca/">chapter2.2 多维下钻根因定位</a></li><li><a href="../AIOps-2_3-trace_rca/">chapter2.3 调用链根因分析</a></li><li><a href="../AIOps-2_4-metric_event_correlation/">chapter2.4 时间序列关联性分析</a></li></ul></li><li>chapter3 故障恢复</li></ul><h2 id="数据解析">数据解析</h2><p>比赛数据包括： 部署拓扑，指标数据，日志数据，调用链数据，故障标签</p><h3 id="部署数据">部署数据</h3><figure><img src="./bushu.png" alt="部署数据" /><figcaption aria-hidden="true">部署数据</figcaption></figure><h3 id="指标数据">指标数据</h3><p>指标数据包括业务指标 和 性能指标。 业务指标用于触发根因分析，性能指标用于局部的根因定位</p><p>每个指标数据，都需要附带的信息有：归属物理设备id，以及相应用id，（这样才能做机器的指标依赖的额故障定位）</p><h4 id="业务指标">业务指标</h4><p>kpi_0304.csv</p><ul><li>rr：单位%，系统响应率</li><li>sr：单位%，业务成功率</li><li>cnt：单位条，交易量</li><li>mrt：单位ms，平均响应时间</li><li>tc：交易码, 有11种应用, 'ServiceTest1', 'ServiceTest10', 'ServiceTest11', 'ServiceTest2', 'ServiceTest3', 'ServiceTest4', 'ServiceTest5', 'ServiceTest6', 'ServiceTest7', 'ServiceTest8', 'ServiceTest9'</li></ul><figure><img src="./yewu.png" alt="业务指标" /><figcaption aria-hidden="true">业务指标</figcaption></figure><h4 id="性能指标">性能指标</h4><p>每个应用的指标, 每个kpi会有一个对应的机器id（即cmdb_id）</p><ul><li>cmdb_id: 指标归属的物理设备, 每个物理设备上收集到的指标一般来说包括两种，「操作系统」性能指标以及「服务」性能指标。</li><li>kpi_name: 指标归属的服务类型，比如归属于操作系统/java虚拟机/Redis/Tomcat/Mysql等</li></ul><figure><img src="./xingneng.png" alt="性能指标" /><figcaption aria-hidden="true">性能指标</figcaption></figure><h3 id="日志数据">日志数据</h3><p>日志数据有3个重要字段：</p><ul><li>cmdb_id： 日志是从哪台物理机器上产生</li><li>log_name: 日志对应的组件名和日志类别, 相当于4个采集器，eg catalina/gc/localhost/localhost_access_log</li><li>value: 日志内容, 里面的信息包括，日志级别，egINFO/WARNING/SEVERE，具体报错信息</li></ul><p>目前只有Tomcat4台服务器有日志数据；并且根据采集的不同的组件，收集的日志。</p><h3 id="调用链数据">调用链数据</h3><p>调用链路数据来自：trace/trace_0304.csv</p><p>重要的字段有：</p><ul><li>cmdb_id: 即对应的服务是部署在哪个机器上的, 一次全局的trace_id 可能跨越几个设备</li><li>parent_id：子调用的上一次调用</li><li>trace_id：一次trace对应的全局id，一个trace包括多次子调用</li><li>span_id： 本流程的Span ID，</li></ul><figure><img src="./trace.png" alt="调用链" /><figcaption aria-hidden="true">调用链</figcaption></figure><h3 id="故障标签">故障标签</h3><p>故障类型可分为--'应用故障', '网络故障', '资源故障'</p><ul><li>应用故障可分为2类：'JVM CPU负载高', 'JVM OOM Heap'</li><li>网络故障可分为两类：'网络延迟', '网络隔离'</li><li>资源故障可分为三类：CPU使用率爬升，内存使用率过高，磁盘IO写使用率过高</li></ul><h2 id="demo方案">demo方案</h2><p>流程：</p><ol type="1"><li>对「业务指标」进行异常检测，异常则触发下面的诊断。</li><li>调用链异常检测和根因定位:「业务」指标异常了，定位是哪个中间件或者服务出现了异常，以及根因的那个服务。</li><li>对应机器的指标进行根因定位：定位到了调用链中的根因服务，然后对该服务所在的机器进行下钻分析，进行更细粒度的根因指标定位，使用到了机器和中间件的「性能指标」。</li></ol><h3 id="业务指标异常检测略">业务指标异常检测(略)</h3><p>找出第一个故障发生时刻：</p><ul><li>2021-03-04 08:39:00 - 2021-03-04 08:44:00</li></ul><h3 id="调用链异常检测和根因定位">调用链异常检测和根因定位</h3><ol type="1"><li>找出异常调用路径--trace_id</li><li>找出对应的根因的子调用--span_id</li><li>找到span_id的机器</li></ol><figure><img src="./trace_rca.png" alt="调用链异常检测和根因定位" /><figcaption aria-hidden="true">调用链异常检测和根因定位</figcaption></figure><h3 id="对定位到的机器进行指标根因分析">对定位到的机器进行指标根因分析</h3><ol type="1"><li>搜集该机器的所有性能指标，进行异常检测</li><li>对于异常的指标，根据历史数据中学习到的因果图，进行根因推断。</li></ol><figure><img src="./metric_rca.png" alt="指标根因分析" /><figcaption aria-hidden="true">指标根因分析</figcaption></figure><h3 id="对下-分析结果-和-标准答案">对下 分析结果 和 标准答案</h3><figure><img src="./evaluate.png" alt="对比" /><figcaption aria-hidden="true">对比</figcaption></figure><h2 id="参考资料">参考资料</h2><ol type="1"><li><a href="http://iops.ai/competition_detail/?competition_id=17&amp;flag=1">aiops挑战赛2021-官网</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-0-summary/&quot;&gt;chapter0 概览&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-1-event-generate/&quot;&gt;chapter1 故障发现&lt;/a&gt;
&lt;</summary>
      
    
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/categories/AIOps/"/>
    
    
    <category term="图数据" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE/"/>
    
    <category term="根因分析" scheme="https://chiechie.github.io/tags/%E6%A0%B9%E5%9B%A0%E5%88%86%E6%9E%90/"/>
    
    <category term="AIOps" scheme="https://chiechie.github.io/tags/AIOps/"/>
    
    <category term="微服务" scheme="https://chiechie.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>chapter1.5 日志聚类</title>
    <link href="https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-1_5-log-analysis/"/>
    <id>https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-1_5-log-analysis/</id>
    <published>2021-05-21T12:05:20.000Z</published>
    <updated>2021-06-02T09:43:09.302Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录">目录</h2><ul><li><a href="../AIOps-0-summary/">chapter0 概览</a></li><li><a href="../AIOps-1-event-generate/">chapter1 故障发现</a><ul><li><a href="../AIOps-1_1-kpi-detector/">chapter1.1 单指标异常检测</a></li><li><a href="../AIOps-1_2-fault-prediction/">chapter1.3 故障预测</a></li><li><a href="../AIOps-1_4-kpi-correlation/">chapter1.4 指标异常关联</a></li><li><a href="../AIOps-1_5-log-analysis/">chapter1.5 日志聚类</a><ul><li><a href="../AIOps-1_5_1-log-analysis_logmine/">chapter1.5.1 使用logmine加强版做日志聚类</a></li><li><a href="../AIOps-1_5_2-log-analysis_meituan/">chapter1.5.2 美团日志聚类</a></li></ul></li></ul></li><li><a href="../AIOps-2-event-analysis/">chapter2 故障定位</a><ul><li><a href="../AIOps-2_1-topo-rca/">chapter2.1 微服务系统的故障定位</a><ul><li><a href="../AIOps-2_1_1-topo-rca-causeinfer-notes1/">chapter2.1.1 CauseInfer1</a></li><li><a href="../AIOps-2_1_2-topo-rca-causeinfer-notes2/">chapter2.1.2 CauseInfer2</a></li><li><a href="../AIOps-2_1_3-topo-rca-aiops2020/">chapter2.1.3 AIOps挑战赛2020-获奖方案分享</a></li><li><a href="../AIOps-2_1_4-topo-rca-aiops2021/">chapter2.1.4 AIOps挑战赛2021-demo方案</a></li><li><a href="../AIOps-2_1_5-topo-rca-cnsoftbei2020/">chapter2.1.5 N-Softbei2020比赛</a></li><li><a href="../AIOps-2_1_6-topo-rca-MicroCause">chapter2.1.6 MicroCause</a></li></ul></li><li><a href="../AIOps-2_2-multi-dimensional-rca/">chapter2.2 多维下钻根因定位</a></li><li><a href="../AIOps-2_3-trace_rca/">chapter2.3 调用链根因分析</a></li><li><a href="../AIOps-2_4-metric_event_correlation/">chapter2.4 时间序列关联性分析</a></li></ul></li><li>chapter3 故障恢复</li></ul><h2 id="做项目之前的分析">做项目之前的分析</h2><p>系统出现故障时，运维人员一般先查看错误日志，定位故障原因。如果业务逻辑简单，故障时错误日志较少，运维人员一般一眼就能定位到问题。</p><p>但是，业务逻辑的复杂的情况下，比如系统依赖很多的服务，引入很多的组件时，一旦整个故障时（如触发Bug、依赖服务超时等等），错误日志急剧增加。如何能快速找到最关键的日志报错信息呢？ 可以对报警进行聚类，整理出报警摘要，有了摘要运维就可以对的故障有个大致印象，再结合业务知识定位故障的根原。</p><p>为了解决上面问题，下面介绍一种针对报警日志的聚类算法</p><p>最近要做一个nlp的项目，需求就是从一堆杂乱无章的日志中，发现一些规律。 看看哪些日志其实是在说一个事情，可归为一类；哪些日志暗示着新的事情在发生，就告警。</p><p>本质是一个EDA,有点类似给用户分群。跟用户分群相比，日志分析有一些特殊的需求，比如，我们通常先关注目前发生的事情严不严重，然后才关注细节。描述前者的典型字段包括时间，日志级别，其他关键词。描述后者的典型字段包括具体ip，网站，端口号等等。</p><p>对一段时间内的告警数据进行聚类，将具有相同根因的告警归纳为泛化报警（Generalized Alarms），最终形成仅有几条泛化报警的报警摘要。如下图1所示意。</p><figure><img src="https://p0.meituan.net/travelcube/0405c8ee9e4e3ea813eedf46c803101122272.png" alt="图1" /><figcaption aria-hidden="true">图1</figcaption></figure><p>图1</p><p>我们希望这些泛化报警既要具有很强的概括性，同时尽可能地保留细节。这样运维人员在收到报警时，便能快速定位到故障的大致方向，从而提高故障排查的效率。</p><h2 id="看看别人怎么做的">看看别人怎么做的</h2><h3 id="美团">美团</h3><h3 id="log3c">log3C</h3><p>《identifies service system problems from system logs》-log3C</p><ul><li>讲了通过数据挖掘-对纯文本进行分析的一种思路：原始日志--&gt;提取事件模版--&gt; 聚合成 时间戳 + session id的日志序列计数向量---&gt;聚类得到典型日志序列技术向量模式---&gt; 日志序列模式 和 系统状态（核心KPI 之间的关系）相关性分析</li><li>将相关性分析 应用到了 具有 物理依赖关系的 数据上面，可以得到 因果关系。</li><li>跟指标异常检测的思路不一样，这个不看日志中提取出来的数值指标，看的是日志间的序列关系，出现的先后顺序，更适合用来做辅助 系统的故障定位（复杂的网状调用调用链路），而前者更适合做系统的性能监控，需要人工定义感兴趣的测量方式（人工指定特征）。</li><li>跟日志异常检测相比，本文的应用更加的end2end。</li></ul><blockquote><p>实际中先不考虑这个方案，复杂且黑盒，不好调效果。</p></blockquote><h2 id="一些思考">一些思考</h2><ol type="1"><li><p>要不要用一些文本模型，比如word2vec，doc2vec，transformer，bert？</p><p>在当前日志的场景下，意义不大。 这些深度模型的本质是想将语义上的相似性通过embedding vector表达。 日志场景下，日志都是同一个print语句打出来的，可以看成是机器的语言，比较少有语言歧义（真的有这种近义词的，肯定不是一个组件打出来的日志），所以没必要去寻找语意上的相似性。 分词完之后，当成char就可以了。</p></li></ol><h2 id="参考资料">参考资料</h2><ol type="1"><li><a href="https://github.com/logpai/logparser/blob/master/logs/Apache/Apache_2k.log">apache_2k.log</a></li><li><a href="https://github.com/chiechie/LogRobot">关于logmine的改进版-code-chiechie</a></li><li><a href="../AIOps-1_5_1-log-analysis_logmine/">关于logmine的实践--chiechie's blog</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-0-summary/&quot;&gt;chapter0 概览&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-1-event-generate/&quot;&gt;chapter1 故障发现&lt;/a&gt;
&lt;</summary>
      
    
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/categories/AIOps/"/>
    
    
    <category term="NLP" scheme="https://chiechie.github.io/tags/NLP/"/>
    
    <category term="AIOps" scheme="https://chiechie.github.io/tags/AIOps/"/>
    
    <category term="日志分析" scheme="https://chiechie.github.io/tags/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>chapter2.4 时间序列关联性分析</title>
    <link href="https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-2_4-metric_event_correlation/"/>
    <id>https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-2_4-metric_event_correlation/</id>
    <published>2021-05-21T09:27:26.000Z</published>
    <updated>2021-06-02T09:43:09.280Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录">目录</h2><ul><li><a href="../AIOps-0-summary/">chapter0 概览</a></li><li><a href="../AIOps-1-event-generate/">chapter1 故障发现</a><ul><li><a href="../AIOps-1_1-kpi-detector/">chapter1.1 单指标异常检测</a></li><li><a href="../AIOps-1_2-fault-prediction/">chapter1.3 故障预测</a></li><li><a href="../AIOps-1_4-kpi-correlation/">chapter1.4 指标异常关联</a></li><li><a href="../AIOps-1_5-log-analysis/">chapter1.5 日志聚类</a><ul><li><a href="../AIOps-1_5_1-log-analysis_logmine/">chapter1.5.1 使用logmine加强版做日志聚类</a></li><li><a href="../AIOps-1_5_2-log-analysis_meituan/">chapter1.5.2 美团日志聚类</a></li></ul></li></ul></li><li><a href="../AIOps-2-event-analysis/">chapter2 故障定位</a><ul><li><a href="../AIOps-2_1-topo-rca/">chapter2.1 微服务系统的故障定位</a><ul><li><a href="../AIOps-2_1_1-topo-rca-causeinfer-notes1/">chapter2.1.1 CauseInfer1</a></li><li><a href="../AIOps-2_1_2-topo-rca-causeinfer-notes2/">chapter2.1.2 CauseInfer2</a></li><li><a href="../AIOps-2_1_3-topo-rca-aiops2020/">chapter2.1.3 AIOps挑战赛2020-获奖方案分享</a></li><li><a href="../AIOps-2_1_4-topo-rca-aiops2021/">chapter2.1.4 AIOps挑战赛2021-demo方案</a></li><li><a href="../AIOps-2_1_5-topo-rca-cnsoftbei2020/">chapter2.1.5 N-Softbei2020比赛</a></li><li><a href="../AIOps-2_1_6-topo-rca-MicroCause">chapter2.1.6 MicroCause</a></li></ul></li><li><a href="../AIOps-2_2-multi-dimensional-rca/">chapter2.2 多维下钻根因定位</a></li><li><a href="../AIOps-2_3-trace_rca/">chapter2.3 调用链根因分析</a></li><li><a href="../AIOps-2_4-metric_event_correlation/">chapter2.4 时间序列关联性分析</a></li></ul></li><li>chapter3 故障恢复</li></ul><blockquote><p>performance counter： 性能监视器</p></blockquote><h2 id="背景">背景</h2><p>为了保证产品的服务质量、减少服务宕机时间，从而避免更大的经济损失，对关键的服务事件的诊断显得尤为重要。实际的运维工作中，对服务事件进行诊断时，运维人员可以通过分析与服务事件相关的时序数据，来对事件发生的原因进行分析。虽然这个相关关系不能完全准确的反映真实的因果关系，但是仍然可以为诊断提供一些很好的线索和启发。</p><ul><li><p>如下图， 两个事件：程序A启动和程序B启动，一个时序：cpu使用率。 可以看到，事件（程序A的运行）与时序（CPU使用率）存在相关关系，并且程序A启动会导致CPU使用率升高，记为A-&gt;cpu上升。</p><p><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2FMjzFINogsh.png?alt=media&amp;token=9002fb74-9363-4a57-a182-fac68f04bd60" /></p></li></ul><p>希望能使用数据驱动的方法，找到类似的相关组合，也就是&lt;事件, 指标&gt;对，例如A-&gt;cpu上升，</p><h2 id="基本概念">基本概念</h2><ul><li>时间序列（metric）： 通常有固定的时间间隔，例如CPU使用率等；指标数据( Metrics Data )：描述具体某个对象某个时间点， CPU 百分比等等，指标数据等等。</li><li>事件（event）：就是一个正常的操作比如程序A的启动，这个是需要运维指定的 他感兴趣的某个日志模版。 比如“Out of memory” /启动某个磁盘intensive程序/ 启动某个cpu intensive程序/query-time out alerts/某个告警，类似log3C的日志pattern，big pandas 的变更事件。event报告告警和日志。</li><li>日志(logging)：例如有个应用出错，抛出了NullPointerExcepction。</li><li>事件序列（event sequence）：记录了特定事件发生的序列。</li><li>故障（incident）：故障定位，就是要找到这个故障的根因。 （感觉也能跟BigPanda的告警关联之后的结果 对应起来），</li></ul><h2 id="总结">总结</h2><ul><li>这篇文章主要是解决的什么问题？找到事件（E，event）和指标（S，metric）的相关性。</li><li>具体的思路？将这个问题转换为统计中的两样本问题，并且使用邻近算法判断相关性。</li><li>难点是什么？异构数据 + 异常关联性，异构指的是文本+时序，异常关联性，指的是，只关心事件和指标异常时刻的相关性。</li><li>用的什么分析方法？还可以应用到哪些领域？ 用2-sample解决event 和 指标 之间的关联关系，可推广到所有离散变量的相关性分析中。</li><li>这篇文章没有解决的问题是？这些问题有什么解决方法？ 本文还是比较学术派，只是给了一个 分析指标 和 事件 的相关性 方法，至于怎么从众多原始日志和告警中得到事件，以及分析出来的相关性怎么应用到故障定位上面去，没有说。但是这两步 对于实际应用来说 是必不可少的。</li><li>BigPandas将众多告警基于业务关系（拓扑数据）收敛成incident，然后将incident跟变更事件进行关联，得到的变更事件就是root cause</li></ul><h3 id="技术细节">技术细节</h3><p>要解决两个问题：</p><ol type="1"><li>确定指标和事件的因果关系，即事件A--&gt;指标1：两个随机分布的相似性指标</li><li>确定因果关系中指标的单调性，即事件A--&gt;指标1上升：判断两个随机变量的大小关系的指标</li></ol><p>都是统计中的假设检验的方法。</p><p>判断方向可以转化为以下问题：</p><ol type="1"><li>判断事件发生前的 一段序列 跟 整个时序的相似性。如果差异大，说明指标 --&gt; event</li><li>判断事件发生后的 一段序列 跟 整个时序的相似性。如果差异大，说明event --&gt; 指标</li></ol><p>判断单调性，是这么做的：</p><ol type="1"><li><p>计算event前后，2个子序列的 均值的差 <span class="math display">\[ t_{s c o r e}=\frac{\mu_{\Gamma^{f r o n t}}-\mu_{\Gamma^{r e a r}}}{\sqrt{\frac{\sigma_{\Gamma^{f} r o n t}^{2}+\sigma_{\Gamma^{r e a r}}^{2}}{n}}} \]</span></p></li><li><p>判断单调性：</p></li></ol><ul><li><p>如果<span class="math inline">\(t_{score} &gt; \alpha\)</span>, 得到负的单调性，即 <img src="./img.png" /></p></li><li><p>如果<span class="math inline">\(t_{score} &lt; -\alpha\)</span>, 得到正的单调性。</p><p>这里P=0.025对应<span class="math inline">\(\alpha=1.96\)</span>，P=0.001对应<span class="math inline">\(\alpha=2.58\)</span></p></li></ul><h3 id="实验">实验</h3><ul><li><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2FGkHOys2alH.png?alt=media&amp;token=95dde9c8-0249-4033-a027-83bca9a543ff" /></li><li><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2Fy5QnzhCHAl.png?alt=media&amp;token=13774051-eb1f-4ada-a978-9cd7d2bee748" /></li></ul><h2 id="参考">参考</h2><ol type="1"><li><a href="http://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/SIGKDD-2014-Correlating-Events-with-Time-Series-for-Incident-Diagnosis.pdf">微软-指标与事件的关联分析paper</a></li><li><a href="https://github.com/jixinpu/aiopstools/tree/master/aiopstools/association_analysis">关联分析code</a>:</li><li><a href="https://mp.weixin.qq.com/s/-NMwaCD4Kzkt4BTnr5JKDQ">智能运维前沿-微软AIOps工作：时序数据与事件的关联分析</a></li><li>H. B. Mann， On a test of whether one of two random variables is stochastically larger than the other. The annals of mathematical statistics, 1947.</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-0-summary/&quot;&gt;chapter0 概览&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-1-event-generate/&quot;&gt;chapter1 故障发现&lt;/a&gt;
&lt;</summary>
      
    
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/categories/AIOps/"/>
    
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="时间序列" scheme="https://chiechie.github.io/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
    <category term="论文笔记" scheme="https://chiechie.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    <category term="预测" scheme="https://chiechie.github.io/tags/%E9%A2%84%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>chapter2.3 调用链根因分析</title>
    <link href="https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-2_3-trace_rca/"/>
    <id>https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-2_3-trace_rca/</id>
    <published>2021-05-21T08:49:19.000Z</published>
    <updated>2021-06-02T09:43:09.271Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录">目录</h2><ul><li><a href="../AIOps-0-summary/">chapter0 概览</a></li><li><a href="../AIOps-1-event-generate/">chapter1 故障发现</a><ul><li><a href="../AIOps-1_1-kpi-detector/">chapter1.1 单指标异常检测</a></li><li><a href="../AIOps-1_2-fault-prediction/">chapter1.3 故障预测</a></li><li><a href="../AIOps-1_4-kpi-correlation/">chapter1.4 指标异常关联</a></li><li><a href="../AIOps-1_5-log-analysis/">chapter1.5 日志聚类</a><ul><li><a href="../AIOps-1_5_1-log-analysis_logmine/">chapter1.5.1 使用logmine加强版做日志聚类</a></li><li><a href="../AIOps-1_5_2-log-analysis_meituan/">chapter1.5.2 美团日志聚类</a></li></ul></li></ul></li><li><a href="../AIOps-2-event-analysis/">chapter2 故障定位</a><ul><li><a href="../AIOps-2_1-topo-rca/">chapter2.1 微服务系统的故障定位</a><ul><li><a href="../AIOps-2_1_1-topo-rca-causeinfer-notes1/">chapter2.1.1 CauseInfer1</a></li><li><a href="../AIOps-2_1_2-topo-rca-causeinfer-notes2/">chapter2.1.2 CauseInfer2</a></li><li><a href="../AIOps-2_1_3-topo-rca-aiops2020/">chapter2.1.3 AIOps挑战赛2020-获奖方案分享</a></li><li><a href="../AIOps-2_1_4-topo-rca-aiops2021/">chapter2.1.4 AIOps挑战赛2021-demo方案</a></li><li><a href="../AIOps-2_1_5-topo-rca-cnsoftbei2020/">chapter2.1.5 N-Softbei2020比赛</a></li><li><a href="../AIOps-2_1_6-topo-rca-MicroCause">chapter2.1.6 MicroCause</a></li></ul></li><li><a href="../AIOps-2_2-multi-dimensional-rca/">chapter2.2 多维下钻根因定位</a></li><li><a href="../AIOps-2_3-trace_rca/">chapter2.3 调用链根因分析</a></li><li><a href="../AIOps-2_4-metric_event_correlation/">chapter2.4 时间序列关联性分析</a></li></ul></li><li>chapter3 故障恢复</li></ul><h2 id="调用链的数据格式">调用链的数据格式</h2><ul><li>做调用链路分析（TraceAnomaly）用到了耗时，以及调用链的结构信息。</li><li>2021AIOps比赛的调用链的数据：每个span_id表示一个trace中的一次子调用，耗时表示当前服务从接受call，到开始response的时间间隔。这里的表格信息量很少，它不知道每次子调用，具体是那个应用在调用，也不知道此次子调用之前，该trace已经走过了哪些调用路径了。</li></ul><h2 id="代码">代码</h2><p>放这里: https://github.com/chiechie/TraceAnomaly</p><h2 id="参考资料">参考资料</h2><ol type="1"><li><a href="https://mp.weixin.qq.com/s/sqYIb6i9z6xF5nDr8fuVsA">清华微众AIOps新作:基于深度学习的调用轨迹异常检测算法 -微信公众号</a></li><li><a href="https://chiechie.github.io/2021/03/09/AI/AIOps/AIOps-2_1_4-topo-rca-aiops2021/">chapter2.1.4 AIOps挑战赛2021-demo方案</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-0-summary/&quot;&gt;chapter0 概览&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-1-event-generate/&quot;&gt;chapter1 故障发现&lt;/a&gt;
&lt;</summary>
      
    
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/categories/AIOps/"/>
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/tags/AIOps/"/>
    
    <category term="调用链" scheme="https://chiechie.github.io/tags/%E8%B0%83%E7%94%A8%E9%93%BE/"/>
    
  </entry>
  
  <entry>
    <title>chapter1.1 单指标异常检测</title>
    <link href="https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-1_1-kpi-detector/"/>
    <id>https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-1_1-kpi-detector/</id>
    <published>2021-05-21T08:37:13.000Z</published>
    <updated>2021-06-02T09:43:09.231Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目录">目录</h1><ul><li><a href="../AIOps-0-summary/">chapter0 概览</a></li><li><a href="../AIOps-1-event-generate/">chapter1 故障发现</a><ul><li><a href="../AIOps-1_1-kpi-detector/">chapter1.1 单指标异常检测</a></li><li><a href="../AIOps-1_2-fault-prediction/">chapter1.3 故障预测</a></li><li><a href="../AIOps-1_4-kpi-correlation/">chapter1.4 指标异常关联</a></li><li><a href="../AIOps-1_5-log-analysis/">chapter1.5 日志聚类</a><ul><li><a href="../AIOps-1_5_1-log-analysis_logmine/">chapter1.5.1 使用logmine加强版做日志聚类</a></li><li><a href="../AIOps-1_5_2-log-analysis_meituan/">chapter1.5.2 美团日志聚类</a></li></ul></li></ul></li><li><a href="../AIOps-2-event-analysis/">chapter2 故障定位</a><ul><li><a href="../AIOps-2_1-topo-rca/">chapter2.1 微服务系统的故障定位</a><ul><li><a href="../AIOps-2_1_1-topo-rca-causeinfer-notes1/">chapter2.1.1 CauseInfer1</a></li><li><a href="../AIOps-2_1_2-topo-rca-causeinfer-notes2/">chapter2.1.2 CauseInfer2</a></li><li><a href="../AIOps-2_1_3-topo-rca-aiops2020/">chapter2.1.3 AIOps挑战赛2020-获奖方案分享</a></li><li><a href="../AIOps-2_1_4-topo-rca-aiops2021/">chapter2.1.4 AIOps挑战赛2021-demo方案</a></li><li><a href="../AIOps-2_1_5-topo-rca-cnsoftbei2020/">chapter2.1.5 N-Softbei2020比赛</a></li><li><a href="../AIOps-2_1_6-topo-rca-MicroCause">chapter2.1.6 MicroCause</a></li></ul></li><li><a href="../AIOps-2_2-multi-dimensional-rca/">chapter2.2 多维下钻根因定位</a></li><li><a href="../AIOps-2_3-trace_rca/">chapter2.3 调用链根因分析</a></li><li><a href="../AIOps-2_4-metric_event_correlation/">chapter2.4 时间序列关联性分析</a></li></ul></li><li>chapter3 故障恢复</li></ul><h1 id="异常检测背景">异常检测背景</h1><p>运维场景的指标监控就是对时序数据做异常检测。但是，很难通过构建一个异常检测策略一劳永逸搞定所有监控需求。因为异常各异，监控指标各异（正常模式各异）。</p><p>先看一下异常有哪些。</p><h2 id="异常分类">异常分类</h2><p>有几类异常：全局异常，条件异常，联合异常</p><ul><li><p>全局异常点：单个点跟历史所有的数据点比，差异很大，有点像黑天鹅事件。 <img src="./global_anomalie.png" /></p></li><li><p>条件异常： 条件异常(contextual or conditional anomalies)：即相对异常，跟剩下的数据点比比较异常。举个例子：</p><ol type="1"><li>我们办公室出现了一个穿西装打领带的人，会很引人注目。但是放到另外一个context中，比如房屋中介行业很正常。</li><li>凌晨销量突然升高 <img src="./img.png" /></li></ol></li><li><p>联合异常：单个点不异常，但是群体表现出某种特殊模式，就可疑了，例如，一个小区中，有人去医院很正常，但是整个小区的人同时去医院就不正常了。 <img src="./img78.png" alt="img.png" /></p></li></ul><h1 id="异常检测方案">异常检测方案</h1><p>时序异常检测原理，由于异常的判断依据是context，所以如何表达context信息是一个重点：</p><h2 id="曲线分类-异常检测">曲线分类 + 异常检测</h2><p>如何构建曲线类型特征？</p><ol type="1"><li>周期性： autocorrelation</li><li>周期offset：高斯核函数拟合分布极值</li><li>趋势判断：指数滑动平均</li><li>分析数据极值: 假设检验。</li></ol><h2 id="不同的检测策略">不同的检测策略</h2><p>针对不同的业务需求，构建检测策略。</p><p>一般来说，突变点检测+上升下降屏蔽+时间收敛的策略已经可以覆盖80%的检测指标了。</p><p>对于特别重要的指标-业务核心KPI，还是有必要手动配置的。</p><table><thead><tr class="header"><th>案例</th><th>指标</th><th>策略</th></tr></thead><tbody><tr class="odd"><td>历史数据有中断</td><td>在线数据或者其他数据，入库失败</td><td>先使用基于插值的方法填充后再检测。</td></tr><tr class="even"><td>趋势漂移是正常模式</td><td>游戏收入在开学季趋势漂移[1]</td><td>学习并且剔除这个趋势漂移，检测残差。</td></tr><tr class="odd"><td>周期性有数据</td><td>定时任务日志数；礼包成交数量[2]</td><td>检测规律行为数据缺失</td></tr><tr class="even"><td>合理范围的突变异常</td><td>登录在线等周期性曲线</td><td>检测突变点</td></tr><tr class="odd"><td>历史数据无规律</td><td>刚上线的游戏和测试服</td><td>相对历史分布的极端异常值。</td></tr><tr class="even"><td>周期性毛刺点</td><td>由于数据质量导致的监控指标周期性毛刺，并且间隔不固定</td><td>先剔除极值再检测</td></tr><tr class="odd"><td>周期性陡增/降[3]</td><td>业务活动特性导致</td><td>1.按时间收敛；2. 模式识别[4]:</td></tr><tr class="even"><td>无历史数据</td><td>新接业务</td><td></td></tr><tr class="odd"><td>历史数据无异常</td><td>新接业务</td><td>无监督</td></tr><tr class="even"><td>不同业务曲线对告警的敏感度不一样</td><td>在线和cpu</td><td>敏感度</td></tr></tbody></table><ul><li>[1]游戏收入在开学季趋势漂移: 进入开学季之后会，游戏在线人数持续走低，业务觉得正常，但是一般算法会告警</li><li>[2]礼包成交数据，礼包只在周末某个固定时间段上架。</li><li>[3]周期性凸起：定时启动任务导致日志数指标定时凸起，业务觉得正常，但是一般算法会告警</li><li>[4]模式识别： 1. 使用dtw衡量两个窗口的距离，兼容偏差； 2 在历史数据中使用滚动窗口的方法，找到一个最近的窗口。</li></ul><h1 id="产品运营">产品运营</h1><p>用户在使用模型服务过程中的疑问</p><ul><li>为什么告警？<ul><li>在模型输出的时候，把特征也带上</li><li>模型开发者需要在输出中加入告警描述字段</li><li>可视化saas，对告警的决策逻辑进行解释，eg上下界</li></ul></li><li>屏蔽周期性的告警/敏感度不一样<ul><li>生成配置，让用户调</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;目录&quot;&gt;目录&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-0-summary/&quot;&gt;chapter0 概览&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-1-event-generate/&quot;&gt;chapter1 故障发现&lt;/a&gt;
&lt;</summary>
      
    
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/categories/AIOps/"/>
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/tags/AIOps/"/>
    
    <category term="异常检测" scheme="https://chiechie.github.io/tags/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"/>
    
    <category term="异常分类" scheme="https://chiechie.github.io/tags/%E5%BC%82%E5%B8%B8%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>chapter1.1 使用GAN做异常检测</title>
    <link href="https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-1_1_1-GAN/"/>
    <id>https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-1_1_1-GAN/</id>
    <published>2021-05-21T08:37:13.000Z</published>
    <updated>2021-06-02T09:43:09.311Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录">目录</h2><ul><li><a href="../AIOps-0-summary/">chapter0 概览</a></li><li><a href="../AIOps-1-event-generate/">chapter1 故障发现</a><ul><li><a href="../AIOps-1_1-kpi-detector/">chapter1.1 单指标异常检测</a></li><li><a href="../AIOps-1_2-fault-prediction/">chapter1.3 故障预测</a></li><li><a href="../AIOps-1_4-kpi-correlation/">chapter1.4 指标异常关联</a></li><li><a href="../AIOps-1_5-log-analysis/">chapter1.5 日志聚类</a><ul><li><a href="../AIOps-1_5_1-log-analysis_logmine/">chapter1.5.1 使用logmine加强版做日志聚类</a></li><li><a href="../AIOps-1_5_2-log-analysis_meituan/">chapter1.5.2 美团日志聚类</a></li></ul></li></ul></li><li><a href="../AIOps-2-event-analysis/">chapter2 故障定位</a><ul><li><a href="../AIOps-2_1-topo-rca/">chapter2.1 微服务系统的故障定位</a><ul><li><a href="../AIOps-2_1_1-topo-rca-causeinfer-notes1/">chapter2.1.1 CauseInfer1</a></li><li><a href="../AIOps-2_1_2-topo-rca-causeinfer-notes2/">chapter2.1.2 CauseInfer2</a></li><li><a href="../AIOps-2_1_3-topo-rca-aiops2020/">chapter2.1.3 AIOps挑战赛2020-获奖方案分享</a></li><li><a href="../AIOps-2_1_4-topo-rca-aiops2021/">chapter2.1.4 AIOps挑战赛2021-demo方案</a></li><li><a href="../AIOps-2_1_5-topo-rca-cnsoftbei2020/">chapter2.1.5 N-Softbei2020比赛</a></li><li><a href="../AIOps-2_1_6-topo-rca-MicroCause">chapter2.1.6 MicroCause</a></li></ul></li><li><a href="../AIOps-2_2-multi-dimensional-rca/">chapter2.2 多维下钻根因定位</a></li><li><a href="../AIOps-2_3-trace_rca/">chapter2.3 调用链根因分析</a></li><li><a href="../AIOps-2_4-metric_event_correlation/">chapter2.4 时间序列关联性分析</a></li></ul></li><li>chapter3 故障恢复</li></ul><blockquote><p>使用gnn做异常检测</p></blockquote><h1 id="不仅仅生成图片用gan做无监督的异常检测">不仅仅生成图片，用GAN做无监督的异常检测</h1><p>代码：https://github.com/chiechie/wgan-gp-anomaly</p><p>GAN被LeCun赞为继CNN之后最为重要的一个工作，其原因在于让各位惊呼“这才有点人工智能的样子”。相比于CNN或者RNN而言，GAN是一种完全不一样的思路。CNN或者RNN，其本质都是一种有监督的学习方式，相比于传统的方式而言，得益于网络强大的表达能力和自动学习特征的end-to-end的学习能力，CNN和RNN在很多任务上实现了巨大提升从而引领了这一次的人工智能的兴起。但是有监督学习的缺陷在于需要大量的数据进行学习，所以很多人工智能公司都是花了大量的资金和人力来收集和标注数据。记得在学校听“驭势科技”的黄波博士的一次技术分享，他就谈到数据的问题，笑称其实现在最赚钱的不是做人工智能技术的公司，而是那些做数据标注的公司。如果我没有记错的话，似乎买一张给自动驾驶标注的<strong>精细的语义分割</strong>的标签图需要1块人民币左右（敲黑板！商机啊！同学们）。</p><p>GAN是一种对抗学习网络，通过生成器G和判别器D的对抗学习来学习训练集的数据分布从而学会生成图片（<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1406.2661.pdf">Goodfellow的paper</a>）。GAN一出来就被大家广泛的讨论，并且大量的人开始研究GAN，2017年以来arxiv上GAN的paper数量如同火箭一般的速度上升。原因就是GAN给做unsupervised learning提供一种很好的思路，最直接的应用在于我们可以用GAN学习真实的数据分布，从而生成图片可以给各种任务做<strong>数据增强</strong>。然后GAN也被应用在其他领域取得了非常不错的效果，有名的比如Twitter的那篇做超分辨的<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1609.04802">SRGAN</a>，最近最火的GAN应该是Berkeley的<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1611.07004">Pix2Pix GAN</a>和<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1703.10593">Cycle GAN</a>。</p><p><strong>Pix2Pix GAN和普通的GAN的区别是实现图片域的转换（Image Translation）</strong>， 比如从手绘画到实物图的转换，而不是从一个噪声生成图片，效果非常之好。但是<strong>Pix2Pix GAN要求需要pair的数据训练</strong>，即两个图片域之间要有对应好的训练数据。Cycle GAN和Pix2Pix GAN一脉相承，加入了cycle consistency loss从而不需要像Pix2Pix GAN一样需要不同图片域里面pair的数据才能训练GAN，实现了unpair的训练就可以完成不同图片域之间的转换。由于开源代码写的非常好（特别是<a href="https://link.zhihu.com/?target=https%3A//github.com/junyanz/pytorch-CycleGAN-and-pix2pix">Pytorch版的代码</a>，简直是Pytoch的良心模板，强推），实验效果也好，并且Image Translation本来就有很多的应用场景（除了刚提到的手绘图还有什么场景？），估计今年的CVPR里面应该会有很多魔改Cycle GAN和Pix2Pix GAN来做各种应用的paper出现。</p><h2 id="把gan应用于做异常检测">把GAN应用于做异常检测</h2><p>这篇文章要讲的不是用GAN来做图片的生成，而是一个非常有意思的应用方向-把GAN应用于做异常检测。首先解释一下什么是异常检测，顾名思义，异常检测就是<strong>检测出异常情况</strong>并且<strong>定位出异常位置</strong>。异常检测有着非常广泛的应用，例如在监控中，人行道中行人正常行走是正常情况，但是一旦出现车、自行车甚至滑板等等就是异常情况；或者在工厂生产产品中，正常外形的产品是合格的，但是也有出现一些瑕疵的产品。一般异常检测任务意味着<strong>异常的复杂性和异常数据的少量性</strong>：</p><ul><li>1、复杂性：异常检测不同于分类任务，分类任务是有确定的类别个数，所有的结果都在确定的分类标签中，但是对于异常检测而言，只要是和正常情况有出入就是异常情况，所以异常情况非常多而且事先无法预知，所以如果用分类的方式来做异常检测有很大的局限性。</li><li>2、异常数据的少量性：异常情况往往不常出现，所以导致异常情况的数据不是很方便收集，但是正常情况的数据通常是很多的。</li></ul><p>有很多正常的数据，但是没有很多异常的数据，那我们可不可以通过一个model来学习正常数据的分布，然后需要检测的异常图通过前面学习到的model找到它应该的正常图的样子，这样一对比不是可以找到异常吗？这样的思路简直完美契合GAN的思想！这篇文章里面我将会介绍一篇相关的paper：Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery， arxiv传送门：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1703.05921">https://arxiv.org/abs/1703.05921</a>。</p><p>这篇paper是把GAN用在医学图像里面做异常检测，我们可以先看下整体的框架图：</p><p><img src="https://pic4.zhimg.com/80/v2-3afb9ef54ee08b8983abcec88975ff17_hd.jpg" alt="img" />Fig.1 图中使用的数据是眼部的SD-OCT图像，这种图像信噪比比较高，然后眼部结构相比于其他部位又比较简单一点。眼部OCT图像需要经过一些预处理：视网膜区域的提取，展平，还有给GAN输入的图像patch的提取和normalization。</p><p>这个框架图基本已经解释了这篇paper的方法，其实就是用正常的图片去训练GAN，然后通过GAN生成与异常图对应的正常图来对比找到异常。</p><p><img src="/Users/stellazhao/research_space/EasyMLBOOK/_image/v2-592e8ddc687eda45212d8ddf70853aeb_hd.png" alt="img" />Fig.2 (a)是网络结构图，(b)是指正常和异常数据的分布</p><p>Fig.2 是paper中使用的GAN的结构图，</p><p>其实在这篇paper里面使用的GAN就是普通的DCGAN，从一个噪声向量Z学习生成一张图片。我们可以看到正常的眼部OCT图的纹理是一种比较正常的过渡，但是异常的OCT图明显纹理产生了变化。DCGAN只用正常的OCT图像训练，这样DCGAN就只能从噪声生成正常纹理的OCT图像。当输入一个异常图时，通过比较DCGAN的生成图和异常图的差异去更新输入的噪声Z，从而生成一个与异常图尽可能相似的正常图。通过这样的方式，可以认为重建出了异常区域的理想的正常情况，这样两张图一对比不仅仅可以认定异常情况，同时还可以找到异常区域。</p><p>这样paper的重点是如何更新GAN的输入噪声Z，最直接的想法就是把在正常图中训练得到的生成器G的参数固定，然后通过计算生成图和输入的L1 loss或者L2 loss来更新输入的噪声Z。这篇paper中同样也是使用了L1 loss，在paper中作者命名为Residual loss，但是本质就是算pixel-wise的L1 loss：</p><figure><img src="/Users/stellazhao/research_space/EasyMLBOOK/_image/v2-77779aba2e1a63a5ef312c0de9c38e2e_hd.png" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>Fig.3 更新噪声Z的Residual loss</p><p>在这篇paper中作者还加了一个loss去迭代噪声Z，An improved discrimination loss based on feature matching：</p><p><img src="https://pic1.zhimg.com/80/v2-13c9d37e5f19a28390fc17de03097cf4_hd.jpg" alt="img" />Fig.4 更新噪声Z的Improved discrimination loss</p><p>加入这个loss目的是希望同时利用到训练好的判别器D，取判别器D中一个layer的输出，对比生成图和输入图之间在这层layer上feature map的差异，从而更新噪声Z。这样的目的在于加入了一个更high level的对比，希望生成图和输入尽量靠近。最后总体的loss是这两个loss的加权和：</p><p><img src="https://pic1.zhimg.com/80/v2-8b08b59f3a23aa990b2fb63bf65b3acc_hd.jpg" alt="img" />Fig.5 Final loss fuction</p><p>下面是作者贴出来的一些实验结果图，可以看到对于异常区域都可以比较明显的找到。</p><p><img src="/Users/stellazhao/research_space/EasyMLBOOK/_image/v2-9dbf3f09ea6ba47de03569ad1ad0bd6e_hd.png" alt="img" />Fig.6</p><p>第一行：真实的输入图；第二行：迭代噪声Z之后的生成器G的生成图；第三行：计算生成与输入直接差异找到的异常区域；第四行：异常区域的heatmap图。图中的红色和黄色标注分别表示通过Residual loss和Improved discriminator loss认定的异常图片。</p><p>这篇paper提出了一个GAN很有意思的应用方向，对于异常情况，通过这样使用GAN就可以不需要任何异常数据而仅通过正常数据的训练就可以找到异常，相当于是一种无监督的异常检测方法。</p><p>但是这篇paper并没有开源代码，同时数据也没有给下载的link，我自己用Pytorch重现了这篇paper，github传送门：<a href="https://link.zhihu.com/?target=https%3A//github.com/oyxhust/wgan-gp-anomaly">oyxhust/wgan-gp-anomaly</a>（来都来了，点个star再走吧）。和原始的paper不同的是我用了wgan-gp实现，而没有用DCGAN，wgan-gp应该是目前gan训练最稳定的一种方式之一。并且我也没有下载到paper中的眼部OCT数据集，目前是在MNIST在做的测试，我选择数字“0”的图像当成正常图像，然后其他数字图就是异常图。WGAN-gp只用数字“0”的图像进行训练，在测试中我用所有数字的图来测试model。</p><p>下面是我复现的效果图：</p><figure><img src="https://pic1.zhimg.com/80/v2-c66190ea550aee83736e30e8e0ff02d0_hd.jpg" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>可以看到GAN只能生成数字“0”（相当于正常情况），对于“0”的测试图，GAN可以生成几乎一样的输出。对于其他数字（相当于异常情况），GAN只能生成形状非常类似的“0”的图像。在我自己的实验中，对于“0”的测试图，L1 loss可以降低0.02左右，但是其他数字的测试图最低也是大概0.05左右，所以还是可以很明显地检测出异常。</p><p>我觉得GAN用来做异常检测是一个非常有意思的方向，但是目前还有很多问题，这篇paper里面的做法我认为只能检测出一些比较大的异常。对于比较小的异常，因为GAN生成图并不能做到细节非常明显，所以很难检测。</p><figure><img src="../_image/image-20191113125624723.png" alt="image-20191113125624723" /><figcaption aria-hidden="true">image-20191113125624723</figcaption></figure><figure><img src="/Users/stellazhao/research_space/EasyMLBOOK/_image/image-20191113125714058.png" alt="image-20191113125714058" /><figcaption aria-hidden="true">image-20191113125714058</figcaption></figure><h2 id="参考资料">参考资料</h2><ol type="1"><li>https://www.youtube.com/watch?v=pXGqDiE4N0I</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-0-summary/&quot;&gt;chapter0 概览&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-1-event-generate/&quot;&gt;chapter1 故障发现&lt;/a&gt;
&lt;</summary>
      
    
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/categories/AIOps/"/>
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/tags/AIOps/"/>
    
    <category term="异常检测" scheme="https://chiechie.github.io/tags/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"/>
    
    <category term="异常分类" scheme="https://chiechie.github.io/tags/%E5%BC%82%E5%B8%B8%E5%88%86%E7%B1%BB/"/>
    
    <category term="GAN" scheme="https://chiechie.github.io/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>chapter1.1 单指标异常检测</title>
    <link href="https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-1_1_2-feature/"/>
    <id>https://chiechie.github.io/2021/05/21/AI/AIOps/AIOps-1_1_2-feature/</id>
    <published>2021-05-21T08:37:13.000Z</published>
    <updated>2021-06-02T09:43:09.283Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录">目录</h2><ul><li><a href="../AIOps-0-summary/">chapter0 概览</a></li><li><a href="../AIOps-1-event-generate/">chapter1 故障发现</a><ul><li><a href="../AIOps-1_1-kpi-detector/">chapter1.1 单指标异常检测</a></li><li><a href="../AIOps-1_2-fault-prediction/">chapter1.3 故障预测</a></li><li><a href="../AIOps-1_4-kpi-correlation/">chapter1.4 指标异常关联</a></li><li><a href="../AIOps-1_5-log-analysis/">chapter1.5 日志聚类</a><ul><li><a href="../AIOps-1_5_1-log-analysis_logmine/">chapter1.5.1 使用logmine加强版做日志聚类</a></li><li><a href="../AIOps-1_5_2-log-analysis_meituan/">chapter1.5.2 美团日志聚类</a></li></ul></li></ul></li><li><a href="../AIOps-2-event-analysis/">chapter2 故障定位</a><ul><li><a href="../AIOps-2_1-topo-rca/">chapter2.1 微服务系统的故障定位</a><ul><li><a href="../AIOps-2_1_1-topo-rca-causeinfer-notes1/">chapter2.1.1 CauseInfer1</a></li><li><a href="../AIOps-2_1_2-topo-rca-causeinfer-notes2/">chapter2.1.2 CauseInfer2</a></li><li><a href="../AIOps-2_1_3-topo-rca-aiops2020/">chapter2.1.3 AIOps挑战赛2020-获奖方案分享</a></li><li><a href="../AIOps-2_1_4-topo-rca-aiops2021/">chapter2.1.4 AIOps挑战赛2021-demo方案</a></li><li><a href="../AIOps-2_1_5-topo-rca-cnsoftbei2020/">chapter2.1.5 N-Softbei2020比赛</a></li><li><a href="../AIOps-2_1_6-topo-rca-MicroCause">chapter2.1.6 MicroCause</a></li></ul></li><li><a href="../AIOps-2_2-multi-dimensional-rca/">chapter2.2 多维下钻根因定位</a></li><li><a href="../AIOps-2_3-trace_rca/">chapter2.3 调用链根因分析</a></li><li><a href="../AIOps-2_4-metric_event_correlation/">chapter2.4 时间序列关联性分析</a></li></ul></li><li>chapter3 故障恢复</li></ul><h2 id="概述">1. 概述</h2><p>大型集群系统中，可能存在软件问题和硬件问题导致的系统故障，严重影响了系统的高可用性。这就要求7*24小时，对系统不间断监控。这就意味着需要不间断地监控大量时间序列数据，以便检测系统潜在的故障和异常现象。然而，实际当中的系统异常很多，且不容易发现；从而导致人工方式监控方式效率很低。</p><p>异常场景本质上是一个或者多个数据点；数据点一般在系统运行过程中产生，且能反应系统的功能是否正常，多以日志形式呈现。当系统功能发生异常时，就会产生异常数据。快速高效地发现这些异常值，对于快速止损具有重要意义。对此，我们提出一种基于时间序列的异常识别模型，用来及时发现异常。</p><p>对于多数系统，一般都有成功率、流量等指标，故障发生时，这些指标也会出现响应的异常。我们将系统成功率、流量统一称为特征值变量，并对其进行建模，从而方便后续其它特征变量的扩展。为了更好地感知这些特征变量的突变，需要对特征变量进行计算处理或者空间转换。那么异常识别问题就转换为以下两个问题：</p><ul><li>特征变量的计算处理和转换</li><li>突变的判断</li></ul><p>针对这两个关键问题，我们将在下文中进行建模和分析。</p><h2 id="异常识别">2. 异常识别</h2><p>如下图，通过计算器进行特征变量的计算处理和转换，通过异常检测器来判断数值的突变，从而解决上面的两个问题。其中，异常检测器由比较器和决策器组成。</p><p><a href="http://www.datadriven.top/images/image-20180815093422131.png"><img src="http://www.datadriven.top/images/image-20180815093422131.png" alt="image-20180815093422131" /></a>image-20180815093422131</p><p>对于给定时间序列二维矩阵X={xmt∈R：∀t≥0,∀m≥0}X={xtm∈R：∀t≥0,∀m≥0} ，xmtxtm为tt时刻的第m个指标的真实数据，umtutm表示时间tt的xmtxtm的计算值，ymtytm为第m个指标的输出结果，ytyt为整体预测结果。</p><p>xmtxtm通过计算器得到计算值umtutm，然后xmtxtm 和 umtutm分别作为比较器的输入，得到第m个指标的输出ymtytm。y1tyt1,y2tyt2…ymtytm作为决策器的输入得到ytyt。ytyt是一个二元值，可以用<code>TRUE</code>（表示输出数据正常），<code>FALSE</code>（表示输入数据异常）表示。下面对计算器和检测器进行说明。</p><h3 id="计算器">2.1 计算器</h3><p><strong>计算器</strong>用来对输入值xmtxtm 进行计算或者空间转换，从而得到特征变量的计算值umtutm。一般情况下，特征变量具有趋势性、周期性等特征。基于这些特征，计算值的获取，可以使用以下三种方式：累计窗口均值计算器、基于趋势性的环比计算器、基于周期性的同比计算器。</p><h4 id="累积窗口均值计算器">2.1.1 累积窗口均值计算器</h4><p>输入值为xtxt（为了方便省略指标参数<code>m</code>），如果直接只用单个点xtxt的抖动来判断，受噪声影响较大。因此，使用累积窗口均值的方式：</p><figure><img src="../_image/image-20191012164029688.png" alt="image-20191012164029688" /><figcaption aria-hidden="true">image-20191012164029688</figcaption></figure><p>其中，ww为累计窗口的大小。通过窗口平滑之后，会过滤掉尖刺等噪声。</p><h4 id="基于趋势性的计算器">2.1.2 基于趋势性的计算器</h4><p>为了描述数据的趋势性，引入环比类算法。对<span class="math inline">\(x_t\)</span>进行空间转换，得到环比，再使用检测器进行检测。</p><figure><img src="/Users/stellazhao/research_space/EasyMLBOOK/_image/image-20191012163924379.png" alt="image-20191012163924379" /><figcaption aria-hidden="true">image-20191012163924379</figcaption></figure><p>其中，分子为当前窗口w内的数据，分母为上一窗口w内数据。通过窗口w对数据进行平滑。</p><h4 id="基于周期性的计算器">2.1.3 基于周期性的计算器</h4><p>为了描述数据的周期性，引入同比算法。当同比值过大或者过小时，认为发生故障。同比公式如下：</p><figure><img src="/Users/stellazhao/research_space/EasyMLBOOK/_image/image-20191012164057696.png" alt="image-20191012164057696" /><figcaption aria-hidden="true">image-20191012164057696</figcaption></figure><p>其中TT为周期，kk表示第几个周期。一般选取kk为<code>1</code>、<code>7</code>、<code>30</code>，来表示昨天、上周、上个月。</p><h4 id="其他类型计算器">2.1.4 其他类型计算器</h4><p>计算器还可以使用其他算法，包括：</p><ul><li>统计类算法：包括同比、环比算法的改进，或者其他统计算法。此时，计算器的输出结果为预测值，预测值和输入值进行比较即可。</li><li>时序型算法：包含ARIMA、Holter-Winter等时序型算法。计算器的输出结果为预测值。</li><li>机器学习：根据有监督、无监督、深度学习(LSTM)等算法，训练出的模型即为计算器。此时，计算器的输出结果一般为归一化的值，根据归一化的值进行比较。</li></ul><p>这些算法，在这里不再做深入研究和阐述。</p><h3 id="异常检测器">2.2 异常检测器</h3><p>当数据出现异常时，计算值会出现较大偏差，该偏差由<strong>异常检测器</strong>来判断。<strong>异常检测器</strong>由比较器和决策器组成，计算值和真实值通过该模块后，得到最终预测结果。</p><h4 id="比较器">2.2.1 比较器</h4><p>比较器的本质是求解如下公式的过程：</p><p>f(xmt,umt;hm) = boolean(4)(4)f(xtm,utm;hm) = boolean</p><p>其中，xmtxtm为真实值，uu为计算值，hmhm为阈值参数，booleanboolean为结果<code>TRUE/FALSE</code>。真实值已知，计算值通过计算器得到；剩下的阈值参数hmhm，则需要根据故障发生时的实际值进行参数估计。</p><p>很多场景下，该公式还可以简化为：f(umt;hm) = booleanf(utm;hm) = boolean ，即计算值直接和阈值比较即可。</p><h5 id="比较器种类">2.2.1.1 比较器种类</h5><p>比较器有两种：相对值比较器和绝对值比较器。给定计算值umtutm和输入值xmtxtm，得到绝对值比较器：</p><p>f=xmt−umt opretor hm(5)(5)f=xtm−utm opretor hm</p><p>其中，opretoropretor为比较操作符，比如<code>&gt; &lt; &gt;= &lt;=</code>。由于utut由xtxt得到，所以很多情况下公式可以简化为 umtopretorhmtutmopretorhtm，即确定计算值的阈值即可。</p><p>对于一些场景来说，需要捕获特征变量的相对性。因此，引入相对值比较器：</p><p>f=xmt−umtumt opretor hm(6)(6)f=xtm−utmutm opretor hm</p><p>通过对相对值比较器进行阈值处理，既可以检测异常值，同时还能对期望值进行归一化。</p><h5 id="比较器阈值h的选取">2.2.1.2 比较器阈值h的选取</h5><p>一般情况下，阈值参数决定了异常检测模块的敏感度。最优阈值的选择，取决于数据分布的性质以及先验数据。一般情况下，<strong>阈值的选取方法为</strong>：</p><ul><li>方法一：跟踪一组故障数据和正常数据，根据经验估计阈值。</li><li>方法二：跟踪一组故障数据和正常数据，根据经验，并结合<code>3σ准则</code>确定，来确定阈值。（特征变量或者特征变量的组合，服从正态分布）</li></ul><h4 id="决策器">2.2.2 决策器</h4><p>如下公式，基于逻辑操作符，对比较器结果进行合并.</p><ul><li>方式一：逻辑组合</li></ul><p>yt=y1t &amp;| y2t &amp;| y3t &amp;| ... ymt(7)(7)yt=yt1 &amp;| yt2 &amp;| yt3 &amp;| ... ytm</p><p>其中，||表示逻辑或操作，&amp;&amp;表示逻辑与操作。</p><ul><li><p>方式二：权重设置法</p><p>yt=k1∗y1t + k2∗y2t + k3∗y3t + ... km∗ymt(8)</p></li></ul><p>其中，kmkm为系数，这种方式一般适合基本无负样本的场景，参数的确定需要使用<code>层次分析法</code>，将在后面的文章进行说明。</p><h2 id="故障止损">3. 故障止损</h2><p>上面主要阐述了异常识别的方式。如果条件过于严格，刚开始并不容易被识别出来；如果条件过松，可能导致误识别。对此，我们将止损策略分为两级：</p><ul><li>级别一：预警。对于不能完全确定故障发生的场景，使用级别一。</li><li>级别二：预警+止损（踢IDC）。对于能确定IDC故障的场景，使用级别二。</li></ul><h2 id="实际场景应用">4. 实际场景应用</h2><p>下面通过一个规则的场景，进行举例说明。假如存在如下异常场景：</p><p><a href="http://www.datadriven.top/images/image-20181108211144340.png"><img src="http://www.datadriven.top/images/image-20181108211144340.png" alt="image-20181108211144340" /></a>image-20181108211144340</p><p><strong>体现在模型中，则级别一（预警）的模型图</strong></p><p><a href="http://www.datadriven.top/images/image-20180815093336600.png"><img src="http://www.datadriven.top/images/image-20180815093336600.png" alt="image-20180815093336600" /></a>image-20180815093336600</p><p><strong>级别二（预警+踢IDC）的模型图：</strong></p><p><a href="http://www.datadriven.top/images/image-20180815093352931.png"><img src="http://www.datadriven.top/images/image-20180815093352931.png" alt="image-20180815093352931" /></a>image-20180815093352931</p><p>最终，得到故障识别规则：</p><ul><li>级别一触发条件: u1&lt;h1 | (u5&lt;h5 &amp; u6&lt;h6 &amp; u7&lt;h7)u1&lt;h1 | (u5&lt;h5 &amp; u6&lt;h6 &amp; u7&lt;h7)</li><li>级别二触发条件：u1&lt;h2 &amp; u3&gt;h3u1&lt;h2 &amp; u3&gt;h3</li></ul><p>其中，h1,h2,h3,h5,h6,h7h1,h2,h3,h5,h6,h7为阈值参数。需要结合经验和实际数据估计得到。</p><h2 id="小结">5. 小结</h2><p>本文主要基于时间序列的数据，提出了异常场景识别模型，并重点对基于规则的识别进行了说明。</p><h2 id="参考">参考</h2><ol type="1"><li><a href="http://dl.acm.org/citation.cfm?id=2788611">Generic and Scalable Framework for Automated Time-series Anomaly Detection</a></li><li><a href="http://www.datadriven.top/categories/数据驱动/">数据驱动应用（一）：整体概述</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-0-summary/&quot;&gt;chapter0 概览&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;../AIOps-1-event-generate/&quot;&gt;chapter1 故障发现&lt;/a&gt;
&lt;</summary>
      
    
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/categories/AIOps/"/>
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/tags/AIOps/"/>
    
    <category term="异常检测" scheme="https://chiechie.github.io/tags/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"/>
    
    <category term="异常分类" scheme="https://chiechie.github.io/tags/%E5%BC%82%E5%B8%B8%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
</feed>
