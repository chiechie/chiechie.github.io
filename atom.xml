<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Chiechie&#39;s Mini World</title>
  
  <subtitle>Set your course by the stars, not by the lights of passing ships. —— Omar Bradley</subtitle>
  <link href="https://chiechie.github.io/atom.xml" rel="self"/>
  
  <link href="https://chiechie.github.io/"/>
  <updated>2021-07-02T09:33:10.759Z</updated>
  <id>https://chiechie.github.io/</id>
  
  <author>
    <name>Chiechie</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>图的最大流和最小割算法</title>
    <link href="https://chiechie.github.io/2021/07/02/data_structure/graph/min-cut/"/>
    <id>https://chiechie.github.io/2021/07/02/data_structure/graph/min-cut/</id>
    <published>2021-07-02T00:48:14.000Z</published>
    <updated>2021-07-02T09:33:10.759Z</updated>
    
    <content type="html"><![CDATA[<h2 id="最大流">最大流</h2><h3 id="最大流问题">最大流问题</h3><h3 id="最大流算法">最大流算法</h3><h2 id="最小割">最小割</h2><h3 id="最小割问题">最小割问题</h3><p>最小割要解决的问题和最大流是一样的</p><p>输入：方向有权图 目标：割的容量最小 输出：某个S-T cut，</p><blockquote><p>最大流最小割定理（Max-Flow Min-Cut Theorem）</p><p>在一个网络流量中，从s到t的最大流量等于，最小s-t cut的容量。</p><p>--L. R. Ford and D. R. Fulkerson. Flows in Networks. Princeton University Press, (1962 .)</p></blockquote><p><img src="img_1.png" /></p><h3 id="寻找最小割的方法">寻找最小割的方法</h3><ol type="1"><li>使用最大流算法获得residual graph， 移走其中反向的边</li><li>在residual graph中，从起点s出发，找到所有能达到的节点，并记为集合S，把其他所有节点记做T（s到不了的节点）。</li><li>将{S, T}记做最小割。</li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.youtube.com/watch?v=Ev_lFSIzNh4&amp;t=128s">图的最小割算法-youtube</a></li><li><a href="https://github.com/wangshusen/AdvancedAlgorithms">图的最小割算法-slide</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;最大流&quot;&gt;最大流&lt;/h2&gt;
&lt;h3 id=&quot;最大流问题&quot;&gt;最大流问题&lt;/h3&gt;
&lt;h3 id=&quot;最大流算法&quot;&gt;最大流算法&lt;/h3&gt;
&lt;h2 id=&quot;最小割&quot;&gt;最小割&lt;/h2&gt;
&lt;h3 id=&quot;最小割问题&quot;&gt;最小割问题&lt;/h3&gt;
&lt;p&gt;最小割要解决的问题和最大流是一</summary>
      
    
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="图算法" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E7%AE%97%E6%B3%95/"/>
    
    <category term="图" scheme="https://chiechie.github.io/tags/%E5%9B%BE/"/>
    
    <category term="最小割" scheme="https://chiechie.github.io/tags/%E6%9C%80%E5%B0%8F%E5%89%B2/"/>
    
  </entry>
  
  <entry>
    <title>一种日志聚类的方法-LogCluster</title>
    <link href="https://chiechie.github.io/2021/07/01/AI/AIOps/AIOps-1_5_3-LogCluster-_ms/"/>
    <id>https://chiechie.github.io/2021/07/01/AI/AIOps/AIOps-1_5_3-LogCluster-_ms/</id>
    <published>2021-07-01T10:56:03.000Z</published>
    <updated>2021-07-02T11:01:15.553Z</updated>
    
    <content type="html"><![CDATA[<h2 id="参考">参考</h2><ol type="1"><li><a href="https://netman.aiops.org/~peidan/ANM2018Fall/6.LogAnomalyDetection/LectureCoverage/2016ICSE_Log%20Clustering%20based%20Problem%20Identification%20for%20Online%20Service%20Systems%20.pdf">Log Clustering based Problem Identification for Online Service Systems- 微软</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;a href=&quot;https://netman.aiops.org/~peidan/ANM2018Fall/6.LogAnomalyDetection/LectureCoverage/2016ICSE_L</summary>
      
    
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/categories/AIOps/"/>
    
    
    <category term="AIOps" scheme="https://chiechie.github.io/tags/AIOps/"/>
    
    <category term="NLP" scheme="https://chiechie.github.io/tags/NLP/"/>
    
    <category term="日志分析" scheme="https://chiechie.github.io/tags/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"/>
    
    <category term="论文笔记" scheme="https://chiechie.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>基于Ray的融合计算框架</title>
    <link href="https://chiechie.github.io/2021/06/30/reading_notes/computer/fenbushi/"/>
    <id>https://chiechie.github.io/2021/06/30/reading_notes/computer/fenbushi/</id>
    <published>2021-06-30T06:39:39.000Z</published>
    <updated>2021-07-01T11:56:15.297Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>看到阿里在2021发表的一个演讲--《新一代的计算基础设施-对于Ray的融合计算》，做一些笔记</p></blockquote><ol type="1"><li>举一个复杂的业务的例子，用户支付流程：</li></ol><ul><li>先选择支付场景--线上/线下/，</li><li>选择支付方式--</li><li>选择交易网络--银联/第三方</li><li>选择银行</li></ul><figure><img src="./img_1.png" alt="img_1.png" /><figcaption aria-hidden="true">img_1.png</figcaption></figure><p>整个流程需要秒级响应。</p><ol start="2" type="1"><li>要是大家都开始用统一的计算平台，AIOps也可以用同一套方案了</li></ol><figure><img src="./img_2.png" alt="img_2.png" /><figcaption aria-hidden="true">img_2.png</figcaption></figure><ol start="3" type="1"><li>业务需求之一是，复杂的业务逻辑计算存在单机性能瓶颈，需要支持分布式无范式的分布式开发。</li><li>现在的基础设计在单一用途的组件上，已经做的比较成熟了，专门做流式计算的计算引擎有flink，专门做深度学习的计算引擎有tensorflow，专门做批处理的有spark。</li><li>但是，考虑到一个复杂的应用场景，完成1个任务需要用到多种计算模式，统一计算平台 能够让这几种计算模式实现状态共享，中间结果共享。在这种场景下，统一计算平台，相较于多个独立的计算组件 效率更高。</li><li>要不要搞统一计算平台，取决于需求的复杂性，如果是一个很pure很纯粹的任务，搞这个的意义就不大。但是可以作为预研嘛，万一以后业务变得越来越复杂，也有准备。</li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.bilibili.com/video/BV1gh411Y7qf?t=1">Ray Forward Meetup 2021-面向金融决策场景的在线计算系统-bilibili</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;看到阿里在2021发表的一个演讲--《新一代的计算基础设施-对于Ray的融合计算》，做一些笔记&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;举一个复杂的业务的例子，用户支付流程：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="大数据" scheme="https://chiechie.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    <category term="读书笔记" scheme="https://chiechie.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    <category term="计算机原理" scheme="https://chiechie.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/"/>
    
    <category term="分布式计算" scheme="https://chiechie.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>零知识量证明</title>
    <link href="https://chiechie.github.io/2021/06/29/reading_notes/qukuailian/zkp/"/>
    <id>https://chiechie.github.io/2021/06/29/reading_notes/qukuailian/zkp/</id>
    <published>2021-06-29T15:54:57.000Z</published>
    <updated>2021-07-01T02:32:20.876Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本概念">基本概念</h2><ol type="1"><li><p>零知识证明(ZKP)的定义为：证明者（prover）能够在不向验证者（verifier）提供任何有用的信息的情况下，使验证者（verifier）相信某个论断是正确的。</p></li><li><p>零知识证明具有三个重要的性质：</p><ul><li>完备性（Completeness）：只要证明者拥有相应的知识，那么就能通过验证者的验证，即证明者有足够大的概率使验证者确信。---验证者的问题是可解的。</li><li>可靠性（Soundness）：如果证明者没有相应的知识，则无法通过验证者的验证，即证明者欺骗验证者的概率可以忽略。---验证者的问题是有难度的。</li><li>零知识性（Zero-Knowledge）：证明者在交互过程中仅向验证者透露是否拥有相应知识的陈述，不会泄露任何关于知识的额外信息。---验证者是无不要知道解答过程的，它只在另外一个问题空间验证。</li></ul></li><li><p>使用零知识证明技术的应用有：隐私币--zcash就是的隐私币，以太坊上的混币合约，链下扩容技术zkRollup。</p></li><li><p>零知识证明是一种基于概率的验证方式，验证者（verifier）向证明者（prover)提出多个随机问题，如果证明者都能给出正确回答，则说明证明者大概率拥有他所声称的“知识”。零知识证明并不是数学意义上的证明，因为它存在小概率的误差，欺骗的证明者有可能通过虚假的陈诉骗过验证者。换句话说，零知识证明是概率证明而不是确定性证明，但是也存在技术能将误差降低到可以忽略的值。</p></li></ol><h2 id="应用场景">应用场景</h2><p>零知识证明在区块链上的两大应用场景：隐私和扩容。</p><p>隐私：在隐私场景中，我们可以借助零知识证明的“不泄露信息”特性，在不泄漏交易的细节（接收方，发送方，交易余额）的情况下证明区块链上的资产转移是有效的。</p><p>扩容：在扩容场景中，我们不太需要关注零知识证明技术的“不泄露信息”这个特性，我们的关注重点是它的“证明论断有效”这个特性，由于链上资源是有限的，所以我们需要把大量的计算迁移到链下进行，因此需要有一种技术能够证明这些在链下发生的动作是可信的，零知识证明正好可以帮助我们做链下可信计算的背书。</p><h3 id="隐私场景">隐私场景</h3><h4 id="为什么需要隐私币">为什么需要隐私币？</h4><ol type="1"><li><p>举个生活中的例子：游客向庙里功德箱中仍香火钱，所有的游客仍的都是同一个年份的一元硬币，这时有一个第三方在一旁观察，他可以知道谁在什么时间扔进去多少个硬币。但是当小沙弥从功德箱中取钱的时候，他无法分别取出的硬币是由谁扔进去的。这里功德箱就起到一个混币的功能.同理，为了保证区块链上交易的隐私性，也可以进行混币。</p></li><li><p>混币的目的是切断加密货币交易中发送方与接受方的联系，发送方利用混币系统将自己的钱与其他人的钱进行混合，接受方(Verifier)利用零知识证明来证明有某一个混币的所有权，从而进行转账交易。</p></li><li><p>需要隐私币的第一个理由：隐私币可以能实现完全匿名且不可追踪。</p><ul><li>目前公链（比特币）的匿名只起到假名的作用，例如现实生活中的人可以生成任意多的公私钥对，用这些公钥在链上发送或接受每笔交易，这些公钥就充当他们的假名。如果外界不知道你和公钥的关系，他们就无法把你和你的交易历史关联起来，只要有人能把你跟公钥联系起来，就可以顺藤摸瓜找到你过去的交易历史。目前不没有办法阻止第三方将我们和我们的公钥联系起来。</li></ul></li><li><p>需要隐私币的第二个理由：由于隐私币无法查看货币的交易记录，所以减少了货币不可互换性的问题。</p><ul><li>流通性使货币具有了内在可互换性,但是加密货币具有极度透明性，我们可以追踪到与某一特定货币的所有相关历史交易，这样一来，人们一旦发现某个货币是“污点”货币（俗称“黑钱”）就可以拒绝接受这种货币。如果这种情况大规模发生，加密货币将不再是可互换的因为“干净”的货币比“污点”货币具有更大价值。</li><li>不可互换的货币会给用户带来额外的负担，用户为了避免不小心买入“污点”货币，那么用户就会被迫检查他们购买的每笔货币的交易历史。</li></ul></li><li><p>下图是使用零知识证明的一般过程，在circuit中会执行一些约束，这些约束是与要解决的问题是相关的。Private input是不对外揭露的，只有prover自己知道这个值。public input是prover与Verifier之间共享的一个值。所以上面的过程可以总结为，prover 在不揭露Private input 的情况下向Verifier证明自己知道一个值能满足（x+3=5)。</p><figure><img src="./img.png" alt="基于circuit的零知识证明" /><figcaption aria-hidden="true">基于circuit的零知识证明</figcaption></figure></li></ol><h4 id="zk-snark的流程图">zk-SNARK的流程图</h4><p>下图是，zk-SNARK不能直接用于解决任何计算问题，我们必须先把问题转换成正确的“形式”来处理，这种形式叫做 "quadratic arithmetic problem"(QAP)，在进行QAP 转换的同时，我们可以用Private input ，public input创建一个对应的解，称为QAP的witness。只有prover用这个witness来生成proof。</p><figure><img src="./img_1.png" alt="zk-Snark流程图" /><figcaption aria-hidden="true">zk-Snark流程图</figcaption></figure><p>整个过程如下：</p><ul><li>首先得有一个计算问题，这个问题一般是NP问题</li><li>然后将计算问题做一个等价转换变成QAP，步骤如下：<ul><li>将计算问题拍平变成circuit</li><li>把circuit转化成 R1CS(rank-1 constraint system，一阶约束系统)。R1CS 是一个由三向量组 (a,b,c) 组成的序列，R1CS 有个解向量 s，s 必须满足符号表示向量的内积运算 a.s * b.s - c.s = 0，这里的解向量s就是witness</li><li>将R1CS转化成QAP形式，这两者的区别是QAP使用多项式来代替点积运算，他们所实现的逻辑完全相同。</li></ul></li><li>接下的是比较重要的一步trusted setup，trusted setup会生成两个值PK，VK，truseted setup的目的是实现零交互验证，它生成的PK，VK相当于是一个“上帝”由它来帮我们做一些挑战，来验证prover。</li></ul><p>prover会用PK已经witness生成一个proof交给Verifier</p><p>Verifier拿到这个proof会用VK做一些校验，这一步发生在链上，有链上的节点或智能合约来做校验。</p><h3 id="扩容">扩容</h3><ol type="1"><li>17年出现了一款非常火爆的Dapp应用叫加密猫，加密猫曾造成以太坊主网大规模的拥堵，造成拥堵的原因是以太坊当时的TPS只有15，这意味着以太坊每秒只能处理15笔交易，如此低的TPS严重限制了区块链应用的大规模落地，所以有人开始研究区块链扩容的问题，目的就是为了提高链上的TPS。</li><li>但区块链扩容受到Vitalik提出的不可能三角的限制(区块链系统设计无法同时兼顾可扩展性，去中心化和安全性).但我们必须知道，一切事物都有自己的边界，公链不应该做所有的事情，公链应该做它该做的事情：“公链是以最高效率达成共识的工具，能够以最低成本来构建信任”。</li><li>作为共识的工具，信任的引擎，公链不应该为了可扩展性放弃去中心化与安全性。那么公链的TPS这么低，该怎么使用呢？可以将大量的工作放到链下去解决，仅仅将最重要的数据提交到区块链主链上，让所有节点都能够验证这些链下的工作都是准确可靠的.</li><li>社会的发展带来的是更精细化的分工，区块链的技术发展也是如此，在底层区块链（Layer1）上构建一个扩展层（Layer2)，Layer1来保证安全和去中心化，绝对可靠、可信；它能做到全球共识，并作为“加密法院”，通过智能合约设计的规则进行仲裁，以经济激励的形式将信任传递到Layer2上，而Layer2追求极致的性能，它只能做到局部共识，但是能够满足各类商业场景的需求。</li></ol><h2 id="发展历史">发展历史</h2><ol type="1"><li>1985 年，零知识证明Zero-Knowledge Proof - 由 S.Goldwasser、 S.Micali 及 C.Rackoff 首次提出。</li><li>2010年，Groth实现了首个基于椭圆曲线双线性映射全能的，常数大小的非交互式零知识证明协议。后来这个协议经过不断优化，最终成为区块链著名的零知识证明协议SNARKs。</li><li>2013年，Pinocchio协议实现了分钟级别证明，毫秒级别验证，证明大小不到300字节，将零知识证明从理论带到了应用。后来Zcash使用的SNARKs正是基于Pinocchio的改进版。</li><li>2014 年，名为Zerocash的加密货币则使用了一种特殊的零知识证明工具zk-SNARKs （ Zero-Knowledge Succinct Non-interactive Arguments of Knowledge ) 实现了对交易金额、交易双方的完全隐藏，更注重于隐私，以及对交易透明的可控性。</li><li>2017 年， Zerocash 团队提出将 zk-SNARKs 与智能合约相互结合的方案，使交易能在众目睽睽下隐身，打造保护隐私的智能合约。</li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://zhuanlan.zhihu.com/p/152065162">零知识证明介绍-zhihu</a></li><li><a href="https://www.notboring.co/p/zero-knowledge">Zero Knowledge, from not boring</a></li><li><a href="https://mp.weixin.qq.com/s/_IrI8SJLo1Ht51nJfI4V_Q">十分钟开发一个混币-原理篇</a></li><li><a href="https://mp.weixin.qq.com/s/8OkwqNXIkUz2PBURoghRJQ">十分钟开发零知识证明之混币</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基本概念&quot;&gt;基本概念&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;零知识证明(ZKP)的定义为：证明者（prover）能够在不向验证者（verifier）提供任何有用的信息的情况下，使验证者（verifier）相信某个论断是正确的。&lt;/p&gt;&lt;/li&gt;
&lt;l</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="加密货币" scheme="https://chiechie.github.io/tags/%E5%8A%A0%E5%AF%86%E8%B4%A7%E5%B8%81/"/>
    
    <category term="零知识量证明" scheme="https://chiechie.github.io/tags/%E9%9B%B6%E7%9F%A5%E8%AF%86%E9%87%8F%E8%AF%81%E6%98%8E/"/>
    
  </entry>
  
  <entry>
    <title>几个思维模型</title>
    <link href="https://chiechie.github.io/2021/06/28/reading_notes/reality/10-mental-model/"/>
    <id>https://chiechie.github.io/2021/06/28/reading_notes/reality/10-mental-model/</id>
    <published>2021-06-28T04:50:00.000Z</published>
    <updated>2021-06-28T05:47:15.061Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>基于剃刀原则的几个思维模型，from Sahil Bloom的twitter</p></blockquote><h2 id="the-steve-jobs-quality-razor">The Steve Jobs Quality Razor</h2><p>When building, take pride in carrying the quality all the way through.Would you be proud for your work to be seen from every angle and perspective? If not, keep working.</p><h2 id="the-eli5-razor">The ELI5 Razor</h2><ul><li>Complexity and jargon are often used to mask a lack of true understanding.</li><li>If you can’t explain it to a 5-year-old, you don’t really understand it.</li><li>If someone uses a lot of complexity and jargon to explain something to you, they probably don’t understand it.</li></ul><h2 id="mungers-rule-of-opinions">Munger’s Rule of Opinions</h2><p>“I never allow myself to have an opinion on anything that I don’t know the other side’s argument better than they do.” - Charlie Munger</p><p>Opinions aren’t free. You have to work to earn the right to have them.</p><h2 id="the-bezos-regret-minimization-framework">The Bezos Regret Minimization Framework</h2><p>The goal is to minimize the number of regrets in life.</p><p>When faced with a difficult decision: (1) Project yourself into the future (2) Look back on the decision (3) Ask "Will I regret not doing this?" (4) Take action</p><h2 id="buffetts-rule-of-holes">Buffett’s Rule of Holes</h2><p>“The most important thing to do if you find yourself in a hole is to stop digging." - Warren Buffett</p><p>When things aren’t working, change course and try something different.</p><p>When you find yourself at the bottom of a hole, stop digging and climb out of it.</p><h2 id="pgs-crazy-idea-razor">PG's Crazy Idea Razor</h2><p>If someone proposes a crazy idea, ask:</p><ol type="1"><li>Are they a domain expert?</li><li>Do I know them to be reasonable?</li></ol><p>If yes on (1) and (2), you should take the idea seriously, as it may be an asymmetric bet on the future.</p><h2 id="the-boasters-razor">The Boaster’s Razor</h2><p>Truly successful people rarely feel the need to boast about their success.</p><p>If someone regularly boasts about their income, wealth, or success, it’s fair to assume the reality is a fraction of what they claim.</p><h2 id="the-circle-of-competence">The Circle of Competence</h2><p>Be ruthless in identifying your circle of competence (and its boundaries).</p><p>When faced with a big decision, ask yourself whether you are qualified to handle it given your circle.</p><p>If yes, proceed. If no, outsource it to someone who is.</p><h2 id="the-duck-test">The Duck Test</h2><p>If it looks like a duck, swims like a duck, and quacks like a duck, it’s probably a duck.</p><p>You can determine a lot about a person by regularly observing their habitual characteristics.</p><h2 id="buffetts-juicy-pitch">Buffett’s Juicy Pitch</h2><p>“You don't have to swing at everything - you can wait for your pitch." - Warren Buffett</p><p>Life doesn’t reward you for the number of swings you take.</p><p>Slow down and focus on identifying the juiciest pitch.</p><p>When it comes, swing hard and don’t miss it.</p><h2 id="occams-razor">Occam’s Razor</h2><p>The simplest explanation is often the best one.</p><p>Simple assumptions &gt; complex assumptions.</p><p>Simple is beautiful.</p><h2 id="the-buffett-reputation-razor">The Buffett Reputation Razor</h2><p>“It takes 20 years to build a reputation and five minutes to ruin it. If you think about that, you'll do things differently.” - Warren Buffett</p><p>Remember that quote and act accordingly.</p><p>Your character is your fate.</p><h2 id="hanlons-razor">Hanlon’s Razor</h2><p>Never attribute to malice that which can be adequately explained by stupidity.</p><p>In assessing someone's actions, we should not assume negative intent if there is a viable alternative explanation, such as different beliefs, incompetence, or ignorance.</p><p>汉隆的剃刀</p><p>永远不要把可以用愚蠢充分解释的事情归咎于恶意。</p><p>在评估某人的行为时，如果有可行的替代解释，例如不同的信念、无能或无知，我们不应假设消极意图。</p><h2 id="nntalebs-the-look-the-part-razor">nntaleb's The “Look the Part” Razor</h2><p>If forced to choose between two options of seemingly equal merit, choose the one that doesn’t look the part.</p><p>The one who doesn’t look the part has had to overcome much more to achieve its status than the one who fit in perfectly.</p><p>如果被迫在看似同等价值的两个选项之间做出选择，请选择一个看起来不合适的选项。</p><p>与完美契合的人相比，看起来不合群的人必须克服更多才能获得地位。</p><h2 id="newtons-flaming-laser-sword">Newton’s Flaming Laser Sword</h2><p>If something cannot be settled by experiment or observation, it is not worth debating.</p><p>This will save you from wasting a lot of time on pointless arguments.</p><p>牛顿的火焰激光剑</p><p>如果一些事情不能通过实验或观察来解决，那就不值得争论了。</p><p>这将使您免于在无意义的争论上浪费大量时间。</p><h2 id="machiavellis-razor">Machiavelli’s Razor</h2><p>Never attribute to malice that which can be adequately explained by self-interest.</p><p>In assessing someone's actions, we should not assume negative intent if there is a viable alternative explanation that they are acting on rooted self-interest.</p><p>马基雅维利的剃刀</p><p>永远不要将可以用自身利益充分解释的事情归咎于恶意。</p><p>在评估某人的行为时，如果有一个可行的替代解释表明他们是根据根深蒂固的自身利益行事，我们不应该假设消极意图。</p><h2 id="hitchens-razor">Hitchens’ Razor</h2><p>What can be asserted without evidence can also be dismissed without evidence.</p><p>The burden of proof regarding a claim lies with the one who makes the claim. If unmet, no argument is required to dismiss it.</p><h2 id="sagans-standard">Sagan’s Standard</h2><p>“Extraordinary claims require extraordinary evidence.”</p><p>The more crazy and outrageous the claim, the more crazy and outrageous the body of evidence must be in order to prove it.</p><p>萨根的标准</p><p>“非凡的主张需要非凡的证据。”</p><p>声称越疯狂和越离谱，为了证明它，证据主体就必须越疯狂和离谱。</p><h2 id="the-eisenhower-decision-matrix">The Eisenhower Decision Matrix</h2><p>When faced with a task, ask: “Is this urgent? Is this important?”</p><p>An "urgent" task is one that requires immediate attention. An "important" task is one that promotes or furthers your long-term goals.</p><p>Place it on a 2x2 matrix and act accordingly.</p><h2 id="the-steve-jobs-settling-razor">The Steve Jobs Settling Razor</h2><p>“The only way to do great work is to love what you do. If you haven’t found it yet, keep looking. Don’t settle.” - Steve Jobs</p><p>It’s Monday morning. Did you wake up with energy or with dread?</p><p>Your answer will tell you if you’re settling.</p><h2 id="the-career-razor">The Career Razor</h2><p>When deciding on a new job, choose the one that will challenge you the most (intellectually, physically, or emotionally).</p><p>Challenge and discomfort forces growth.</p><p>(P.S. Check out the job board below for challenging new roles!)</p><h2 id="decisions">Decisions</h2><p>• If you can’t decide, the answer is no.</p><p>• If two equally difficult paths, choose the one more painful in the short term (pain avoidance is creating an illusion of equality).</p><p>• Choose the path that leaves you more equanimous in the long term."</p><h2 id="参考">参考</h2><ol type="1"><li>https://pallet.xyz/list/thebloomboard/jobs</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;基于剃刀原则的几个思维模型，from Sahil Bloom的twitter&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;the-steve-jobs-quality-razor&quot;&gt;The Steve Jobs Quality Razor&lt;</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="决策" scheme="https://chiechie.github.io/tags/%E5%86%B3%E7%AD%96/"/>
    
  </entry>
  
  <entry>
    <title>进程,线程和协程</title>
    <link href="https://chiechie.github.io/2021/06/27/reading_notes/computer/thread-and-process/"/>
    <id>https://chiechie.github.io/2021/06/27/reading_notes/computer/thread-and-process/</id>
    <published>2021-06-27T04:16:07.000Z</published>
    <updated>2021-07-02T00:47:36.273Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本定义">基本定义</h2><h3 id="进程process">进程（process）</h3><p>进程（process）有时候也称做任务，是指一个程序运行的实例。</p><p>我们想要计算机要做一项任务（task），我们会写一段代码（python/java等）。</p><p>编译器将它翻译成二进制代码--机器的语言。</p><p>但是此时不执行这段断码的话，就还是一段静态程序。</p><p>当执行起来的时候，就变成了一个进程。</p><h4 id="进程的3种状态">进程的3种状态</h4><p>从程序员的角度，可以认为进程总是处于下面三种状态之一：</p><ul><li><p>运行。进程要么在CPU上执行，要么在等待被执行且最终会被内核调度</p></li><li><p>停止。进程的执行被挂起（suspend），且不会被调度。当收到SIGSTOP/SIGTSTP/SIDTTIN/SIGTTOU信号时，进程就停止，直收到SIGCONT信号，这时，进程再次运行</p></li><li><p>终止。进程永远的停止了。进程会因为三种原因终止:</p><ol type="1"><li>收到一个终止进程的信号</li><li>从主程序返回；</li><li>调用exit函数。</li></ol></li></ul><h4 id="创建子进程">创建子进程</h4><ol type="1"><li>子进程得到与父进程用户级虚拟地址空间相同的（但是独立的）一份拷贝，包括文本、数据和bss段、堆以及用户栈。</li><li>子进程还获得与父进程任何打开文件描述符相同的拷贝。</li><li>父进程和新创建的子进程之间最大的区别在于它们有不同PID。</li><li>fork函数调用一次，返回两次，父进程中，fork返回子进程的PID，子进程中fork返回0。</li></ol><h4 id="进程的地址空间">进程的地址空间</h4><ol type="1"><li><p>进程提供给应用程序关键的抽象：</p><ul><li>一个独立的逻辑控制流，它提供一个假象，好像我们的程序独占地使用处理器</li><li>一个私有的地址空间，它提供一个假象，好像我们的程序独占地使用存储器系统</li></ul></li><li><p>每个程序都能看到一片完整连续的地址空间，这些空间并没有直接关联到物理内存，只是操作系统提供的对内存一种抽象，在程序的运行时，会将虚拟地址映射到物理地址。</p></li><li><p>进程的地址空间是分段的，存在所谓的数据段，代码段，bbs段，堆，栈等等。每个段都有特定的作用，下面这张图介绍了进程地址空间中的划分。 <img src="img_3.png" /></p></li><li><p>对于32位的机器来说，虚拟的地址空间大小就是4G，可能实际的物理内存大小才1G到2G，意味着程序可以使用比物理内存更大的空间。</p><ol type="1"><li>从0xc000000000到0xFFFFFFFF共1G的大小是内核地址空间，余下的低地址3G是用户地址空间。</li><li>Code VMA: 即程序的代码段，CPU执行的机器指令部分。通常，这一段是可以共享的，即多线程共享进程的代码段。并且，此段是只读的，不能修改。</li><li>Data VMA: 即程序的数据段，包含ELF文件在中的data段和bss段。</li><li>堆和栈: new或者malloc分配的空间在「堆」上，需要程序猿维护，如果没有主动释放堆上的空间，进程运行结束后会自动释放。「栈」上的是函数栈临时的变量，还有程序的局部变量，自动释放。</li><li>共享库和mmap内容映射区：位于栈和堆之间，例如程序使用的printf，函数共享库printf.o固定在某个物理内存位置上，让许多进程映射共享。mmap是一个系统函数，可以把磁盘文件的一部分直接映射到内存，这样文件中的位置直接就有对应的内存地址。</li><li>命令行参数: 程序的命令行参数</li><li>环境变量：类似于Linux下的PATH，HOME等环境变量，子进程会继承父进程的环境变量。</li></ol></li></ol><h3 id="线程threads">线程（threads）</h3><p>一个进程中的执行的单位。</p><p>线程（thread）：能并行运行，并且与他们的父进程（创建他们的进程）共享同一地址空间（一段内存区域）和其他资源的轻量级的进程</p><h3 id="协程coroutines">协程（CoRoutines）</h3><p>Co：即corperation，Routines即函数。</p><p>协程（CoRoutines）：即用来实现functions 即corperate with each other。</p><p><img src="img_2.png" /></p><p>不同的编程语言有不同的实现协程的方式，在python和js里面，用的较多的就是yield</p><p>用python实现一个协程</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_coroutine_body</span>(<span class="params">*args</span>):</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># Do some funky stuff</span></span><br><span class="line">        *args = <span class="keyword">yield</span> value_im_returning</span><br><span class="line">        <span class="comment"># Do some more funky stuff</span></span><br><span class="line"></span><br><span class="line">my_coro = make_coroutine(my_coroutine_body)</span><br><span class="line"></span><br><span class="line">x = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">   <span class="comment"># The coroutine does some funky stuff to x, and returns a new value.</span></span><br><span class="line">   x = my_coro(x)</span><br><span class="line">   <span class="built_in">print</span> x</span><br></pre></td></tr></table></figure><h3 id="生成器generator">生成器(generator)</h3><p>A generator is essentially a cut down (asymmetric) coroutine.</p><p>The difference between a coroutine and generator is that a coroutine can accept arguments after it's been initially called, whereas a generator can't.</p><h2 id="应用-vs-线程-vs-进程">应用 vs 线程 vs 进程</h2><p>一个应用，比如chrome，可能会启动多个进程（多个网页）, 一个进有多个线程。</p><p>进程和线程的区别：</p><ul><li>进程（火车）间不会相互影响，一个线程（车厢）挂掉将导致整个进程（火车）挂掉</li><li>线程（车厢）在进程（火车）下行进</li><li>一个进程（火车）可以包含多个线程（车厢）</li><li>不同进程（火车）间数据很难共享，同一进程（火车）下不同线程（车厢）间数据很易共享</li></ul><p>线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据， 进程之间的通信需要以通信的方式（IPC)进行</p><ul><li>进程要比线程消耗更多的计算机资源</li><li>进程间不会相互影响，一个线程挂掉将导致整个进程挂掉</li><li>进程可以拓展到多机，线程最多适合多核</li><li>进程使用的内存地址可以上锁，即一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。－"互斥锁"</li><li>进程使用的内存地址可以限定使用量－“信号量”</li></ul><h2 id="硬件多线程vs软件多线程">硬件多线程vs软件多线程</h2><p>CPU架构演进路线：</p><p>多cpu---&gt;超线程--&gt;多core</p><p>https://stackoverflow.com/questions/680684/multi-cpu-multi-core-and-hyper-thread</p><p>其中的超线程（hyper thread）指的硬件多线程，如下图，相当于给一个core，虚拟化为2个core，可以更方便压榨计算机性能</p><h2 id="多进程-or-多线程">多进程 or 多线程？</h2><p>多进程更稳定，但是多线程能达到更高的计算效率</p><figure><img src="img_1.png" alt="左边是单线程，右边是多线程" /><figcaption aria-hidden="true">左边是单线程，右边是多线程</figcaption></figure><p>多线程的优势：</p><ul><li>响应性：比如启动一个网页（启动一个浏览器进程），可以同时并行做个事情，如浏览/下载/问答（并行启动多个线程）。</li><li>资源共享：一个进程上的所有线程共享同一份内存，这样能够让机器的使用效率更高，可以做更多的复杂的事情。---赋能/增效</li><li>更经济： 多进程浪费资源，因为创建1个进程需要分配很多内存和资源，相比之下，创建和切换线程的成本小的多。另外，完成一个复杂的任务，多线程共用一份底层资源，多进程就需要把资源复制几份。又浪费了一遍。--降本</li><li>充分压榨多处理器的架构：</li></ul><blockquote><p>大中台类似多线程，烟囱式开发类似多进程</p></blockquote><h2 id="实践">实践</h2><h3 id="练习1-模拟单线程cpp的进程管理">练习1-模拟单线程CPP的进程管理</h3><p><a href="https://leetcode-cn.com/problems/single-threaded-cpu/">leetcode</a>的题目，</p><p>需求：实现一个任务管理/编排的机制，即，输入一堆任务，每个任务的计划执行时间/执行时长都有，现在有一台单线程CPU，如何安排这些任务的执行顺序？</p><p>分析： 设想应用场景，医院的排队系统/有一堆任务要排期。</p><p>一遍在执行已有的任务，一边有源源不断的接到新的任务，</p><p>每执行完一个任务，check一下距离上次检查，有多少新任务进来了，加到任务池里面，从里面选出最容易的。</p><p>设计1个数据结构：</p><p>1个是优先队列，存放候选任务，并且按照执行时间长短从小到到排序。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tasks = [[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">4</span>],[<span class="number">3</span>,<span class="number">2</span>],[<span class="number">4</span>,<span class="number">1</span>]]</span><br><span class="line">n = <span class="built_in">len</span>(tasks)</span><br><span class="line">timestamp = <span class="number">1</span></span><br><span class="line">candidate_list = []</span><br><span class="line">new_task = []</span><br><span class="line">j = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    <span class="keyword">while</span> (j &lt; n) <span class="keyword">and</span> (tasks[j][<span class="number">0</span>] &lt;= timestamp):</span><br><span class="line">        heapq.heappush(candidate_list, (tasks[j][<span class="number">1</span>], j))</span><br><span class="line">        j+=<span class="number">1</span></span><br><span class="line">        print(j, n)</span><br><span class="line">    print(candidate_list)</span><br><span class="line">    process, index = heapq.heappop(candidate_list)</span><br><span class="line">    print(candidate_list)</span><br><span class="line">    new_task.append(index)</span><br><span class="line">    timestamp += process</span><br><span class="line">new_task</span><br></pre></td></tr></table></figure><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.zhihu.com/question/25532384/answer/411179772">线程和进程的区别是什么？-zhihu</a></li><li><a href="https://www.youtube.com/watch?v=usyg5vbni34">Threading in Python - Advanced Python 16 - Programming Tutorial-youtube</a></li><li><a href="https://www.junmajinlong.com/os/multi_cpu/">计算机原理系列-blog</a></li><li><a href="https://www.junmajinlong.com/os/cpu_cache/">关于CPU上的高速缓存</a></li><li><a href="https://www.youtube.com/watch?v=tqay-vzqSN0">What are CoRoutines in Programming?YOUTUBE</a></li><li><a href="https://stackoverflow.com/questions/715758/coroutine-vs-continuation-vs-generator">生成器和协程</a></li><li><a href="https://buptjz.github.io/2014/04/23/processAndThreads">进程、线程及其内存模型</a></li><li>深入理解操作系统</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基本定义&quot;&gt;基本定义&lt;/h2&gt;
&lt;h3 id=&quot;进程process&quot;&gt;进程（process）&lt;/h3&gt;
&lt;p&gt;进程（process）有时候也称做任务，是指一个程序运行的实例。&lt;/p&gt;
&lt;p&gt;我们想要计算机要做一项任务（task），我们会写一段代码（python/j</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="计算机原理" scheme="https://chiechie.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/"/>
    
    <category term="线程" scheme="https://chiechie.github.io/tags/%E7%BA%BF%E7%A8%8B/"/>
    
    <category term="进程" scheme="https://chiechie.github.io/tags/%E8%BF%9B%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>计算机的存储单元</title>
    <link href="https://chiechie.github.io/2021/06/26/reading_notes/computer/cache-memory/"/>
    <id>https://chiechie.github.io/2021/06/26/reading_notes/computer/cache-memory/</id>
    <published>2021-06-26T01:47:32.000Z</published>
    <updated>2021-06-28T05:56:10.034Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概览">概览</h2><ol type="1"><li><p>计算机上的存储单元的处理速度从快到慢依次是： 寄存器&gt; L1&gt;L2&gt;L3&gt;内存&gt;固态硬盘&gt; 机械硬盘</p><figure><img src="./img_1.png" alt="存储单元" /><figcaption aria-hidden="true">存储单元</figcaption></figure></li><li><p>早期的计算机只有寄存器和内存，但是寄存器的处理速度远高于内存，所以大部分时间是寄存器在等内存，所以CPU是处于空转状态。 经过改进</p></li><li><p>除了寄存器，后面的计算机在CPU中又逐步加入了高速缓存--L1/L2/L3缓存，相当于让内存提前做功课，把数据提前取出来，在3个缓存中候着，等寄存器有空了就取来用。笨鸟先飞嘛。</p></li><li><p>L1/L2/L3缓存，每层速度递减、容量递增。L1缓存速度接近寄存器速度，大约1ns时延。</p></li><li><p>多核CPU的L3对诶个core是共享的，L2和L1是每个core私有的。</p></li></ol><figure><img src="./img_2.png" alt="img_2.png" /><figcaption aria-hidden="true">img_2.png</figcaption></figure><ol start="6" type="1"><li>CPU读取数据时，要从内存读取到L3，再读取到L2再读取到L1，同样写到内存时也会经过这些层次。</li></ol><h2 id="参考">参考</h2><ol type="1"><li>https://www.junmajinlong.com/os/cpu_cache/</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;概览&quot;&gt;概览&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;计算机上的存储单元的处理速度从快到慢依次是： 寄存器&amp;gt; L1&amp;gt;L2&amp;gt;L3&amp;gt;内存&amp;gt;固态硬盘&amp;gt; 机械硬盘&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;./img_1</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="计算机原理" scheme="https://chiechie.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/"/>
    
    <category term="内存" scheme="https://chiechie.github.io/tags/%E5%86%85%E5%AD%98/"/>
    
    <category term="缓存" scheme="https://chiechie.github.io/tags/%E7%BC%93%E5%AD%98/"/>
    
    <category term="寄存器" scheme="https://chiechie.github.io/tags/%E5%AF%84%E5%AD%98%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>数据结构基础</title>
    <link href="https://chiechie.github.io/2021/06/25/data_structure/data-structure-base/"/>
    <id>https://chiechie.github.io/2021/06/25/data_structure/data-structure-base/</id>
    <published>2021-06-25T01:17:29.000Z</published>
    <updated>2021-07-02T10:13:29.495Z</updated>
    
    <content type="html"><![CDATA[<h2 id="总结">总结</h2><ol type="1"><li><p>数据结构分为线性和非线性</p></li><li><p>线性包括数组列表栈队列</p><figure><img src="b3728c27302a8548fe9e8a87e619ca83.png" alt="线性数据结构" /><figcaption aria-hidden="true">线性数据结构</figcaption></figure></li><li><p>非线性包括树和图,树可以认为是有向图的special case <img src="e6d5a8d9a75587abe612dfef9abffc01.png" alt="非线性数据结构" /></p></li><li><p>图分有向图和无向图</p><figure><img src="18c651092d22c7204021d10a5a79b0ff.png" alt="有向图vs无向图" /><figcaption aria-hidden="true">有向图vs无向图</figcaption></figure></li><li><p>无向图的一个实例是fb的社交网络，边表示好友关系。</p><figure><img src="f3fc896014d62fb1ec1c96c93210f7ff.png" alt="社交网络" /><figcaption aria-hidden="true">社交网络</figcaption></figure></li><li><p>基于社交网络这个数据结构有什么应用呢？好友推荐, 推荐朋友的朋友,网络社会科学的小世界</p><blockquote><p>小世界网络的重要性质：“流行病学”、“合作”、“知识”</p></blockquote><figure><img src="d5fe57a166d6f2ee93457d0ea4b54cef0.png" alt="社交网路" /><figcaption aria-hidden="true">社交网路</figcaption></figure></li><li><p>有向图的一个实例是万维网,好有一个文章影响因子 <img src="b9b97250ce6e998045dcbb0d5b379724.png" alt="www" /></p></li><li><p>图还可以分有权图和无权图，无权图可认为是权图的special case，权重都为1。</p></li><li><p>有权图的一个实例是高速公路网,边代表距离 <img src="5b81b50b2d2b048ed3188b71af85a02f.png" alt="公路网" /></p></li><li><p>树的一个实例是家谱，树种，任意一对节点，有且只有一条通路（不存在loop嘛）</p></li><li><p>因果图是一个有向有权图。</p></li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.youtube.com/watch?v=gXgEDyodOJU">youtube</a></li><li><a href="https://www.youtube.com/watch?v=V_TulH374hw">Graph-theoretic Models</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;数据结构分为线性和非线性&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;线性包括数组列表栈队列&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;b3728c27302a8548fe9e8a87e619ca83.pn</summary>
      
    
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="编程" scheme="https://chiechie.github.io/tags/%E7%BC%96%E7%A8%8B/"/>
    
    <category term="数据结构" scheme="https://chiechie.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="图数据" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>一些聚类算法</title>
    <link href="https://chiechie.github.io/2021/06/23/AI/machine_learning/clustering/"/>
    <id>https://chiechie.github.io/2021/06/23/AI/machine_learning/clustering/</id>
    <published>2021-06-23T03:20:42.000Z</published>
    <updated>2021-07-02T09:24:56.308Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>除了kmeans，聚类算法中还有一类更简单直观的方法，就是层次聚类。</p></blockquote><h2 id="总结">总结</h2><ol type="1"><li>我们常常对表数据使用kmeans来实现聚类，其实也是分为两步，第一步是是将多维的表数据（维度代表特征），转为2D的相似图（一个节点代表一个样本）。第二步，是对这个图进行聚类。</li><li>kmeans在实际中应用较多，但是并没有理论保证其收敛。 &gt; ...I don't think there is a nice theory of convergence or rate of convergence, But is a very popular algorimth,..., But that's one sort of hack that works quite well--Gilbert Strang</li><li>对一个图，找到其中的一些cluster，kmeans是其中一种方法，还有谱聚类（spectral clustring）。</li><li>除此之外，还可以使用终极大招--使用数值方法去求解优化问题（比如BP，就是alternative methods的一个特例）。</li><li>按照理论严密从高到低，实现聚类的算法可以分为三类：谱聚类，基于运筹优化的聚类，一些直觉类的方法。直觉类的方法包括kmeans，层次聚类</li></ol><h2 id="聚类算法summary">聚类算法summary</h2><p>目前常用的聚类算法大概分为三类：</p><ul><li>层次聚类： nearest neigbour</li><li>基于分区的聚类（partitional）：Kmeans系列/FCM/图理论</li><li>基于密度：DBSCAN</li><li>其他：ACODF</li></ul><figure><img src="./img.png" alt="img.png" /><figcaption aria-hidden="true">img.png</figcaption></figure><h2 id="层次聚类">层次聚类</h2><p>层次聚类算法,又称为树聚类算法,它使用数据的联接规则,透过一种层次架构方式,反复将数据进行分裂或聚合,以形成一个层次序列的聚类问题解.</p><p>本文仅以层次聚类算法中的层次聚合算法为例进行介绍.</p><p>层次聚合算法的时间复杂度为<span class="math inline">\(O(n^2)\)</span>,适合于小数据集的分类.</p><p>该算法由树状结构的底部开始逐层向上进行聚合,假定样本集S={o1,o2,...,on}共有n个样本.</p><ol type="1"><li>初始化：每个样本 <span class="math inline">\(o_i\)</span> 为一个类; 共形成 n 个类:<span class="math inline">\(o_1,o_2,...,o_n\)</span></li><li>找最近的<strong>两个类</strong>：从现有所有类中找出相似度最大的<strong>两个</strong>类<span class="math inline">\(o_r\)</span> 和 <span class="math inline">\(o_k\)</span> <span class="math display">\[distance(o_r,o_k) = min_{\forall{o_u,o_v \in S,o_u \neq o_v}}distance(o_u,o_v)\]</span></li><li>将类<span class="math inline">\(o_r\)</span>和<span class="math inline">\(o_k\)</span>合并成一个新类<span class="math inline">\(o_{rk}\)</span>，现有cluster个数减1</li><li>若所有的样本都属于同一个类,则终止;否则,返回步骤2.</li></ol><p>层次聚类最大的优点，它一次性地得到了整个聚类的过程。如果想要改变cluster个数，不需要重新训练聚类模型，取聚类树的中间某一层就好了。相比之下kmeans是要重新弄训练的。</p><p>层次聚类的缺点是计算量比较大，因为要每次都要计算多个cluster内所有数据点的两两距离，复杂度是O(n^2*d)，d表示聚类树的深度。</p><p>还有一个缺点，超参数比较难设置，跟kmeans一样。最终到底聚成多少类，需人工给定一个distance threshold，这个阈值跟sample有关，跟距离函数的定义也有关，并且聚类结果对这个参数比较敏感。</p><p>btw，如何判断两个cluster之间的距离？</p><ul><li>一开始每个数据点独自作为一个类，它们的距离就是这两个点之间的距离。</li><li>对于包含不止一个数据点的cluster，最常用的方法是average-linkage，即计算两个cluster各自数据点的两两距离的平均值。 其他方法还有single-linkage/complete-linkage，选择两个cluster中距离最短/最长的一对数据点的距离作为类的距离。 个人经验complete-linkage基本没用，single-linkage通过关注局域连接，可以得到一些形状奇特的cluster，但是因为太过极端，所以效果也不是太好。</li></ul><h2 id="基于graph的聚类">基于Graph的聚类</h2><p>基于Graph的聚类算法，大致思路是，计算样本两两之间的相似度，并设定阈值，高于阈值就右边，低于阈值就无边，以此构造有权无向图，权重即为相似度。</p><h3 id="谱聚类">谱聚类</h3><p>什么是spectrum？</p><p>矩阵的spectrum就是矩阵的特征根。 spectral clustring就是使用矩阵的特征根聚类</p><p>回忆一下，其拉普拉斯矩阵定义为 <span class="math inline">\(L=D-A\)</span>.</p><p>怎么根据L来找到目标的clusters（or centriod）？ 对L进行谱分解（特征根分解），并且找到L的fieder向量。</p><p>fieder向量中的元素有正的，也有负的， 正的位置对应的样本分配到cluster1，负元素对应的样本分配到cluster2</p><p>谱聚类的流程是：</p><p>输入：n个样本, 类别k</p><ol type="1"><li>根据样本两两之间的相似度，构建有权无向图，以及邻接矩阵W。</li><li>计算出拉普拉斯矩阵L，对L做谱分解（相当于降维）：计算拉普拉斯矩阵L的最小的k个特征值对应的特征向量u1, u2,...,uk,将这些向量组成n*k维的矩阵U,</li><li>将U中的每一行作为一个样本，共n个样本，使用k-means对这n个样本进行聚类</li></ol><p>得到簇划分C(c1,c2,...ck).</p><h2 id="聚类应用">聚类应用</h2><h3 id="日志分析">日志分析</h3><h3 id="图像分割">图像分割</h3><p>图像的分割是图聚类的其中一个应用场景。</p><p>层次聚类可看成框架，而基于图的图像分割是在层次聚类上加了骨头，使他更适用于图像分割的领域，而使用者可以在骨头上继续加肉来达到不同的分割效果。</p><p>图像中的每一个像素点是一个item，图像分割的任务即对所有items聚类，属于一个cluster的所有像素就构成了一个区域， 最终的分割结构就是若干个区域（即clusters）组成的。由此我们过渡到本文的第二部分，</p><p>基于图的图像分割算法，主要流程如下</p><p>输入一个图<span class="math inline">\(G=(V,E)\)</span>，有n个点和m个边。输出是一个分割V，分割成<span class="math inline">\(S=(C_1,...,C_2).\)</span></p><ol type="1"><li><p>对边E进行排序，生成非递减的序列<span class="math inline">\(\pi = (o_1,...,o_m)\)</span></p></li><li><p>从初始分割<span class="math inline">\(S^0\)</span>开始，每一个点<span class="math inline">\(v_i\)</span>自己就是一个区域</p></li><li><p>对于每一个边<span class="math inline">\(q = 1,...,m\)</span>重复步骤3，通过<span class="math inline">\(S^{q-1}\)</span>构建<span class="math inline">\(S^q\)</span>，使用如下的方式</p><ul><li>令<span class="math inline">\(v_i\)</span>和<span class="math inline">\(v_j\)</span>表示按顺序排列的第q条边的两个点，比如<span class="math inline">\(o_q = (v_i,v_j)\)</span>。</li><li>如果<span class="math inline">\(v_i\)</span>和<span class="math inline">\(v_j\)</span>在<span class="math inline">\(S^{q-1}\)</span>中连个不同的区域下，并且<span class="math inline">\(w(o_q)\)</span>比两个区域的内部差异都小，那么合并这连个区域，否则什么也不做。</li><li>用公式来表达就是：<ul><li>令<span class="math inline">\(C_{i}^{q-1}\)是\(S^{q-1}\)</span>的一个区域，它包含点<span class="math inline">\(v_i\)</span>；令<span class="math inline">\(C_{j}^{q-1}\)是\(S^{q-1}\)</span>的一个区域，它包含点<span class="math inline">\(v_j\)</span>。</li><li>如果<span class="math inline">\(C_{i}^{q-1} \neq C_{j}^{q-1}\)</span> 并且<span class="math inline">\(w(o_q) \leq MInt(C_i^{q-1},C_j^{q-1})\)</span>，那么通过合并<span class="math inline">\(C_{i}^{q-1}\)</span>和<span class="math inline">\(C_{j}^{q-1}\)</span>得到了<span class="math inline">\(S^q\)</span>；</li><li>否则的话<span class="math inline">\(S^q = S^{q-1}\)</span>，返回<span class="math inline">\(S = S^m\)</span></li></ul></li></ul></li></ol><p>图像分割结果如下</p><figure><img src="img1.png" alt="图像分割" /><figcaption aria-hidden="true">图像分割</figcaption></figure><h2 id="参考">参考</h2><ol type="1"><li><a href="https://patentimages.storage.googleapis.com/34/c0/df/3417293b1602a5/CN105468677A.pdf">一种基于图结构的日志聚类算法</a></li><li><a href="https://zhuanlan.zhihu.com/p/78382376">常用聚类算法综述</a></li><li><a href="https://buptjz.github.io/2014/04/21/cluster">从层次聚类到Graph-based图像分割</a></li><li><a href="http://www.jos.org.cn/1000-9825/19/48.pdf">聚类算法</a></li><li><a href="https://www.youtube.com/watch?v=cxTmmasBiC8">35. Finding Clusters in Graphs-mit-youtube</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;除了kmeans，聚类算法中还有一类更简单直观的方法，就是层次聚类。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;我们常常对表数据使用kmeans来实现聚类，其实也是分为两步，第一</summary>
      
    
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="图数据" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE/"/>
    
    <category term="聚类" scheme="https://chiechie.github.io/tags/%E8%81%9A%E7%B1%BB/"/>
    
    <category term="日志聚类" scheme="https://chiechie.github.io/tags/%E6%97%A5%E5%BF%97%E8%81%9A%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>图数据基础</title>
    <link href="https://chiechie.github.io/2021/06/22/data_structure/graph/graph-basic/"/>
    <id>https://chiechie.github.io/2021/06/22/data_structure/graph/graph-basic/</id>
    <published>2021-06-22T03:42:17.000Z</published>
    <updated>2021-07-02T10:29:07.111Z</updated>
    
    <content type="html"><![CDATA[<h2 id="总结">总结</h2><ol type="1"><li>图不仅仅通过边存储静态的信息，还能基于边，inference更多的信息。</li></ol><h2 id="真实世界中的网络">真实世界中的网络</h2><ol type="1"><li>计算机网络：互联网</li><li>交通网络（铁路网，公路网）</li><li>金融网络</li><li>下水道网络</li><li>政治网络</li><li>犯罪网络</li></ol><h2 id="图的定义">图的定义</h2><p>传统的空间都是定义在欧几里得空间（Euclidean Space）的，在该空间定义的距离被称为欧式距离。 音频，图像，视频等都是定义在欧式空间下的欧几里得结构化数据，然而对于社交网络等数据，使用欧几里得空间进行定义并不合适，所以将这一类的数据所处的空间称为非欧几里得空间。</p><p>非欧空间下最有代表的结构就是图（Graph）结构， 每一个图都有对应的4个矩阵：incidence matrix,A/degree matrix/adjacency matrix/拉普拉斯矩阵（laplacian matrix， L）</p><p>incidence matrix:<span class="math inline">\(A \ in R^{m *n}\)</span>, m 是边的个数，n是节点的个数 每一行代表一条边的起点（也叫parent）和终点（也叫children）</p><figure><img src="img_2.png" alt="img_2.png" /><figcaption aria-hidden="true">img_2.png</figcaption></figure><h3 id="邻接矩阵adjacency-matrix">邻接矩阵（Adjacency matrix）</h3><p>邻接矩阵是一个NxN的矩阵，对于有权图，其值为权重或0，对于无权图，其值为0和1，该矩阵定义如下： <span class="math display">\[A \in R^{N \times N}, A_{i j}=\left\{\begin{array}{ll}a_{i j} \neq 0 &amp; e_{i j} \in E \\ 0 &amp; \text { othersize }\end{array}\right.\]</span></p><h3 id="度矩阵degree-matrix">度矩阵（Degree matrix）</h3><p>度矩阵D是一个对角矩阵，其定义为：</p><p><span class="math display">\[D \in R^{N \times N}, D_{i i}=\sum_{j} A_{i j}\]</span></p><h3 id="邻域neighborhood">邻域（Neighborhood）</h3><p>邻域表示与某个顶点有连接的点集，其定义为：<span class="math display">\[N\left(v_{i}\right)=\left\{v_{j} \mid e_{i j} \in E\right\}\]</span></p><h3 id="谱spectral">谱（Spectral）</h3><h3 id="拉普拉斯矩阵lapalcian-matrix">拉普拉斯矩阵（Lapalcian matrix）</h3><h4 id="谱分解spectral-factorization">谱分解(Spectral Factorization)</h4><p>什么是spectrum？ 矩阵的spectrum就是矩阵的特征根。 只有方阵才有谱概念，方阵作为线性算子，其所有特征值的集合称为方阵的谱。方阵的谱半径为其最大的特征值，谱分解就是特征分解。</p><p>谱分解(Spectral Factorization)又叫特征值分解，实际上就是对n维方阵做特征分解. 只有含有n个线性无关的特征向量的n维方阵才可以进行特征分解.</p><blockquote><p>spectral定理用公式表达：对于一个对称矩阵S，其特征根<span class="math inline">\(\Lambda\)</span>都是实数, 特征向量都正交<span class="math inline">\(Q\)</span></p><blockquote><p><span class="math display">\[S = Q\LambdaQ^T\]</span></p></blockquote></blockquote><p>graph laplacian 矩阵：connection of 线性代数和图论</p><p>拉普拉斯矩阵（laplacian matrix），<span class="math inline">\(L \ in R^{n *n}\)</span> <span class="math display">\[L = A^T A= D-B\]</span></p><p>degree matrix：<span class="math inline">\(D \ in R^{n*n}\)</span>，代表了每个节点有多少degree adjaceny matrix：<span class="math inline">\(B \ in R^{n*n}\)</span>，代表了任意两个点是否有link</p><p>拉普拉斯矩阵是半正定矩阵,其特征根从小到达排序 1. 第一个特征根为0，<span class="math inline">\(\lambda_1 = 0\)</span>, 即DIM(null space) = 1，对应的特种向量为常熟向量 2. 第二个特征根（最小的正的特征根）叫fiedler， 对应的特征向量叫fiedler vector</p><p>graph的laplacian矩阵和laplace方程（有限差分方法）的关系：</p><p>laplace方程也叫微分方程，其微分形式 跟一个网格图的laplacian矩阵（n*n）就是离散形式。</p><ol start="3" type="1"><li>实对称矩阵,有n个线性无关的特征向量;</li><li>其特征向量可以进行正交单位化;</li><li>所有的特征值非负;</li></ol><p><span class="math display">\[L=U\left(\begin{array}{ccc}\lambda_{1} &amp; &amp; \\ &amp; \ddots &amp; \\ &amp; &amp; \lambda_{n}\end{array}\right) U^{-1}=U\left(\begin{array}{ccc}\lambda_{1} &amp; &amp; \\ &amp; \ddots &amp; \\ &amp; &amp; \lambda_{n}\end{array}\right) U^{T}\]</span></p><p>有时，使用的都是正规拉普拉斯矩阵（Symmetric Normalized Laplacian matrix）: <span class="math display">\[L^{s y s}=D^{-1 / 2} L D^{-1 / 2}=I-D^{-1 / 2} A D^{-1 / 2}\]</span></p><h2 id="图的算法">图的算法</h2><p>基于这个网络，可以做一些什么分析呢？聚类分析，</p><p>即，找到一些cluster，内部的距离很小，之间的距离很大，这个可以抽象成求最大割或者最小流问题 通常还有一些其他的基于图的问题：</p><p>比如，给定一个图，任意两个元素之间是否存在一个link？如果存在，最快捷的路径是什么？</p><p>还有一个经典的问题--'图分割'（graph partition）</p><h3 id="s-t-cut">S-T Cut</h3><p>S-T Cut 就是把一个图切成了两个子图，S和T</p><figure><img src="img.png" alt="img.png" /><figcaption aria-hidden="true">img.png</figcaption></figure><p>S-T cut的容量，就是链接S,C的变（图中红色的边）的权重求和，</p><figure><img src="img_1.png" alt="img_1.png" /><figcaption aria-hidden="true">img_1.png</figcaption></figure><h3 id="最小割">最小割</h3><p>最小割（min -cut），就是容量最小的那个S-T cut</p><figure><img src="img_2.png" alt="img_2.png" /><figcaption aria-hidden="true">img_2.png</figcaption></figure><p>最小割是指去掉图中的一些边，在使得图从连通图变为不连通图，并且尽可能保证去除的边对应的权重很小。</p><p>最小割可能并不唯一</p><p>对于相似性图来说，最小割就是要去除一些很弱的相似性，把数据点从一个连通的大图切割成多个独立的连通小图。</p><h2 id="参考">参考</h2><ol type="1"><li>https://zhuanlan.zhihu.com/p/84271169</li><li><a href="https://www.youtube.com/watch?v=V_TulH374hw">Graph-theoretic Models</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;图不仅仅通过边存储静态的信息，还能基于边，inference更多的信息。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;真实世界中的网络&quot;&gt;真实世界中的网络&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;计算机网</summary>
      
    
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="图算法" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E7%AE%97%E6%B3%95/"/>
    
    <category term="图" scheme="https://chiechie.github.io/tags/%E5%9B%BE/"/>
    
    <category term="拓扑数据" scheme="https://chiechie.github.io/tags/%E6%8B%93%E6%89%91%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>细说红楼梦</title>
    <link href="https://chiechie.github.io/2021/06/21/reading_notes/zhexue/hongloumengxishuo/"/>
    <id>https://chiechie.github.io/2021/06/21/reading_notes/zhexue/hongloumengxishuo/</id>
    <published>2021-06-21T02:02:37.000Z</published>
    <updated>2021-06-22T06:21:25.475Z</updated>
    
    <content type="html"><![CDATA[<h2 id="第一回">第一回</h2><p>空空道人有批注：“因空见色，由色生情，传情入色，自色悟空，遂易名为情僧……”</p><p>“因空见色”，是说本来就白茫茫一片，什么都没有，（六祖慧能：本来无一物），因为我们的幻觉，看到好多好多的现象，“由色生情”，情多了就会陷进去，陷进了更深的色的幻觉，“传情入色”，要经过多少彻悟之后，再从里面出来，“自色悟空”，再回到白茫茫一片真干净。</p><p>甄士隐经了这许多人生起伏，有一天突然又看见跛足道士来了，口里唱一首《好了歌》：</p><blockquote><p>世人都晓神仙好，惟有功名忘不了！古今将相在何方？荒冢一堆草没了。世人都晓神仙好，只有金银忘不了！终朝只恨聚无多，及到多时眼闭了。世人都晓神仙好，只有姣妻忘不了！君生日日说恩情，君死又随人去了。世人都晓神仙好，只有儿孙忘不了！痴心父母古来多，孝顺儿孙谁见了？</p></blockquote><p>甄士隐说：“你唱什么？我只听见‘好’‘了’、‘好’‘了’两个字。道人说：</p><blockquote><p>好便是了，了便是好。若不了，便不好；若要好，须是了。</p></blockquote><p>跛足道人讲的是道家的哲学，对儒家社会秩序，有很大的颠覆性。儒家修身齐家治国平天下这一套道理，要建立的是稳定的社会秩序（social order），鼓励人入世，求功名、利禄、妻子、儿女，儒家宗法社会下面，大概就是这些。</p><p>跛足道人给了很大的一个警告，好就是了，了就是好，等于给恋恋在红尘中的人临头棒喝、醍醐灌顶。</p><p>人大概都经过几个阶段：年轻的时候，大家都是入世哲学，儒家那一套，要求功名利禄。到了中年，大概受了些挫折，于是道家来了，点你一下，有所醒悟。到了最后，要超脱人生境界的时候，佛家就来了。</p><p>所以过去的中国人，从儒道释，大致都经过这么三个阶段，有意思的是这三个阶段不冲突。在同一个人身上，这三样哲学都有。所以中国人既出世又入世的态度，常常造成整个文化的一种紧张，也就是说，我们的人生态度在这之间常常有一种徘徊迟疑，我想，这就是文学的起因。</p><p>文学写什么呢？写一个人求道提升，讲他的目标求道，讲这一生多么地艰难，往往很多人没有求到，在半路已经失败。不管是爱情也好，理想也好，各种的失败，我想，文学写的就是这些。《红楼梦》写的也是这些。</p><p>甄士隐对《好了歌》的注解：</p><blockquote><p>陋室空堂，当年笏满床；衰草枯杨，曾为歌舞场。蛛丝儿结满雕梁，绿纱今又糊在蓬窗上。说什么脂正浓、粉正香，如何两鬓又成霜？昨日黄土陇头送白骨，今宵红灯帐底卧鸳鸯。金满箱，银满箱，展眼乞丐人皆谤。正叹他人命不长，那知自己归来丧！训有方，保不定日后作强梁。择膏粱，谁承望流落在烟花巷！因嫌纱帽小，致使锁枷扛；昨怜破袄寒，今嫌紫蟒长：乱烘烘你方唱罢我登场，反认他乡是故乡。甚荒唐，到头来都是为他人作嫁衣裳！</p></blockquote><p>人生不就是个大舞台，一个人唱完下来，第二个人上去唱，唱完又一鞠躬下台，又换个人上去唱，“乱烘烘你方唱罢我登场”，然后“反认他乡是故乡”。</p><p>佛家说，我们以为这是我们自己的故乡，其实也靠不住，一下子一把火就整个烧掉了。道家说，要醒悟这一点，才找到你真正理想的地方。甚荒唐！到头来都是为他人做嫁衣裳。讲起来，整个一生是白忙一场，都为他人做嫁衣裳，所有事情都是为他人做的。</p><p>甄士隐、贾雨村，一个代表出世，一个代表入世。后来甄士隐变成道士，贾雨村经过好多官宦历程的折腾，到了书结束的时候，这两人又碰到一起。甄士隐想要度化贾雨村，贾雨村还是迷恋红尘。各走各的路，两个分歧，自己去看，自己去选择。</p><h2 id="第二章">第二章</h2><p>贾政，自觉是遵从儒家理想的一个人。他非常正直，也想用儒家那一套思想道德来持家，但是太过守法，太过拘束了。中国社会能够生存下来，光靠儒家思想、书生之见是不够的，还需要别种哲学，譬如很要紧的法家，很实在的、很现实的顶在后边。儒家的很多理想不一定都能实现，碰到了现实问题，常常不能解决。不过儒家也很重要，它是一种道德力量（moral force），没有它也不行，但光是有它也不行，所以，还要配合别的东西。</p><p>贾雨村听冷子兴讲了半天贾宝玉这个怪人，也发表了一篇言论：</p><p>“天地生人，除大仁大恶两种，馀者皆无大异。若大仁者，则应运而生，大恶者，则应劫而生。运生世治，劫生世危。尧、舜、禹、汤、文、武、周、召、孔、孟、董、韩、周、程、张、朱，皆应运而生者。蚩尤、共工、桀、纣、始皇、王莽、曹操、桓温、安禄山、秦桧等，皆应劫而生者。大仁者，修治天下；大恶者，挠乱天下。清明灵秀，天地之正气，仁者之所秉也；残忍乖僻，天地之邪气，恶者之所秉也。今当运隆祚永之朝，太平无为之世，清明灵秀之气所秉者，上至朝廷，下及草野，比比皆是。所馀之秀气，漫无所归，遂为甘露、为和风，洽然溉及四海。彼残忍乖僻之邪气，不能荡溢于光天化日之中，遂凝结充塞于深沟大壑之内，偶因风荡，或被云摧，略有摇动感发之意，一丝半缕误而泄出者，偶值灵秀之气适过，正不容邪，邪复妒正，两不相下，亦如风水雷电，地中既遇，既不能消，又不能让，必至搏击掀发后始尽。故其气亦必赋人，发泄一尽始散。使男女偶秉此气而生者，在上则不能成仁人君子，下亦不能为大凶大恶。置之于万万人中，其聪俊灵秀之气，则在万万人之上；其乖僻邪谬不近人情之态，又在万万人之下。若生于公侯富贵之家，则为情痴情种；若生于诗书清贫之族，则为逸士高人；纵再偶生于薄祚寒门，断不能为走卒健仆，甘遭庸人驱制驾驭，必为奇优名娼。如前代之许由、陶潜、阮籍、嵇康、刘伶、王谢二族、顾虎头、陈后主、唐明皇、宋徽宗、刘庭芝、温飞卿、米南宫、石曼卿、柳耆卿、秦少游，近日之倪云林、唐伯虎、祝枝山，再如李龟年、黄幡绰、敬新磨、卓文君、红拂、薛涛、崔莺、朝云之流，此皆易地则同之人也。”</p><h2 id="第四章">第四章</h2><p>再看看贾雨村这个人，他也是有高度象征性的一个人，象征这个世界上每一个为求功名利禄不择手段往上爬的凡俗之人。</p><p>贾雨村刚刚做官，还不太清楚。葫芦僧就讲，贾、王、史、薛这四大家族是互相牵连、互相庇护的，你一动薛家，其他家族就暗中使力，根本没法去办他们。的确是！后来薛蟠又打死人，贾家去讲讲情也就过了。</p><p>为官为政的这些人，像贾雨村者也是很典型的，一旦发迹，若从前是贫贱出身，他不愿意人家知道他的过去，哪个不长心眼儿的去碰他的过去的话，砍掉！因为他要维持现在的形象，掩掉过去。后来贾家没落的时候，贾雨村果然对有恩的贾家加踹一脚，这正是官场反复无情的写照。</p><h2 id="第五章">第五章</h2><p>无常，我们看起来好像是个悲剧，在佛家看，人所有的一切就是如此。佛教很理性地看待人生，看待一切的事物，没有永远存在的东西，因为时间会破坏一切、会毁灭一切，有时间的转动，春夏秋冬的转动，就会有无常现象。人生无常，什么都无常。所以，“生关死劫谁能躲？闻说道，西方宝树唤婆娑，上结着长生果。”这是惜春的醒悟！佛教的传说，佛陀释迦牟尼圆寂的时候，是在两棵宝树中间，那两棵宝树叫作“娑罗”。佛教对“婆娑”两字另有所解，长生果，佛家讲修成正果，要悟道了以后，从而解脱。最后惜春出家了，她是找到解脱最彻底的一个人物。</p><p>王熙凤，机关算尽太聪明，她最精明，涉入红尘也最深，《好了歌》讲：“世人都晓神仙好，只有金银忘不了！”等到聚多之时缘尽了。凤姐放高利贷，到处攒钱，聚敛多时，一下子抄家抄得精光，一场空欢喜！她在贾府最得宠，掌大权，抄家的原因之一是她放高利贷给抄出来了，一世的颜面丢得精光。“反算了卿卿性命”，后来王熙凤的下场也很悲惨。</p><p>对照一下，惜春走一条路，王熙凤走另外一条路，一个出世，一个入世，两种不同的道路。甄士隐跟贾雨村，也是出世和入世的辩证。曹雪芹从未批判哪方，他只是写出各人选的道路。儒家的入世在《红楼梦》的结局也很重要，贾府衰败，王熙凤死了，也还有接班人，谁呢？薛宝钗，她把贾府重新扛起来，这就是人生。</p><p>中国人的人生，常常有三种哲学的循环。年轻的时候有所求，中年醒悟，晚年一切看开。有这三种哲学，才是完整的中国文化，三者相克相生，互用互补。 《红楼梦》曲最后收尾的曲子：</p><blockquote><p>为官的，家业凋零；富贵的，金银散尽；有恩的，死里逃生；无情的，分明报应。欠命的，命已还；欠泪的，泪已尽。冤冤相报实非轻，分离聚合皆前定。欲知命短问前生，老来富贵也真侥幸。看破的，遁入空门；痴迷的，枉送了性命。好一似食尽鸟投林，落了片白茫茫大地真干净！</p></blockquote><h2 id="第16回">第16回</h2><p>儒家跟道家人生观，宇宙、社会的看法，互相冲突。《红楼梦》的悲剧，并不是一个突发性的意外，而是人生必然的过程，</p><h2 id="第22回">第22回</h2><p>宝玉出的灯谜：南面而坐，北面而朝，“象忧亦忧，象喜亦喜”。 佛家有一句话说镜花水月，一切都是幻象。宝玉看到的一切，由色入空，一切都是幻象。</p><h2 id="参考">参考</h2><ol type="1"><li>https://weread.qq.com/web/reader/3c432fc05d0f283c488450e</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;第一回&quot;&gt;第一回&lt;/h2&gt;
&lt;p&gt;空空道人有批注：“因空见色，由色生情，传情入色，自色悟空，遂易名为情僧……”&lt;/p&gt;
&lt;p&gt;“因空见色”，是说本来就白茫茫一片，什么都没有，（六祖慧能：本来无一物），因为我们的幻觉，看到好多好多的现象，“由色生情”，情多了就会陷进</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="道家" scheme="https://chiechie.github.io/tags/%E9%81%93%E5%AE%B6/"/>
    
    <category term="佛家" scheme="https://chiechie.github.io/tags/%E4%BD%9B%E5%AE%B6/"/>
    
    <category term="人生哲学" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E7%94%9F%E5%93%B2%E5%AD%A6/"/>
    
    <category term="儒家" scheme="https://chiechie.github.io/tags/%E5%84%92%E5%AE%B6/"/>
    
  </entry>
  
  <entry>
    <title>概率图简介</title>
    <link href="https://chiechie.github.io/2021/06/19/data_structure/graph/gailvtu/"/>
    <id>https://chiechie.github.io/2021/06/19/data_structure/graph/gailvtu/</id>
    <published>2021-06-19T08:52:21.000Z</published>
    <updated>2021-06-28T02:12:21.520Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本概念">基本概念</h2><p>概率图模型(Probabilistic Graphical Model，PGM)，简称图模型(Graphical Model，GM)，首先是一种概率模型，其次，它用图结构描述多个随机变量之间的依赖关系，它是研究高维空间中的概率模型的一种有用工具。</p><p>概率图模型有三个基本问题: 表示问题，学习问题和推断问题</p><p><img src="https://img.mubu.com/document_image/e3036b4e-18d3-4e73-b996-eafe4a4c08d1-3380623.jpg" /></p><h3 id="表示问题">1. 表示问题</h3><p>表示问题，即对于一个概率模型，如何通过图结构来描述变量之间的依赖关系。</p><h4 id="有向图模型directed-graphical-model">有向图模型(Directed Graphical model)</h4><p>有向图模型(Directed Graphical model)，也称为贝叶斯网络(Bayesian Network)，或信念网络(Belief Network，BN)，是指用有向图来表示概率分布的图模型。</p><figure><img src="https://img.mubu.com/document_image/75c9420a-058f-4005-a4b2-4609e7987c1b-3380623.jpg" alt="贝叶斯网络" /><figcaption aria-hidden="true">贝叶斯网络</figcaption></figure><p>很多机器学习模型可以用有向图模型来描述，比如</p><ul><li>朴素贝叶斯分类器</li><li>隐马尔可夫模型</li><li>深度信念网络(sigmoid 信念网络)</li></ul><h4 id="无向图模型">无向图模型</h4><p>无向图模型也称为马尔可夫随机场(Markov Random Field，MRF)或 马尔可夫网络(Markov Network)，是一类用无向图来描述一组具有局部马尔可夫性质的随机向量 X 的联合概率分布的模型。</p><figure><img src="https://img.mubu.com/document_image/85a18510-051c-4339-a808-4d3759095432-3380623.jpg" alt="无向图模型" /><figcaption aria-hidden="true">无向图模型</figcaption></figure><ul><li><p>如果(G,X)满足局部马尔可夫性质， 即一个变量 Xk 在给定它的邻居的情况下独立于所有其它变量，</p></li><li><p>无向图模型的概率分解</p><ul><li>因子分解 :无向图中的的联合概率可以分解为一系列定义在最大团上的非负函数的乘积形式。</li><li>吉布斯分布 :无向图模型和吉布斯分布是一致的。吉布斯分布一定满足马尔可夫随机场的条件独立性质，并且马尔可夫随机场的概率分布一定可以表示成吉布斯分布。</li></ul></li><li><p>常见的无向图模型:很多经典的机器学习模型可以使用无向图模型来描述，比如</p><ul><li>对数线性模型(Log-Linear Model)或最大熵模型(Maximum Entropy Model)</li><li>条件随机场(Conditional Random Field，CRF)</li><li>玻尔兹曼机</li><li>受限玻尔兹曼机等</li></ul></li><li><p>有向图和无向图之间的转换:</p><ul><li>无向图模型可以表示有向图模型无法表示的一些依赖关系，比如循环依赖;</li><li>无向图模型不能表示有向图模型能够表示的某些关系，比如因果关系。</li></ul></li></ul><h3 id="推断问题">2. 推断问题</h3><p>推断问题，即在已知部分变量时，计算其它变量的后验概率分布。</p><p>图模型的推断问题可以转换为求任意一个变量子集的边际概率分布问题。</p><h4 id="精确推断">精确推断</h4><p>精确推断的方法有变量消除法和信念传播方法</p><p>信念传播(Belief Propagation，BP)算法，也称为和积(Sum-Product)算法 或消息传递(Message Passing)算法，是将变量消除法中的和积(Sum-Product) 操作看作是消息，并保存起来，这样可以节省大量的计算资源。</p><p>链式结构上的的信念传播算法</p><p><img src="https://img.mubu.com/document_image/bd0b3e40-76a5-42e2-8716-799247eddc32-3380623.jpg" /></p><p>树结构上的信念传播算法：</p><ul><li>从叶子节点到根节点依次计算并传递 消息;</li><li>从根节点开始到叶子节点，依次计算并传递消息;</li><li>在每个节点上 计算所有接收消息的乘积(如果是无向图还需要归一化)，就得到了所有变量的 边际概率。</li></ul><p>环路信念传播</p><h4 id="近似推断">近似推断</h4><p>图模型中有些变量的局部条件分布可能非常复杂，或其积分无法计算。需要使用数值方法来近似，比如，变分法和采样法</p><h5 id="变分法">变分法</h5><p>变分法(Variational Method)是引入一个变分分布(通常是比较简单的分布)来近似复杂的局部条件概率，然后通过迭代的方法计算后验分布。</p><h5 id="采样法">采样法</h5><p>采样法(SamplingMethod) 是通过simulation的方式来采集符合某个分布 p(x) 的一些样本，并通过这些样本来估计和这个分布有关的运算，比如期望等。</p><ol type="1"><li>拒绝采样(Rejection Sampling):也叫接受-拒绝采样(Acceptance-RejectionSampling)：假设原始分布 p(x) 难以直接采样，可引入一个容易采样的分布 q(x)， 一般称为提议分布(Proposal Distribution)，然后以某个标准来拒绝一部分的样本使得最终采集的样本服从分布p(x)。</li></ol><p><img src="https://img.mubu.com/document_image/f6ae17af-597a-4445-abbf-2c2b0a5bce67-3380623.jpg" /></p><ol start="2" type="1"><li>重要性采样(Importance Sampling):通过引入重要性权重，将分布p(x)下f(x)的期望变为在分布q(x)下f(x)w(x)的期望.如果采样的目的是计算分布 p(x)下函数f(x)的期望，那么实际上抽取的样本不需要严格服从分布p(x)。也可以通过另一个分布，即提议分布q(x)，直接采样并估计。</li><li>马尔可夫链蒙特卡罗(Markov Chain Monte Carlo，MCMC): 在高维空间中拒绝采样和重要性采样效率低，<ul><li>Metropolis-Hastings算法，以及两个特例Metropolis算法和吉布斯采样(Gibbs Sampling)</li><li>Metropolis算法，假设MH算法中的提议分布是对称的</li><li>吉布斯采样(Gibbs Sampling)，用全条件概率(Full Conditional Probability)作为提议分布来依次对每个维度 进行采样，并设置接受率为A = 1。</li></ul></li></ol><blockquote><p>蒙特卡罗的基本思想可以归结为，根据一个已知概率密度函数为 p(x) 的 分布来计算函数 f (x) 的期望</p></blockquote><h3 id="学习问题">3. 学习问题</h3><p>概率图模型的学习包括：图结构的学习和参数的学习</p><p>参数的学习，即参数估计问题，可分为含隐变量的参数估计和不含因变量的参数估计：</p><ul><li><p>不含隐变量的参数估计：</p><ul><li>如果图模型中不包含隐变量，即所有变量都是可观测的，那么网络参数一般可以直接通过最大似然来进行估计。</li><li>有向图模型：所有变量x的联合概率分布可以分解为每个随机变量<span class="math inline">\(x_k\)</span>的局部条件概率 <span class="math inline">\(p(xk |xπk , \theta_k)\)</span> 的连乘形式，其中<span class="math inline">\(\theta_k\)</span>为第 k 个变量的局部 条件概率的参数。</li><li>无向图模型： 所有变量x的联合概率分布可以分解为定义在最 大团上的势能函数的连乘形式。</li></ul></li><li><p>含隐变量的参数估计：</p><ul><li>如果图模型中包含隐变量，即有部分变量是不可观测的，就需要用 EM 算法</li><li>EM 算法的应用例子:高斯混合模型。高斯混合模型(Gaussian Mixture Model，GMM)是由多个高斯分布组成的模型，其密度函数为多个高 斯密度函数的加权组合。 <img src="https://img.mubu.com/document_image/3476923c-5528-4dd4-aa4d-ae10183bf377-3380623.jpg" /> <img src="https://img.mubu.com/document_image/28d53640-0eb6-4a17-81c6-ffa8e4dbb289-3380623.jpg" /></li></ul></li></ul><h2 id="概率图模型与机器学习">概率图模型与机器学习</h2><ul><li>很多机器学习模型都可以归结为概率模型，即建模输入和输 出之间的条件概率分布。</li><li>图模型提供了一种新的角度来解释机器学习模 型，并且这种角度有很多优点，比如了解不同机器学习模型之间的联系，方便设计新模型等。</li><li>概率图模型中最基本的假设是条件独立性。图形化表示直观地描述了随机 变量之间的条件独立性，有利于将复杂的概率模型分解为简单模型的组合，并 更好地理解概率模型的表示、推断、学习等方法。</li></ul><h2 id="概率图模型与神经网络">概率图模型与神经网络</h2><p>概率图模型和神经网络有着类似的网络结构，但两者不同。</p><ul><li>节点<ul><li>概率图模型的节点是随机变量，其图结构的主要功能是用来描述变量 之间的依赖关系，一般是稀疏连接。使用图模型的好处是可以有效进行统计推 断。</li><li>神经网络中的节点是神经元，是一个计算节点。如果将神经网络中每个神经元看做是一个binary随机变量，那神经网络就变成一个sigmoid信念网络。</li></ul></li><li>变量的含义<ul><li>图模型中的每个变量一般有着明确的解释，<strong>变量之间依赖关系一般是人工来定义</strong>。</li><li>神经网络中的单个神经元则没有直观的解释</li></ul></li><li>生成模型与判别模型<ul><li>神经网络是判别模型，直接用来分类</li><li>图模型不但可以是判别模型，也可以是生成模型。生成模型不但可以用来生成样本，也可以通过贝叶斯公式用来做分类。</li></ul></li><li>学习方法<ul><li>神经网络参数学习的目标为交叉熵或平方误差等损失函数。</li><li>图模型的参数学习的目标函数为似然函数或条件似然函数，若包含隐变量则通常通过EM算法来求解。</li></ul></li></ul><p>神经网络和概率图模型的结合：</p><ul><li><p>用神经网络强大的表示能力来建模图模型中的</p><ul><li>推断问题：比如变分自编码器</li><li>生成问题：比如生成对抗网络，第</li><li>势能函数：比如 LSTM+CRF模型[Lample et al., 2016, Ma and Hovy, 2016]</li></ul></li><li><p>用图模型的算法来解决复杂结构神经网络中的学习和推断问题</p><ul><li>图结构神经网络(Graph Neural Network)</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基本概念&quot;&gt;基本概念&lt;/h2&gt;
&lt;p&gt;概率图模型(Probabilistic Graphical Model，PGM)，简称图模型(Graphical Model，GM)，首先是一种概率模型，其次，它用图结构描述多个随机变量之间的依赖关系，它是研究高维空间中的概率</summary>
      
    
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="贝叶斯网络" scheme="https://chiechie.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C/"/>
    
    <category term="概率图" scheme="https://chiechie.github.io/tags/%E6%A6%82%E7%8E%87%E5%9B%BE/"/>
    
    <category term="贝叶斯优化" scheme="https://chiechie.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>哲学导论</title>
    <link href="https://chiechie.github.io/2021/06/18/reading_notes/zhexue/zhexue-summart/"/>
    <id>https://chiechie.github.io/2021/06/18/reading_notes/zhexue/zhexue-summart/</id>
    <published>2021-06-18T09:01:52.000Z</published>
    <updated>2021-06-28T02:11:59.256Z</updated>
    
    <content type="html"><![CDATA[<h1 id="定义">定义</h1><p>哲学，就我对这个词的理解来说，乃是某种介乎神学与科学之间的东西。它和神学一样，包含着人类对于那些迄今仍为科学知识所不能肯定之事物的思考；但它又像科学一样，是诉之于人类的理性而不是诉之于权威的，不论是传统的权威还是启示的权威。一切确切的知识都属于科学；一切涉及超乎确切知识之外的教条都属于神学。但介乎神学与科学之间还有一片受到双方攻击的无人之域，这片无人之域就是哲学。---罗素</p><h1 id="哲学的主分支">哲学的主分支</h1><p>哲学的主分支：形而上学、知识论、伦理学、逻辑学和美学 - <a href="https://zh.wikipedia.org/wiki/%E9%82%8F%E8%BC%AF%E5%AD%B8">逻辑学</a> - <a href="https://zh.wikipedia.org/wiki/%E5%BD%A2%E8%80%8C%E4%B8%8A%E5%AD%B8">形而上学</a>/<a href="https://zh.wikipedia.org/wiki/%E5%AE%87%E5%AE%99%E8%AB%96">宇宙论</a> - <a href="https://zh.wikipedia.org/wiki/%E7%9F%A5%E8%AD%98%E8%AB%96">知识论</a> - <a href="https://zh.wikipedia.org/wiki/%E5%80%AB%E7%90%86%E5%AD%B8">伦理学</a>/<a href="https://zh.wikipedia.org/wiki/%E5%83%B9%E5%80%BC%E8%AB%96">价值论</a> - <a href="https://zh.wikipedia.org/wiki/%E7%BE%8E%E5%AD%B8">美学</a></p><h1 id="特殊分支">特殊分支</h1><p>哲学的特殊分支：是交叉学科的哲学研究</p><ul><li><a href="https://zh.wikipedia.org/wiki/%E5%85%83%E5%93%B2%E5%AD%A6">后设哲学</a></li><li><a href="https://zh.wikipedia.org/wiki/%E5%AE%97%E6%95%99%E5%93%B2%E5%AD%A6">宗教哲学</a></li><li><a href="https://zh.wikipedia.org/wiki/%E5%BF%83%E9%9D%88%E5%93%B2%E5%AD%B8">心灵哲学</a></li><li><a href="https://zh.wikipedia.org/wiki/%E8%AF%AD%E8%A8%80%E5%93%B2%E5%AD%A6">语言哲学</a></li><li><a href="https://zh.wikipedia.org/wiki/%E7%A7%91%E5%AD%A6%E5%93%B2%E5%AD%A6">科学哲学</a>： 现代西方科学哲学的中心是<strong>科学方法论</strong>问题，具体包括<ul><li>统计哲学：统计假设检验（证伪），贝叶斯</li><li>数学哲学：</li><li>物理哲学</li><li>化学哲学</li><li>生物哲学</li><li>医学哲学</li><li>心理学哲学</li><li>经济哲学</li><li>社会科学哲学：代表之一---马克思</li></ul></li><li><a href="https://zh.wikipedia.org/wiki/%E6%94%BF%E6%B2%BB%E5%93%B2%E5%AD%A6">政治哲学</a></li><li><a href="https://zh.wikipedia.org/wiki/%E6%B3%95%E5%BE%8B%E5%93%B2%E5%AD%B8">法律哲学</a></li></ul><h2 id="西方的-科学哲学发展路径">西方的 科学哲学发展路径</h2><ul><li>到50年代为止，一直是作为“正统科学哲学”的<strong>逻辑实证主义</strong>占主导地位</li><li>从50年代末兴起，在60年代发展和完成：波普尔的<strong>批判理性主义</strong>和库恩-拉卡托斯的<strong>历史主义</strong>科学哲学。</li><li>至70年代，出现了两股发展趋势。<ul><li>一股是<strong>复兴</strong>和发展“正统<strong>的”逻辑主义方法论</strong>，</li><li>另一股就是法伊尔阿本德的<strong>非理性主义</strong>，它在很大程度上是把<strong>历史主义</strong>中的非理性因素贯彻到极端程度的产物。</li></ul></li><li>本书对<strong>逻辑实证主义</strong>和波普尔、库恩与拉卡托斯的科学哲学等现代西方理性主义科学哲学学说一一作了批判，并在这个批判中阐发了自己的科学哲学——<strong>多元主义方法论</strong></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;定义&quot;&gt;定义&lt;/h1&gt;
&lt;p&gt;哲学，就我对这个词的理解来说，乃是某种介乎神学与科学之间的东西。它和神学一样，包含着人类对于那些迄今仍为科学知识所不能肯定之事物的思考；但它又像科学一样，是诉之于人类的理性而不是诉之于权威的，不论是传统的权威还是启示的权威。一切确切的</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="哲学" scheme="https://chiechie.github.io/tags/%E5%93%B2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>关于AGI？</title>
    <link href="https://chiechie.github.io/2021/06/17/meditation/about-AGI/"/>
    <id>https://chiechie.github.io/2021/06/17/meditation/about-AGI/</id>
    <published>2021-06-17T09:04:32.000Z</published>
    <updated>2021-06-28T02:11:37.160Z</updated>
    
    <content type="html"><![CDATA[<h2 id="chiechies-reflection">chiechie's reflection</h2><ol type="1"><li>理论突破不是技术爆发的必经之路，很多技术都没有理论，比如古代时候的发明，造船，造纸，造火药，爱迪森发明电灯泡，还有现代的量子计算机和深度学习，理论完备个P。</li><li>大部分发明都是做实验，通过试错迭代而产生的,而很多情况下理论都是滞后的。</li></ol><h2 id="无人驾驶现状">无人驾驶现状</h2><ol type="1"><li>一个技术在工业化生产之前，一般要经历三个阶段, 理论突破，技术验证，工程化<ol type="1"><li>理论突破，科学家在理论上证明其可行性，即产品要达到一个什么样的性能，在技术上是一定可以实现的；</li><li>技术突破，研究机构突破技术实现上壁垒，做出来达到预期的Demo；</li><li>工程化，主要解决产品设计，方案优化，功能完备，性能提升，良品率，鲁棒性，可用性提升，大规模复制的技术准备，成本降低等工程问题。</li></ol></li><li>通用无人驾驶在第一，第二阶段还彻底整明白的情况下，由资本驱动直接进入第三阶段.</li></ol><h2 id="agi的理论先行者">AGI的理论先行者</h2><ol type="1"><li>目前强化学习是最被看好的方向。</li><li>强化学习本质上是演化论的思路，跟自然界一样，给定一个reward，让机器放肆的学习探索。</li><li>目前还需要解决的问题是计算资源的问题。</li><li>自然界的演化大部分时间是平稳状态，只有极少数黑天鹅事件决定了演化的方向。</li><li>在计算机中模拟agent的演化过程，和自然界的演化类似，需要忍受长期的无秩序无进展。</li><li>如果全世界的资源往这方面倾斜，可能可以加快黑天鹅事件出现。</li><li>理论突破不是AGI成熟的必要条件，有可能是2者互相促进发展。</li><li>目前收到关注较多的公司--自动标注样本公司scale</li></ol><h2 id="参考">参考</h2><ol type="1"><li>https://www.zhihu.com/question/404870865/answer/1324577689</li><li>https://www.zhihu.com/question/464616760/answer/1940847401</li><li><a href="https://www.sciencedirect.com/science/article/pii/S0004370221000862">reward is enough ,david silver</a></li><li><a href="https://www.notboring.co/p/scale-rational-in-the-fullness-of?token=eyJ1c2VyX2lkIjoxNzY2NjQ2OSwicG9zdF9pZCI6Mzc4NDY2MzEsIl8iOiJrTHFWcCIsImlhdCI6MTYyNDQyNDU4NCwiZXhwIjoxNjI0NDI4MTg0LCJpc3MiOiJwdWItMTAwMjUiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.zWmuXLn35R720iDVtX7yTuTpM4kCMk25457XzZN8_Ks">not boring</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;chiechies-reflection&quot;&gt;chiechie&#39;s reflection&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;理论突破不是技术爆发的必经之路，很多技术都没有理论，比如古代时候的发明，造船，造纸，造火药，爱迪森发明电灯泡，还有现代的量子计算机</summary>
      
    
    
    
    <category term="沉思录" scheme="https://chiechie.github.io/categories/%E6%B2%89%E6%80%9D%E5%BD%95/"/>
    
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="科技史" scheme="https://chiechie.github.io/tags/%E7%A7%91%E6%8A%80%E5%8F%B2/"/>
    
    <category term="人工智障" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E9%9A%9C/"/>
    
  </entry>
  
  <entry>
    <title>关于Scale AI</title>
    <link href="https://chiechie.github.io/2021/06/16/reading_notes/reality/about-scale/"/>
    <id>https://chiechie.github.io/2021/06/16/reading_notes/reality/about-scale/</id>
    <published>2021-06-16T02:39:20.000Z</published>
    <updated>2021-06-30T07:30:46.238Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>看到Packy激情满满写了一篇关于Scale AI的公关文，比较好奇这个年轻的小公司有何特别之处，为什么会受到资本的一致认可。</p><p>印象中Scale AI就是一家硅谷的数据标注公司，主要靠外包给第三方国家，赚取中间费用，这种公司有什么竞争力呢？跟大厂比起来？</p></blockquote><h2 id="总结">总结</h2><ol type="1"><li><p>Scale AI创立至今5年，最近一次估值73亿$。它跟stripe有点像，在一个蓬勃发展的行业，找到一个关键但是不起眼的小地方，深耕细作。</p></li><li><p>刚开始成立的时候，Scale AI专注做数据标注，但是他们的野心不限于此，他们想做更好用的数据标注工具，即人机互助的方式，Human-in-the-Loop（HIL）。</p></li><li><p>Scale AI的故事是：随着标记数据越来越多，标注数据的边际成本会降低，因为标记样本越多，标记机器人的性能越好，能hold的事情就越多，需要分配出去的工作就越少。</p><blockquote><p>这里有一个问题，怎么确定，哪些是机器可以搞定的，哪些是机器搞不定的？这个是不是又要多一层人工监督了？</p><p>可以从环境中获取到反馈，也可以人工抽查。</p><p>总的来说，都不是很完善的方案。</p></blockquote></li><li><p>Scale AI还有一个亮点，他的客户群体很分散，从国防部到无人驾驶公司，eg OpenAI, Airbnb and Lyft。这有一个好处就是。AI公司去去留留，竞争之后，留下了最有效的ml应用场景，但是Scale AI始终有机会，因为是做基础设施的。</p></li><li><p>除了标注API，Scale AI还做了一个样本调试的产品--Nucleus，data debugging SaaS product。目的是做全链路基建嘛。 <img src="./img.png" alt="Nucleus" /></p></li><li><p>Scale AI的CEO Alexandr Wang 说的一段话</p><blockquote><p>At Scale, we’re building the foundation to enable organizations to manage the entire AI lifecycle. Whether they have an AI team in-house or need a fully managed models-as-a-service approach, we partner with our customers to build their strategy from the ground up and ensure they have the infrastructure in place to systematically deliver highly-performant models.</p></blockquote></li></ol><p>简单点说，他们的方法是，帮助企业从0到1落地一个AI应用--不管这个企业内部有没有AI团队--企业能够使用这个基建更高效地构建模型. 就是win-win,后生可畏.</p><ol start="10" type="1"><li><p>对于没有AI团队的传统企业，Scale AI定制化合作（跟必示一样），客户例如Brex和Flexport。</p><figure><img src="./img1.png" alt="img.png" /><figcaption aria-hidden="true">img.png</figcaption></figure></li><li><p>这里有一个小故事：Brex doesn’t have an AI team working on the model; they outsource it to Scale. .Brex一开始找的是专门做OCR的大公司，帮他们做发票文本提取，但是效果一般（“they were all mediocre.” ）。后面找到scale，通过深入合作定制化了一个模型，效果100%。后面沉淀出了一个产品document。</p></li><li><p>scale的产品还有蛮多的：地图/文档/图像。。 <img src="img2.png" alt="img.png" /></p></li></ol><blockquote><p>btw, 知乎上有一个相关提问--如何评价Scale AI？大家似乎认识非常有限（只知道它是做数据标注的），还讨论的热火朝天。由此可见的，噪声膨胀的速度远远超过信息增长的速度。</p></blockquote><h2 id="chiechies-reflection">chiechie's reflection</h2><ol type="1"><li><p>packy这篇文章的公司分析框架蛮好的，后面分析科技公司可以套用：</p><ul><li>行业介绍：The State of AI and ML</li><li>公司介绍：Getting to Scale.</li><li>相同模式的成功案例对比：Scaling Like Stripe.</li><li>关于公司的负面观点：The Bear Case for Scale.</li><li>关于公司的正面观点：The Bull Case for Scale.</li><li>前景展望：Scale’s Compounding Vision.</li></ul></li><li><p>AI市场未来还有这么大的成长空间，当前只有8%的公司应用了AI技术,看到这个数字有点吃惊。但是，即便如此，AI从业人员的需求也不用过分乐观估计。</p></li><li><p>AI应用目前还在探索期。Scale AI比较鸡贼，让AI公司在前面探路，让他们相互pk，把有价值可落地的场景摸索清楚，自己在后面提供军火库，妥妥的赢家。</p></li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.notboring.co/p/scale-rational-in-the-fullness-of">not boring</a></li><li><a href="https://zhuanlan.zhihu.com/p/384012257">吴恩达发起新型竞赛范式！模型固定，只调数据？</a></li><li><a href="https://scale.com/blog/series-e">Scale AI’s Series E: Deploying AI Across Every Industry</a></li><li><a href="https://dashboard.scale.com/nucleus/">nucleus</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;看到Packy激情满满写了一篇关于Scale AI的公关文，比较好奇这个年轻的小公司有何特别之处，为什么会受到资本的一致认可。&lt;/p&gt;
&lt;p&gt;印象中Scale AI就是一家硅谷的数据标注公司，主要靠外包给第三方国家，赚取中间费用，这种公司有什么竞争</summary>
      
    
    
    
    <category term="投资" scheme="https://chiechie.github.io/categories/%E6%8A%95%E8%B5%84/"/>
    
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="投资" scheme="https://chiechie.github.io/tags/%E6%8A%95%E8%B5%84/"/>
    
    <category term="行业研究" scheme="https://chiechie.github.io/tags/%E8%A1%8C%E4%B8%9A%E7%A0%94%E7%A9%B6/"/>
    
  </entry>
  
  <entry>
    <title>贝叶斯网络推断</title>
    <link href="https://chiechie.github.io/2021/06/15/data_structure/graph/bayesnetwork/"/>
    <id>https://chiechie.github.io/2021/06/15/data_structure/graph/bayesnetwork/</id>
    <published>2021-06-15T06:28:18.000Z</published>
    <updated>2021-06-28T01:34:19.335Z</updated>
    
    <content type="html"><![CDATA[<p>如何应用贝叶斯网络来做决策？</p><ul><li>首先需要将先验知识表达成一个因果图--贝叶斯网络，（准确来说贝叶斯网络的边不仅仅表达因果关系，他表达所有的信息传播的方向）。</li><li>做推断</li></ul><ol type="1"><li><p>构造贝叶斯网络 <img src="img.png" alt="img.png" /></p></li><li><p>推断</p></li></ol><p>已知P(R,W,S,C）, 求P(r)</p><h3 id="枚举法">枚举法</h3><ol type="1"><li>先推到条件概率分布</li></ol><figure><img src="img_1.png" alt="img_1.png" /><figcaption aria-hidden="true">img_1.png</figcaption></figure><ol start="2" type="1"><li><img src="img_2.png" title="fig:" alt="img_2.png" /></li></ol><h3 id="变量消除法">变量消除法</h3><figure><img src="img_3.png" alt="img_3.png" /><figcaption aria-hidden="true">img_3.png</figcaption></figure><figure><img src="img_4.png" alt="img_4.png" /><figcaption aria-hidden="true">img_4.png</figcaption></figure><p>所有非query变量祖先的变量，都应该被消去，当然不是真的消去啦，是对该消去变量求和，然后变成一个新的因子f。</p><p>依次迭代，直到没有可以消除的变量。</p><figure><img src="img_5.png" alt="img_5.png" /><figcaption aria-hidden="true">img_5.png</figcaption></figure><h3 id="贝叶斯网络中的依赖性">贝叶斯网络中的依赖性</h3><ol type="1"><li>每一个随机变量都是条件独立于他的非后代节点，给定他的父母节点时，</li><li>如下，给定A，B时，C和D是独立的。</li></ol><figure><img src="img_6.png" alt="img_6.png" /><figcaption aria-hidden="true">img_6.png</figcaption></figure><ol start="3" type="1"><li>每个随机变量独立其他任何变量，当给定他的马尔可夫毯（Markov Blanket）<ul><li>父亲，孩子，以及孩子的父母亲（配偶）</li></ul></li></ol><figure><img src="img_7.png" alt="Markov Blanket" /><figcaption aria-hidden="true">Markov Blanket</figcaption></figure><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.youtube.com/watch?v=TuGDMj43ehw">Bayesian Networks-youtuybe</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;如何应用贝叶斯网络来做决策？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先需要将先验知识表达成一个因果图--贝叶斯网络，（准确来说贝叶斯网络的边不仅仅表达因果关系，他表达所有的信息传播的方向）。&lt;/li&gt;
&lt;li&gt;做推断&lt;/li&gt;
&lt;/ul&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;构</summary>
      
    
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="贝叶斯网络" scheme="https://chiechie.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>为什么要工作？</title>
    <link href="https://chiechie.github.io/2021/06/14/meditation/why-do-We-work/"/>
    <id>https://chiechie.github.io/2021/06/14/meditation/why-do-We-work/</id>
    <published>2021-06-14T09:28:02.000Z</published>
    <updated>2021-06-28T00:33:05.522Z</updated>
    
    <content type="html"><![CDATA[<p>类似的问题，</p><ul><li>我们高中为什么要学数理化和文言文？长大之后并没有用上。</li><li>面试造火箭工作拧螺丝。</li></ul><p>工作除了挣钱，还能带来点别的东西，这个东西是什么呢？似乎做完了才知道。</p><p>最近的一份工作，本来是想提升技术，但是事实上，并没有磨练技术的机会，大部分时间是在做产品设计。做产品设计的过程中，越做越困惑，本能地想要找到答案，先在本领域里面寻找，但是大部分所谓的专家，写的文章都是空洞的方法论，言之无物。我不满意，遂去寻找其他领域的文章，比如哲学，社会科学，心理学，经济学。我发现，产品设计上遇到的一些问题，追问到其本质，似乎跟其他领域也想通，原来大家都在研究差不多的问题。</p><p>潜移默化，思考问题的方式发生了改变，从追求触手可及的答案（捷径往往不是正确的道路），到追求更深层次的更本质的问题，当然也更花时间和精力。 从之前迷信权威，到现在delay judgement。</p><p>得知东隅，失之西隅。</p><p>再想一想高中学习的那些东西，可能真不见得有什么实际收益，但是在不可见的维度，可能还是有收获的。比如磨练了我们的意志力，让我们做事情能够吃苦耐劳，或者对性格的其他方面有一些潜在的影响。这个影响显然不是设计高考制度的人想出来的，而是人在做事，在实践的过程中，意外得到的，可能去种地也会起到同样的作用。只有事后，自己才可以总结出来。</p><p>一些联想：观察到事件A和事件B在现实中存在某种若隐若现的关联时，不一定A和B就有直接的因果关系。背后可能存在着某个状态不可见的混杂因子。很多情况下，因为我们没有足够的人生经验，所以做事之前，我们都不知道这个混杂因子是个什么，做完之后才恍然大悟。</p><p>因缘际会，凡事用心投入，大概率会是有好结果的吧，这个结果可能发生在另外一件事情上。</p><p>"做之前想的再多没用，做着做着就知道意义了"。现在似乎有点明白这个意思，人的能力太有限，世界变幻莫测，哪有可能预测到事情的演化方向。直到走完这条路，并且回过头来看这条路，才知道终点是什么，才能总结出这一路的意义是什么。</p><blockquote><p>莫听穿林打叶声，何妨吟啸且徐行。竹杖芒鞋轻胜马，谁怕？ 一蓑烟雨任平生。</p><p>料峭春风吹酒醒，微冷，山头斜照却相迎。回首向来萧瑟处，归去，也无风雨也无晴。</p><p>-- 定风波 苏轼</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;类似的问题，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们高中为什么要学数理化和文言文？长大之后并没有用上。&lt;/li&gt;
&lt;li&gt;面试造火箭工作拧螺丝。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;工作除了挣钱，还能带来点别的东西，这个东西是什么呢？似乎做完了才知道。&lt;/p&gt;
&lt;p&gt;最近的一份工作，本来是</summary>
      
    
    
    
    <category term="沉思录" scheme="https://chiechie.github.io/categories/%E6%B2%89%E6%80%9D%E5%BD%95/"/>
    
    
    <category term="阅读" scheme="https://chiechie.github.io/tags/%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>《社会心理学》读书笔记</title>
    <link href="https://chiechie.github.io/2021/06/13/reading_notes/reality/shehuixinlixue/"/>
    <id>https://chiechie.github.io/2021/06/13/reading_notes/reality/shehuixinlixue/</id>
    <published>2021-06-13T01:24:54.000Z</published>
    <updated>2021-06-28T00:33:05.525Z</updated>
    
    <content type="html"><![CDATA[<h2 id="社会中的自我">1. 社会中的自我</h2><h3 id="焦点效应">焦点效应</h3><ol type="1"><li>人总是高估他们内在状态外露的程度，但是事实上，他人并没有你想象的那样注意你。</li><li>焦点效应（spotlight effect）：把自己看作世界中心，直觉地高估别人对我们的关注程度。几个例子：</li></ol><ul><li>会聚焦在自我与当前社会环境的差异性，会关注差别最大的那个维度。</li><li>自我服务：当关系出现问题时，个体通常会把责任更多推到配偶身上，情况好转时，确认为自己起了更重要的作用。</li><li>自我关注引发的很多行为：我们关注他人的行为和期望，并随之调整自己的行为。</li><li>在不同的关系中，自我也在发生变化。</li></ul><ol start="2" type="1"><li><p>透明度错觉（illusion of transoarency）：我们能敏锐觉察到自己的情绪，很自然地表现出来，并且直觉的认为别人会通过我们的表情觉察到我们的情绪。</p><blockquote><p>其实不是的，1是我们的表现可能模糊不清，2是别人的关注点可能在他自己。</p></blockquote></li><li><p>公众心理疏忽（public mental slips）：如果我们五一冒犯了别人，我们可能懊恼，但是别人经常注意不到，即使注意到也可能很快就会忘记。</p></li><li><p>我们的大多数行为不受意识控制，是自动。显示的自我会制定长期计划，设定目标和进行约束，设想各种可能，将自己和他们相比较，管理自己的reputation和社会关系，但是更多时候可能成为幸福的障碍。</p></li></ol><h3 id="我是谁">我是谁</h3><ol type="1"><li>self-schemas：对自己的认识，比如聪明，自省，勤奋，怀疑，个人主义。</li><li>self-schemas影响我们对社会信息的加工，也影响我们感知，回忆和评价他人/自己。</li><li>我们对跟self-schemas相关的信息会特别关注。</li><li>possible selves：可能的自我，梦想中自我的样子，比如富有，充满激情，自信，丛容，智慧。</li><li>possible selves会激发一种我们渴望的生活愿景，对我们产生巨大的激励作用，或促进我们避免成为自己害怕的样子。</li></ol><h3 id="社会自我">社会自我</h3><ol type="1"><li>基因对人格和自我概念有重要的影响，社会经验也有：扮演的角色，社会同一性，和别人的比较，成功和失败，他人如何评价我们，周围的文化。</li><li>扮演的角色：我们为这个角色说了很多好话，不知不觉，我们会越来越相信这些话，为这些话提供证据。就这样，角色扮演变成了事实。</li><li>社会比较：判断自己是否聪明/智慧？通过社会比较。生活的大部分是围绕比较进行的，因此人们可能会因为别人的失败而暗自高兴。当人嗯攀爬成功的阶梯时，通常会向上看，将自己与做的更好的人比。面对竞争时，常常认为竞争对手本来就有一些优势，以此来保护我们业已动摇的自尊。</li><li>别人的评价：镜像自我--别人对我们的看法，我们把别人作为镜子，我们认为的别人眼中的我，据此来认识自己。换句话说，重要的不是别人实际上如何评价我们，而是我们想象中他们如何评价我们。</li></ol><h3 id="自我与文化">自我与文化</h3><ol type="1"><li>对于部分群体，“个人主义”十分盛行，他们的额经历大部分是这样：青春期与负米分离，各异开始依靠自己，定义独立的自我。即使个体来到一片陌生的土地上，他的特性：有特殊能力，特点，价值和梦想的个体也会保留。当经历过富裕，地位改变，城市化和大众传媒后，个人主义开始迅速发展，</li><li>亚洲文化则更重视集体主义（collectivism）。</li><li>保守派，经济上的个人主义（不要征税）和道德上的集体主义（制定法律来约束不道德）</li><li>自由主义者，经济上的集体主义（支持全民健康保障）和道德上的个人主义（不要用法律来约束我）</li><li>许多文化似乎正在走向个人主义。</li><li>究竟是人们更加关注自我，所以喜欢听关注自我的歌曲，还是反过来？还是存在混杂因子？</li></ol><h3 id="文化与认知">文化与认知</h3><ol type="1"><li>东亚人的思维更具有整体性，从人际关系和环境的角度思考人和物。东方人不重视表达自己的独特性，更重视分享，很少强调个人的选择和自由。</li><li>西方的文化强调个体的力量，个体的价值。</li><li>相互依赖的自我是多个自我的组合，如为人子女的我，职场中的我，作为朋友的我。一个具有相互依赖自我的人会有强烈的归属感，当跟组织分开之后，会丢失掉自我定义。相互依赖的自我存在于社会关系中，社会生活的目标是协调和支持群体。相互依赖的自我聚焦寻求社会支持，比独立自我更深入地融入他人。在相互依赖的文化中，</li><li>自我概念会适应环境，如果一生都与一群人交往，身边人对你的影响很重要；反之，如果每几年换一个环境，身边的人就没有那么重要，而「自我」变成忠实伙伴。“无论你去哪儿，你就是你”。</li></ol><h3 id="自我认识">自我认识</h3><ol type="1"><li>我们对自己行为的解释，在原因有点微妙时候，通常答案都是错误的，我们会忽视重要因素，而夸大一些无关紧要的因素。</li></ol><h2 id="社会关系">社会关系</h2><ol type="1"><li>内疚感：没有帮助别人或者说谎时，会产生内疚感，人会通过在其他方面的行动来弥补这一种感觉。</li><li>经历过极度悲痛的人，会经历一种强烈的自我关注时期。</li><li>悲痛并且自我关注的人，较少意愿去帮助他人；悲痛并且关注别人的人，较多意愿去帮助他人。</li><li>快乐的人更愿意帮助别人。</li><li>帮助行为可以缓解不好的情绪，也可以维持好的情绪。比如给某人指路之后，自我感觉会更好。接着，好的心情又回产生积极的思维，从而指导在其他事情上产生积极的行为。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;社会中的自我&quot;&gt;1. 社会中的自我&lt;/h2&gt;
&lt;h3 id=&quot;焦点效应&quot;&gt;焦点效应&lt;/h3&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;人总是高估他们内在状态外露的程度，但是事实上，他人并没有你想象的那样注意你。&lt;/li&gt;
&lt;li&gt;焦点效应（spotlight effe</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="心理学" scheme="https://chiechie.github.io/tags/%E5%BF%83%E7%90%86%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>《行为经济学》读书笔记</title>
    <link href="https://chiechie.github.io/2021/06/12/reading_notes/economics/xingweijingjixue/"/>
    <id>https://chiechie.github.io/2021/06/12/reading_notes/economics/xingweijingjixue/</id>
    <published>2021-06-12T01:26:37.000Z</published>
    <updated>2021-06-28T00:33:05.523Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第二讲">第二讲</h1><h2 id="第二部分-社会网络研究">第二部分 社会网络研究</h2><h3 id="选择选择什么">选择选择什么？</h3><ol type="1"><li>“群体选择”:群体之间的竞争可能使内部合作的群体最终胜出并淘汰那些内部不合作的群体.群体选择这一主题兼具个体视角和群体视角。</li><li>"利他行为"：体为增加群体的适存度而降低自己的适存度，它的行为是利他行为。适存度，fitness。</li><li>生物学家怎样测度呢？他们用后代与母代之比，来测度适存度。如果一个人的生存策略有利于增加自己的适存度，那么在一名旁观者看来，他的后代的数目必须逐渐超过母代的数目，这就是繁衍，否则就是消亡</li><li>行为模式是可观测的，行为动机是不可观测的。策略是对行为模式的一种描述，所以是可观测的。心理学描述心理事实，包括动机，通常是不可观测的。如生物学家那样，行为经济学试图做的，是从可观测的“显型”策略，推测那些不可观测的“基因型”行为动机。</li><li>什么是传统：：一切经过长期历史的检验有利于生存和繁衍的知识。其中可交流的传统就是常识。传统的大部分不能交流，只能模仿。</li><li>为什么蚂蚁懂得合作没有淘汰人类？蚂蚁行为的驱动力量是族群惯性，但是他没有灵活性。人的行为驱动力量一部分是族群惯性，一部分是灵活性，这样就使得可以保持创新的同时，又能够保持一定的合作秩序。</li><li>在古尔德看来，漫长的地球演化史，首先由一些漫长的稳态构成，其次，这些稳态之间有一些瞬间的黑天鹅事件打破既有的均衡态，然后陷入新的均衡态，再等待新的黑天鹅事件</li><li>人类的出现，就是其中一个黑天鹅事件，它只占演化史的一个瞬间，是大约900万年以内的事情</li><li>古尔德的结论是：历史从来不是决定论的，由许多偶然因素决定历史路径，只在事后才可能知道 自然选择的力量从来不是惟一的演化力量，类似地，为什么最优越的物种只在以往漫长历史的最后一秒之内发生呢？</li><li>在多因多果的网络里，科学家怎样令人信服地指出哪一条因果链条是最重要的呢？理想方法是通过实验，在实验中，我们可以只让一条因果链发生作用，我们控制所有其他因果关系不许它们起作用</li></ol><h3 id="社会网络研究什么">社会网络研究什么？</h3><ol type="1"><li>如何界定一项知识的重要性？用途。手段的质，依赖于目的本身。</li></ol><h3 id="爱因斯坦的自由论">爱因斯坦的自由论</h3><ol type="1"><li>整体论可爱，但不可信，因为它缺少可行的研究方法。个体论可信，却不可爱。</li><li>爱因斯坦:创造是个体的，从来就是个体行为。但是自由，却是整体的. 没有宽容的社会，个人自由也将消失。</li></ol><h3 id="哈耶克的涌现秩序">哈耶克的涌现秩序</h3><ol type="1"><li><p>马克思理论的逻辑矛盾在第一卷里尚未出现，非要在第二卷和第三卷才成为无法挣脱的内在矛盾。</p></li><li><p>马克思主义和哈耶克：哈耶克论证，没有一个微观主体（个体或群体），不论多么聪明，有能力预先知道从大量哪怕是极简单的微观主体的相互作用中涌现出来的宏观秩序是怎样的。这当然意味着社会计划的不可能和理性的狂妄。理性实在很渺小，不可能完成社会主义者赋予它的资源有效配置任务。</p></li><li><p>人类互动问题的复杂性，时间与结构的复制以及涌现，宏观秩序的涌现</p></li><li><p>哈耶克的“涌现秩序"：演化理论，假以时日，从大量的简单局部结构之间的相互作用中必能涌现更复杂的结构。</p><blockquote><p>涌现秩序的思想，可以溯源至柏格森和怀特海。</p></blockquote></li><li><p>哈耶克使用的关键词：简单结构、复制过程、优胜劣汰、适应性。</p></li><li><p>哈耶克的社会演化基本原理：单子复杂交往涌现宏观秩序的不可预见性。</p><ul><li>“单子”，是莱布尼茨的概念，它们如“素数”那样单纯，具有不可再分性。只不过，莱布尼茨假设单子之间没有交往，而哈耶克假设单子之间的交往是事物演化的原因。</li></ul></li><li><p>多主体仿真（multi-agent simuiation）:一种模拟不确定性的环境与社会变迁的程序.哈佛的诺瓦克小组在使用软件仿真时，将每一个agent都设置为具有最简单的行为规则。然后，一个环境中有数千个agent，相互作用之后，宏观秩序涌现出来，这个宏观秩序是不可预期的。最初研究这样的仿真程序的，是2005年与奥曼分享诺贝尔经济学奖的谢林，这一程序称为“谢林程序”。</p></li><li><p>《解释的程度》中，哈耶克的论述十分接近“社会现象是多因多果”这一见解。</p></li><li><p>《复杂现象论》中，哈耶克全面论述了他设想的演化理论的各要素。目前，社会网络的研究方法，是最适合研究哈耶克涌现秩序的实证方法。</p></li><li><p>哈耶克对于统计学的看法：通过消除复杂性来处理大量数据。</p></li></ol><h3 id="多因多果模型">多因多果模型</h3><ol type="1"><li><p>多因多果网络中，那一条因果链条是重要的？以及如何论证出这个结论是对的？前者靠直觉，或者说taste/判断力。后者用控制变量的方法。</p><blockquote><p>社会心理学和行为经济学都会用到控制变量的方法来确定因果关系。</p><p>判断力哪里来？靠日积月累的实践。</p></blockquote></li><li></li></ol><h1 id="第三讲">第三讲</h1><ol type="1"><li>杨格的“策略学习的不可能性定理”：</li></ol><h1 id="参考">参考</h1><ol type="1"><li><a href="https://weread.qq.com/web/reader/b48321a058a8aeb48d182ac">行为经济学讲义-演化论视角</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;第二讲&quot;&gt;第二讲&lt;/h1&gt;
&lt;h2 id=&quot;第二部分-社会网络研究&quot;&gt;第二部分 社会网络研究&lt;/h2&gt;
&lt;h3 id=&quot;选择选择什么&quot;&gt;选择选择什么？&lt;/h3&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;“群体选择”:群体之间的竞争可能使内部合作的群体最终胜出并淘汰那些</summary>
      
    
    
    
    <category term="经济学" scheme="https://chiechie.github.io/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6/"/>
    
    
    <category term="经济学" scheme="https://chiechie.github.io/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6/"/>
    
    <category term="行为经济学" scheme="https://chiechie.github.io/tags/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A6/"/>
    
    <category term="幂律" scheme="https://chiechie.github.io/tags/%E5%B9%82%E5%BE%8B/"/>
    
    <category term="哈耶克" scheme="https://chiechie.github.io/tags/%E5%93%88%E8%80%B6%E5%85%8B/"/>
    
    <category term="群体选择" scheme="https://chiechie.github.io/tags/%E7%BE%A4%E4%BD%93%E9%80%89%E6%8B%A9/"/>
    
  </entry>
  
  <entry>
    <title>关于图数据结构，图模型和图算法</title>
    <link href="https://chiechie.github.io/2021/06/11/meditation/graph-summary/"/>
    <id>https://chiechie.github.io/2021/06/11/meditation/graph-summary/</id>
    <published>2021-06-11T10:42:27.000Z</published>
    <updated>2021-06-26T10:56:35.487Z</updated>
    
    <content type="html"><![CDATA[<ol type="1"><li>图数据是一种数据结构，对于图数据有一些常见的任务，比如单源最短路径，等。</li><li>当图数据的点和边具备一定的含义，如边代表概率，这个时候就是一个概率图模型。通常用于对多个变量之间的因果关系或者相关关系进行建模。</li><li>概率图模型可以细分为有向图和无向图。有向图比如贝叶斯网络，无向图比条件随机场（CRF）。</li><li>有向图又可进一步细分，如果边的方向代表因果关系，就是一个因果图。通常因果图都是需要专家构建的。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;图数据是一种数据结构，对于图数据有一些常见的任务，比如单源最短路径，等。&lt;/li&gt;
&lt;li&gt;当图数据的点和边具备一定的含义，如边代表概率，这个时候就是一个概率图模型。通常用于对多个变量之间的因果关系或者相关关系进行建模。&lt;/li&gt;
&lt;li&gt;概率</summary>
      
    
    
    
    <category term="沉思录" scheme="https://chiechie.github.io/categories/%E6%B2%89%E6%80%9D%E5%BD%95/"/>
    
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="图数据" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
</feed>
