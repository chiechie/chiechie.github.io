---
title: 深度学习7 Bert
author: chiechie
mathjax: true
date: 2021-07-08 11:50:30
tags: 
- NLP
- 神经网络
- 模型可视化
- Transformer
- Bert
- attention
categories:
- 深度学习
---


# bert模型


![bert模型可视化](https://images.prismic.io/peltarionv2/e69c6ec6-50d9-43e9-96f0-a09bb338199f_BERT_model.png?auto=compress%2Cformat&rect=0%2C0%2C2668%2C3126&w=1980&h=2320)




# 参考
1. Bahdanau, Cho, & Bengio. Neural machine translation by jointly learning to align and translate. In ICLR, 2015.
2. Cheng, Dong, & Lapata. Long Short-Term Memory-Networks for Machine Reading. In EMNLP, 2016.
3. Vaswani et al. Attention Is All You Need. In NIPS, 2017.
4. [Transformer模型(2/2): 从Attention层到Transformer网络](https://www.youtube.com/watch?v=aJRsr39F4dI)