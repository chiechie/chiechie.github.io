<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Chiechie&#39;s Mini World</title>
  
  <subtitle>Set your course by the stars, not by the lights of passing ships. —— Omar Bradley</subtitle>
  <link href="https://chiechie.github.io/atom.xml" rel="self"/>
  
  <link href="https://chiechie.github.io/"/>
  <updated>2021-06-28T02:07:25.208Z</updated>
  <id>https://chiechie.github.io/</id>
  
  <author>
    <name>Chiechie</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>计算机的存储单元</title>
    <link href="https://chiechie.github.io/2021/06/28/reading_notes/computer/cache-memory/"/>
    <id>https://chiechie.github.io/2021/06/28/reading_notes/computer/cache-memory/</id>
    <published>2021-06-28T01:47:32.000Z</published>
    <updated>2021-06-28T02:07:25.208Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概览">概览</h2><ol type="1"><li><p>计算机上的存储单元的处理速度从快到慢依次是： 寄存器&gt; L1&gt;L2&gt;L3&gt;内存&gt;固态硬盘&gt; 机械硬盘</p><figure><img src="./img_1.png" alt="存储单元" /><figcaption aria-hidden="true">存储单元</figcaption></figure></li><li><p>早期的计算机只有寄存器和内存，但是寄存器的处理速度远高于内存，所以大部分时间是寄存器在等内存，所以CPU是处于空转状态。 经过改进</p></li><li><p>除了寄存器，后面的计算机在CPU中又逐步加入了高速缓存--L1/L2/L3缓存，相当于让内存提前做功课，把数据提前取出来，在3个缓存中候着，等寄存器有空了就取来用。笨鸟先飞嘛。</p></li><li><p>L1/L2/L3缓存，每层速度递减、容量递增。L1缓存速度接近寄存器速度，大约1ns时延。</p></li><li><p>多核CPU的L3对诶个core是共享的，L2和L1是每个core私有的。</p></li></ol><p><img src="./img_2.png" alt="img_2.png" /> 6. CPU读取数据时，要从内存读取到L3，再读取到L2再读取到L1，同样写到内存时也会经过这些层次。</p><h2 id="参考">参考</h2><ol type="1"><li>https://www.junmajinlong.com/os/cpu_cache/</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;概览&quot;&gt;概览&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;计算机上的存储单元的处理速度从快到慢依次是： 寄存器&amp;gt; L1&amp;gt;L2&amp;gt;L3&amp;gt;内存&amp;gt;固态硬盘&amp;gt; 机械硬盘&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;./img_1</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="计算机原理" scheme="https://chiechie.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/"/>
    
    <category term="内存" scheme="https://chiechie.github.io/tags/%E5%86%85%E5%AD%98/"/>
    
    <category term="缓存" scheme="https://chiechie.github.io/tags/%E7%BC%93%E5%AD%98/"/>
    
    <category term="寄存器" scheme="https://chiechie.github.io/tags/%E5%AF%84%E5%AD%98%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>进程和线程</title>
    <link href="https://chiechie.github.io/2021/06/27/reading_notes/computer/thread-and-process/"/>
    <id>https://chiechie.github.io/2021/06/27/reading_notes/computer/thread-and-process/</id>
    <published>2021-06-27T04:16:07.000Z</published>
    <updated>2021-06-28T02:06:27.111Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本定义">基本定义</h2><h3 id="进程process">进程（process）</h3><p>我们想要计算机要做一项任务（task），我们会写一段代码（python/java等）。</p><p>编译器将它翻译成二进制代码--机器的语言。</p><p>但是此时不执行这段断码的话，就还是一段静态程序。</p><p>当执行起来的时候，就变成了一个进程。</p><p>进程（process）有时候也称做任务，是指一个程序运行的实例。</p><h3 id="线程threads">线程（threads）</h3><p>一个进程中的执行的单位。</p><p>线程（thread）：能并行运行，并且与他们的父进程（创建他们的进程）共享同一地址空间（一段内存区域）和其他资源的轻量级的进程</p><h2 id="应用-vs-线程-vs-进程">应用 vs 线程 vs 进程</h2><p>一个应用，比如chrome，可能会启动多个进程（多个网页）, 一个进有多个线程。</p><p>进程和线程的区别：</p><p>• 进程（火车）间不会相互影响，一个线程（车厢）挂掉将导致整个进程（火车）挂掉 • 线程（车厢）在进程（火车）下行进 • 一个进程（火车）可以包含多个线程（车厢） • 不同进程（火车）间数据很难共享，同一进程（火车）下不同线程（车厢）间数据很易共享 线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据， 进程之间的通信需要以通信的方式（IPC)进行 • 进程要比线程消耗更多的计算机资源 • 进程间不会相互影响，一个线程挂掉将导致整个进程挂掉 • 进程可以拓展到多机，线程最多适合多核 • 进程使用的内存地址可以上锁，即一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。－"互斥锁" • 进程使用的内存地址可以限定使用量－“信号量”</p><h2 id="硬件多线程vs软件多线程">硬件多线程vs软件多线程</h2><p>CPU架构演进路线： 多cpu---&gt;超线程--&gt;多core</p><p>https://stackoverflow.com/questions/680684/multi-cpu-multi-core-and-hyper-thread</p><p>其中的超线程（hyper thread）指的硬件多线程，如下图，相当于给一个core，虚拟化为2个core，可以更方便压榨计算机性能</p><h2 id="多进程-or-多线程">多进程 or 多线程？</h2><p>多进程更稳定，但是多线程能达到更高的计算效率</p><figure><img src="img_1.png" alt="左边是单线程，右边是多线程" /><figcaption aria-hidden="true">左边是单线程，右边是多线程</figcaption></figure><p>多线程的优势：</p><ul><li>响应性：比如启动一个网页（启动一个浏览器进程），可以同时并行做个事情，如浏览/下载/问答（并行启动多个线程）。</li><li>资源共享：一个进程上的所有线程共享同一份内存，这样能够让机器的使用效率更高，可以做更多的复杂的事情。---赋能/增效</li><li>更经济： 多进程浪费资源，因为创建1个进程需要分配很多内存和资源，相比之下，创建和切换线程的成本小的多。另外，完成一个复杂的任务，多线程共用一份底层资源，多进程就需要把资源复制几份。又浪费了一遍。--降本</li><li>充分压榨多处理器的架构：</li></ul><blockquote><p>大中台类似多线程，烟囱式开发类似多进程</p></blockquote><h2 id="实践">实践</h2><h3 id="练习1-模拟单线程cpp的进程管理">练习1-模拟单线程CPP的进程管理</h3><p><a href="https://leetcode-cn.com/problems/single-threaded-cpu/">leetcode</a>的题目，</p><p>需求：实现一个任务管理/编排的机制，即，输入一堆任务，每个任务的计划执行时间/执行时长都有，现在有一台单线程CPU，如何安排这些任务的执行顺序？</p><p>分析：设计两个数据结构：1个是普通队列，存放每个任务的计划执行时间；还有1个是优先队列，存放候选执行任务，并且按照优先级排序。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tasks = [[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">4</span>],[<span class="number">3</span>,<span class="number">2</span>],[<span class="number">4</span>,<span class="number">1</span>]]</span><br><span class="line">n = <span class="built_in">len</span>(tasks)</span><br><span class="line">timestamp = <span class="number">1</span></span><br><span class="line">candidate_list = []</span><br><span class="line">new_task = []</span><br><span class="line">j = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    <span class="keyword">while</span> (j &lt; n) <span class="keyword">and</span> (tasks[j][<span class="number">0</span>] &lt;= timestamp):</span><br><span class="line">        heapq.heappush(candidate_list, (tasks[j][<span class="number">1</span>], j))</span><br><span class="line">        j+=<span class="number">1</span></span><br><span class="line">        print(j, n)</span><br><span class="line">    print(candidate_list)</span><br><span class="line">    process, index = heapq.heappop(candidate_list)</span><br><span class="line">    print(candidate_list)</span><br><span class="line">    new_task.append(index)</span><br><span class="line">    timestamp += process</span><br><span class="line">new_task</span><br></pre></td></tr></table></figure><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.zhihu.com/question/25532384/answer/411179772">biaodianfu-zhihu</a></li><li><a href="https://www.youtube.com/watch?v=usyg5vbni34">thred</a></li><li><a href="https://www.junmajinlong.com/os/multi_cpu/">计算机原理系列-blog</a></li><li><a href="https://www.junmajinlong.com/os/cpu_cache/">关于CPU上的高速缓存</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基本定义&quot;&gt;基本定义&lt;/h2&gt;
&lt;h3 id=&quot;进程process&quot;&gt;进程（process）&lt;/h3&gt;
&lt;p&gt;我们想要计算机要做一项任务（task），我们会写一段代码（python/java等）。&lt;/p&gt;
&lt;p&gt;编译器将它翻译成二进制代码--机器的语言。&lt;/p&gt;
</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="计算机原理" scheme="https://chiechie.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/"/>
    
    <category term="线程" scheme="https://chiechie.github.io/tags/%E7%BA%BF%E7%A8%8B/"/>
    
    <category term="进程" scheme="https://chiechie.github.io/tags/%E8%BF%9B%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>数据结构基础</title>
    <link href="https://chiechie.github.io/2021/06/25/data_structure/data-structure-base/"/>
    <id>https://chiechie.github.io/2021/06/25/data_structure/data-structure-base/</id>
    <published>2021-06-25T01:17:29.000Z</published>
    <updated>2021-06-28T02:08:34.886Z</updated>
    
    <content type="html"><![CDATA[<ol type="1"><li><p>数据结构分为线性和非线性</p></li><li><p>线性包括数组列表栈队列</p><figure><img src="b3728c27302a8548fe9e8a87e619ca83.png" alt="线性数据结构" /><figcaption aria-hidden="true">线性数据结构</figcaption></figure></li><li><p>非线性包括树和图,树可以认为是图的special case <img src="e6d5a8d9a75587abe612dfef9abffc01.png" alt="非线性数据结构" /></p></li><li><p>图分有向图和无向图</p><figure><img src="18c651092d22c7204021d10a5a79b0ff.png" alt="有向图vs无向图" /><figcaption aria-hidden="true">有向图vs无向图</figcaption></figure></li><li><p>无向图的一个实例是fb的社交网络，边表示好友关系。</p><figure><img src="f3fc896014d62fb1ec1c96c93210f7ff.png" alt="社交网络" /><figcaption aria-hidden="true">社交网络</figcaption></figure></li><li><p>基于社交网络这个数据结构有什么应用呢？好友推荐, 推荐朋友的朋友,网络社会科学的小世界</p><blockquote><p>小世界网络的重要性质：“流行病学”、“合作”、“知识”</p></blockquote><figure><img src="d5fe57a166d6f2ee93457d0ea4b54cef0.png" alt="社交网路" /><figcaption aria-hidden="true">社交网路</figcaption></figure></li><li><p>有向图的一个实例是万维网,好有一个文章影响因子 <img src="b9b97250ce6e998045dcbb0d5b379724.png" alt="www" /></p></li><li><p>图还可以分有权图和无权图，无权图可认为是权图的special case，权重都为1。</p></li><li><p>有权图的一个实例是高速公路网,边代表距离 <img src="5b81b50b2d2b048ed3188b71af85a02f.png" alt="公路网" /></p></li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.youtube.com/watch?v=gXgEDyodOJU">youtube</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;数据结构分为线性和非线性&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;线性包括数组列表栈队列&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;b3728c27302a8548fe9e8a87e619ca83.png&quot; alt=&quot;线性数据结构&quot; /&gt;&lt;f</summary>
      
    
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="编程" scheme="https://chiechie.github.io/tags/%E7%BC%96%E7%A8%8B/"/>
    
    <category term="数据结构" scheme="https://chiechie.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="图数据" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>细说红楼梦</title>
    <link href="https://chiechie.github.io/2021/06/21/reading_notes/zhexue/hongloumengxishuo/"/>
    <id>https://chiechie.github.io/2021/06/21/reading_notes/zhexue/hongloumengxishuo/</id>
    <published>2021-06-21T02:02:37.000Z</published>
    <updated>2021-06-22T06:21:25.475Z</updated>
    
    <content type="html"><![CDATA[<h2 id="第一回">第一回</h2><p>空空道人有批注：“因空见色，由色生情，传情入色，自色悟空，遂易名为情僧……”</p><p>“因空见色”，是说本来就白茫茫一片，什么都没有，（六祖慧能：本来无一物），因为我们的幻觉，看到好多好多的现象，“由色生情”，情多了就会陷进去，陷进了更深的色的幻觉，“传情入色”，要经过多少彻悟之后，再从里面出来，“自色悟空”，再回到白茫茫一片真干净。</p><p>甄士隐经了这许多人生起伏，有一天突然又看见跛足道士来了，口里唱一首《好了歌》：</p><blockquote><p>世人都晓神仙好，惟有功名忘不了！古今将相在何方？荒冢一堆草没了。世人都晓神仙好，只有金银忘不了！终朝只恨聚无多，及到多时眼闭了。世人都晓神仙好，只有姣妻忘不了！君生日日说恩情，君死又随人去了。世人都晓神仙好，只有儿孙忘不了！痴心父母古来多，孝顺儿孙谁见了？</p></blockquote><p>甄士隐说：“你唱什么？我只听见‘好’‘了’、‘好’‘了’两个字。道人说：</p><blockquote><p>好便是了，了便是好。若不了，便不好；若要好，须是了。</p></blockquote><p>跛足道人讲的是道家的哲学，对儒家社会秩序，有很大的颠覆性。儒家修身齐家治国平天下这一套道理，要建立的是稳定的社会秩序（social order），鼓励人入世，求功名、利禄、妻子、儿女，儒家宗法社会下面，大概就是这些。</p><p>跛足道人给了很大的一个警告，好就是了，了就是好，等于给恋恋在红尘中的人临头棒喝、醍醐灌顶。</p><p>人大概都经过几个阶段：年轻的时候，大家都是入世哲学，儒家那一套，要求功名利禄。到了中年，大概受了些挫折，于是道家来了，点你一下，有所醒悟。到了最后，要超脱人生境界的时候，佛家就来了。</p><p>所以过去的中国人，从儒道释，大致都经过这么三个阶段，有意思的是这三个阶段不冲突。在同一个人身上，这三样哲学都有。所以中国人既出世又入世的态度，常常造成整个文化的一种紧张，也就是说，我们的人生态度在这之间常常有一种徘徊迟疑，我想，这就是文学的起因。</p><p>文学写什么呢？写一个人求道提升，讲他的目标求道，讲这一生多么地艰难，往往很多人没有求到，在半路已经失败。不管是爱情也好，理想也好，各种的失败，我想，文学写的就是这些。《红楼梦》写的也是这些。</p><p>甄士隐对《好了歌》的注解：</p><blockquote><p>陋室空堂，当年笏满床；衰草枯杨，曾为歌舞场。蛛丝儿结满雕梁，绿纱今又糊在蓬窗上。说什么脂正浓、粉正香，如何两鬓又成霜？昨日黄土陇头送白骨，今宵红灯帐底卧鸳鸯。金满箱，银满箱，展眼乞丐人皆谤。正叹他人命不长，那知自己归来丧！训有方，保不定日后作强梁。择膏粱，谁承望流落在烟花巷！因嫌纱帽小，致使锁枷扛；昨怜破袄寒，今嫌紫蟒长：乱烘烘你方唱罢我登场，反认他乡是故乡。甚荒唐，到头来都是为他人作嫁衣裳！</p></blockquote><p>人生不就是个大舞台，一个人唱完下来，第二个人上去唱，唱完又一鞠躬下台，又换个人上去唱，“乱烘烘你方唱罢我登场”，然后“反认他乡是故乡”。</p><p>佛家说，我们以为这是我们自己的故乡，其实也靠不住，一下子一把火就整个烧掉了。道家说，要醒悟这一点，才找到你真正理想的地方。甚荒唐！到头来都是为他人做嫁衣裳。讲起来，整个一生是白忙一场，都为他人做嫁衣裳，所有事情都是为他人做的。</p><p>甄士隐、贾雨村，一个代表出世，一个代表入世。后来甄士隐变成道士，贾雨村经过好多官宦历程的折腾，到了书结束的时候，这两人又碰到一起。甄士隐想要度化贾雨村，贾雨村还是迷恋红尘。各走各的路，两个分歧，自己去看，自己去选择。</p><h2 id="第二章">第二章</h2><p>贾政，自觉是遵从儒家理想的一个人。他非常正直，也想用儒家那一套思想道德来持家，但是太过守法，太过拘束了。中国社会能够生存下来，光靠儒家思想、书生之见是不够的，还需要别种哲学，譬如很要紧的法家，很实在的、很现实的顶在后边。儒家的很多理想不一定都能实现，碰到了现实问题，常常不能解决。不过儒家也很重要，它是一种道德力量（moral force），没有它也不行，但光是有它也不行，所以，还要配合别的东西。</p><p>贾雨村听冷子兴讲了半天贾宝玉这个怪人，也发表了一篇言论：</p><p>“天地生人，除大仁大恶两种，馀者皆无大异。若大仁者，则应运而生，大恶者，则应劫而生。运生世治，劫生世危。尧、舜、禹、汤、文、武、周、召、孔、孟、董、韩、周、程、张、朱，皆应运而生者。蚩尤、共工、桀、纣、始皇、王莽、曹操、桓温、安禄山、秦桧等，皆应劫而生者。大仁者，修治天下；大恶者，挠乱天下。清明灵秀，天地之正气，仁者之所秉也；残忍乖僻，天地之邪气，恶者之所秉也。今当运隆祚永之朝，太平无为之世，清明灵秀之气所秉者，上至朝廷，下及草野，比比皆是。所馀之秀气，漫无所归，遂为甘露、为和风，洽然溉及四海。彼残忍乖僻之邪气，不能荡溢于光天化日之中，遂凝结充塞于深沟大壑之内，偶因风荡，或被云摧，略有摇动感发之意，一丝半缕误而泄出者，偶值灵秀之气适过，正不容邪，邪复妒正，两不相下，亦如风水雷电，地中既遇，既不能消，又不能让，必至搏击掀发后始尽。故其气亦必赋人，发泄一尽始散。使男女偶秉此气而生者，在上则不能成仁人君子，下亦不能为大凶大恶。置之于万万人中，其聪俊灵秀之气，则在万万人之上；其乖僻邪谬不近人情之态，又在万万人之下。若生于公侯富贵之家，则为情痴情种；若生于诗书清贫之族，则为逸士高人；纵再偶生于薄祚寒门，断不能为走卒健仆，甘遭庸人驱制驾驭，必为奇优名娼。如前代之许由、陶潜、阮籍、嵇康、刘伶、王谢二族、顾虎头、陈后主、唐明皇、宋徽宗、刘庭芝、温飞卿、米南宫、石曼卿、柳耆卿、秦少游，近日之倪云林、唐伯虎、祝枝山，再如李龟年、黄幡绰、敬新磨、卓文君、红拂、薛涛、崔莺、朝云之流，此皆易地则同之人也。”</p><h2 id="第四章">第四章</h2><p>再看看贾雨村这个人，他也是有高度象征性的一个人，象征这个世界上每一个为求功名利禄不择手段往上爬的凡俗之人。</p><p>贾雨村刚刚做官，还不太清楚。葫芦僧就讲，贾、王、史、薛这四大家族是互相牵连、互相庇护的，你一动薛家，其他家族就暗中使力，根本没法去办他们。的确是！后来薛蟠又打死人，贾家去讲讲情也就过了。</p><p>为官为政的这些人，像贾雨村者也是很典型的，一旦发迹，若从前是贫贱出身，他不愿意人家知道他的过去，哪个不长心眼儿的去碰他的过去的话，砍掉！因为他要维持现在的形象，掩掉过去。后来贾家没落的时候，贾雨村果然对有恩的贾家加踹一脚，这正是官场反复无情的写照。</p><h2 id="第五章">第五章</h2><p>无常，我们看起来好像是个悲剧，在佛家看，人所有的一切就是如此。佛教很理性地看待人生，看待一切的事物，没有永远存在的东西，因为时间会破坏一切、会毁灭一切，有时间的转动，春夏秋冬的转动，就会有无常现象。人生无常，什么都无常。所以，“生关死劫谁能躲？闻说道，西方宝树唤婆娑，上结着长生果。”这是惜春的醒悟！佛教的传说，佛陀释迦牟尼圆寂的时候，是在两棵宝树中间，那两棵宝树叫作“娑罗”。佛教对“婆娑”两字另有所解，长生果，佛家讲修成正果，要悟道了以后，从而解脱。最后惜春出家了，她是找到解脱最彻底的一个人物。</p><p>王熙凤，机关算尽太聪明，她最精明，涉入红尘也最深，《好了歌》讲：“世人都晓神仙好，只有金银忘不了！”等到聚多之时缘尽了。凤姐放高利贷，到处攒钱，聚敛多时，一下子抄家抄得精光，一场空欢喜！她在贾府最得宠，掌大权，抄家的原因之一是她放高利贷给抄出来了，一世的颜面丢得精光。“反算了卿卿性命”，后来王熙凤的下场也很悲惨。</p><p>对照一下，惜春走一条路，王熙凤走另外一条路，一个出世，一个入世，两种不同的道路。甄士隐跟贾雨村，也是出世和入世的辩证。曹雪芹从未批判哪方，他只是写出各人选的道路。儒家的入世在《红楼梦》的结局也很重要，贾府衰败，王熙凤死了，也还有接班人，谁呢？薛宝钗，她把贾府重新扛起来，这就是人生。</p><p>中国人的人生，常常有三种哲学的循环。年轻的时候有所求，中年醒悟，晚年一切看开。有这三种哲学，才是完整的中国文化，三者相克相生，互用互补。 《红楼梦》曲最后收尾的曲子：</p><blockquote><p>为官的，家业凋零；富贵的，金银散尽；有恩的，死里逃生；无情的，分明报应。欠命的，命已还；欠泪的，泪已尽。冤冤相报实非轻，分离聚合皆前定。欲知命短问前生，老来富贵也真侥幸。看破的，遁入空门；痴迷的，枉送了性命。好一似食尽鸟投林，落了片白茫茫大地真干净！</p></blockquote><h2 id="第16回">第16回</h2><p>儒家跟道家人生观，宇宙、社会的看法，互相冲突。《红楼梦》的悲剧，并不是一个突发性的意外，而是人生必然的过程，</p><h2 id="第22回">第22回</h2><p>宝玉出的灯谜：南面而坐，北面而朝，“象忧亦忧，象喜亦喜”。 佛家有一句话说镜花水月，一切都是幻象。宝玉看到的一切，由色入空，一切都是幻象。</p><h2 id="参考">参考</h2><ol type="1"><li>https://weread.qq.com/web/reader/3c432fc05d0f283c488450e</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;第一回&quot;&gt;第一回&lt;/h2&gt;
&lt;p&gt;空空道人有批注：“因空见色，由色生情，传情入色，自色悟空，遂易名为情僧……”&lt;/p&gt;
&lt;p&gt;“因空见色”，是说本来就白茫茫一片，什么都没有，（六祖慧能：本来无一物），因为我们的幻觉，看到好多好多的现象，“由色生情”，情多了就会陷进</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="道家" scheme="https://chiechie.github.io/tags/%E9%81%93%E5%AE%B6/"/>
    
    <category term="佛家" scheme="https://chiechie.github.io/tags/%E4%BD%9B%E5%AE%B6/"/>
    
    <category term="人生哲学" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E7%94%9F%E5%93%B2%E5%AD%A6/"/>
    
    <category term="儒家" scheme="https://chiechie.github.io/tags/%E5%84%92%E5%AE%B6/"/>
    
  </entry>
  
  <entry>
    <title>概率图简介</title>
    <link href="https://chiechie.github.io/2021/06/19/data_structure/graph/gailvtu/"/>
    <id>https://chiechie.github.io/2021/06/19/data_structure/graph/gailvtu/</id>
    <published>2021-06-19T08:52:21.000Z</published>
    <updated>2021-06-28T02:12:21.520Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本概念">基本概念</h2><p>概率图模型(Probabilistic Graphical Model，PGM)，简称图模型(Graphical Model，GM)，首先是一种概率模型，其次，它用图结构描述多个随机变量之间的依赖关系，它是研究高维空间中的概率模型的一种有用工具。</p><p>概率图模型有三个基本问题: 表示问题，学习问题和推断问题</p><p><img src="https://img.mubu.com/document_image/e3036b4e-18d3-4e73-b996-eafe4a4c08d1-3380623.jpg" /></p><h3 id="表示问题">1. 表示问题</h3><p>表示问题，即对于一个概率模型，如何通过图结构来描述变量之间的依赖关系。</p><h4 id="有向图模型directed-graphical-model">有向图模型(Directed Graphical model)</h4><p>有向图模型(Directed Graphical model)，也称为贝叶斯网络(Bayesian Network)，或信念网络(Belief Network，BN)，是指用有向图来表示概率分布的图模型。</p><figure><img src="https://img.mubu.com/document_image/75c9420a-058f-4005-a4b2-4609e7987c1b-3380623.jpg" alt="贝叶斯网络" /><figcaption aria-hidden="true">贝叶斯网络</figcaption></figure><p>很多机器学习模型可以用有向图模型来描述，比如</p><ul><li>朴素贝叶斯分类器</li><li>隐马尔可夫模型</li><li>深度信念网络(sigmoid 信念网络)</li></ul><h4 id="无向图模型">无向图模型</h4><p>无向图模型也称为马尔可夫随机场(Markov Random Field，MRF)或 马尔可夫网络(Markov Network)，是一类用无向图来描述一组具有局部马尔可夫性质的随机向量 X 的联合概率分布的模型。</p><figure><img src="https://img.mubu.com/document_image/85a18510-051c-4339-a808-4d3759095432-3380623.jpg" alt="无向图模型" /><figcaption aria-hidden="true">无向图模型</figcaption></figure><ul><li><p>如果(G,X)满足局部马尔可夫性质， 即一个变量 Xk 在给定它的邻居的情况下独立于所有其它变量，</p></li><li><p>无向图模型的概率分解</p><ul><li>因子分解 :无向图中的的联合概率可以分解为一系列定义在最大团上的非负函数的乘积形式。</li><li>吉布斯分布 :无向图模型和吉布斯分布是一致的。吉布斯分布一定满足马尔可夫随机场的条件独立性质，并且马尔可夫随机场的概率分布一定可以表示成吉布斯分布。</li></ul></li><li><p>常见的无向图模型:很多经典的机器学习模型可以使用无向图模型来描述，比如</p><ul><li>对数线性模型(Log-Linear Model)或最大熵模型(Maximum Entropy Model)</li><li>条件随机场(Conditional Random Field，CRF)</li><li>玻尔兹曼机</li><li>受限玻尔兹曼机等</li></ul></li><li><p>有向图和无向图之间的转换:</p><ul><li>无向图模型可以表示有向图模型无法表示的一些依赖关系，比如循环依赖;</li><li>无向图模型不能表示有向图模型能够表示的某些关系，比如因果关系。</li></ul></li></ul><h3 id="推断问题">2. 推断问题</h3><p>推断问题，即在已知部分变量时，计算其它变量的后验概率分布。</p><p>图模型的推断问题可以转换为求任意一个变量子集的边际概率分布问题。</p><h4 id="精确推断">精确推断</h4><p>精确推断的方法有变量消除法和信念传播方法</p><p>信念传播(Belief Propagation，BP)算法，也称为和积(Sum-Product)算法 或消息传递(Message Passing)算法，是将变量消除法中的和积(Sum-Product) 操作看作是消息，并保存起来，这样可以节省大量的计算资源。</p><p>链式结构上的的信念传播算法</p><p><img src="https://img.mubu.com/document_image/bd0b3e40-76a5-42e2-8716-799247eddc32-3380623.jpg" /></p><p>树结构上的信念传播算法：</p><ul><li>从叶子节点到根节点依次计算并传递 消息;</li><li>从根节点开始到叶子节点，依次计算并传递消息;</li><li>在每个节点上 计算所有接收消息的乘积(如果是无向图还需要归一化)，就得到了所有变量的 边际概率。</li></ul><p>环路信念传播</p><h4 id="近似推断">近似推断</h4><p>图模型中有些变量的局部条件分布可能非常复杂，或其积分无法计算。需要使用数值方法来近似，比如，变分法和采样法</p><h5 id="变分法">变分法</h5><p>变分法(Variational Method)是引入一个变分分布(通常是比较简单的分布)来近似复杂的局部条件概率，然后通过迭代的方法计算后验分布。</p><h5 id="采样法">采样法</h5><p>采样法(SamplingMethod) 是通过simulation的方式来采集符合某个分布 p(x) 的一些样本，并通过这些样本来估计和这个分布有关的运算，比如期望等。</p><ol type="1"><li>拒绝采样(Rejection Sampling):也叫接受-拒绝采样(Acceptance-RejectionSampling)：假设原始分布 p(x) 难以直接采样，可引入一个容易采样的分布 q(x)， 一般称为提议分布(Proposal Distribution)，然后以某个标准来拒绝一部分的样本使得最终采集的样本服从分布p(x)。</li></ol><p><img src="https://img.mubu.com/document_image/f6ae17af-597a-4445-abbf-2c2b0a5bce67-3380623.jpg" /></p><ol start="2" type="1"><li>重要性采样(Importance Sampling):通过引入重要性权重，将分布p(x)下f(x)的期望变为在分布q(x)下f(x)w(x)的期望.如果采样的目的是计算分布 p(x)下函数f(x)的期望，那么实际上抽取的样本不需要严格服从分布p(x)。也可以通过另一个分布，即提议分布q(x)，直接采样并估计。</li><li>马尔可夫链蒙特卡罗(Markov Chain Monte Carlo，MCMC): 在高维空间中拒绝采样和重要性采样效率低，<ul><li>Metropolis-Hastings算法，以及两个特例Metropolis算法和吉布斯采样(Gibbs Sampling)</li><li>Metropolis算法，假设MH算法中的提议分布是对称的</li><li>吉布斯采样(Gibbs Sampling)，用全条件概率(Full Conditional Probability)作为提议分布来依次对每个维度 进行采样，并设置接受率为A = 1。</li></ul></li></ol><blockquote><p>蒙特卡罗的基本思想可以归结为，根据一个已知概率密度函数为 p(x) 的 分布来计算函数 f (x) 的期望</p></blockquote><h3 id="学习问题">3. 学习问题</h3><p>概率图模型的学习包括：图结构的学习和参数的学习</p><p>参数的学习，即参数估计问题，可分为含隐变量的参数估计和不含因变量的参数估计：</p><ul><li><p>不含隐变量的参数估计：</p><ul><li>如果图模型中不包含隐变量，即所有变量都是可观测的，那么网络参数一般可以直接通过最大似然来进行估计。</li><li>有向图模型：所有变量x的联合概率分布可以分解为每个随机变量<span class="math inline">\(x_k\)</span>的局部条件概率 <span class="math inline">\(p(xk |xπk , \theta_k)\)</span> 的连乘形式，其中<span class="math inline">\(\theta_k\)</span>为第 k 个变量的局部 条件概率的参数。</li><li>无向图模型： 所有变量x的联合概率分布可以分解为定义在最 大团上的势能函数的连乘形式。</li></ul></li><li><p>含隐变量的参数估计：</p><ul><li>如果图模型中包含隐变量，即有部分变量是不可观测的，就需要用 EM 算法</li><li>EM 算法的应用例子:高斯混合模型。高斯混合模型(Gaussian Mixture Model，GMM)是由多个高斯分布组成的模型，其密度函数为多个高 斯密度函数的加权组合。 <img src="https://img.mubu.com/document_image/3476923c-5528-4dd4-aa4d-ae10183bf377-3380623.jpg" /> <img src="https://img.mubu.com/document_image/28d53640-0eb6-4a17-81c6-ffa8e4dbb289-3380623.jpg" /></li></ul></li></ul><h2 id="概率图模型与机器学习">概率图模型与机器学习</h2><ul><li>很多机器学习模型都可以归结为概率模型，即建模输入和输 出之间的条件概率分布。</li><li>图模型提供了一种新的角度来解释机器学习模 型，并且这种角度有很多优点，比如了解不同机器学习模型之间的联系，方便设计新模型等。</li><li>概率图模型中最基本的假设是条件独立性。图形化表示直观地描述了随机 变量之间的条件独立性，有利于将复杂的概率模型分解为简单模型的组合，并 更好地理解概率模型的表示、推断、学习等方法。</li></ul><h2 id="概率图模型与神经网络">概率图模型与神经网络</h2><p>概率图模型和神经网络有着类似的网络结构，但两者不同。</p><ul><li>节点<ul><li>概率图模型的节点是随机变量，其图结构的主要功能是用来描述变量 之间的依赖关系，一般是稀疏连接。使用图模型的好处是可以有效进行统计推 断。</li><li>神经网络中的节点是神经元，是一个计算节点。如果将神经网络中每个神经元看做是一个binary随机变量，那神经网络就变成一个sigmoid信念网络。</li></ul></li><li>变量的含义<ul><li>图模型中的每个变量一般有着明确的解释，<strong>变量之间依赖关系一般是人工来定义</strong>。</li><li>神经网络中的单个神经元则没有直观的解释</li></ul></li><li>生成模型与判别模型<ul><li>神经网络是判别模型，直接用来分类</li><li>图模型不但可以是判别模型，也可以是生成模型。生成模型不但可以用来生成样本，也可以通过贝叶斯公式用来做分类。</li></ul></li><li>学习方法<ul><li>神经网络参数学习的目标为交叉熵或平方误差等损失函数。</li><li>图模型的参数学习的目标函数为似然函数或条件似然函数，若包含隐变量则通常通过EM算法来求解。</li></ul></li></ul><p>神经网络和概率图模型的结合：</p><ul><li><p>用神经网络强大的表示能力来建模图模型中的</p><ul><li>推断问题：比如变分自编码器</li><li>生成问题：比如生成对抗网络，第</li><li>势能函数：比如 LSTM+CRF模型[Lample et al., 2016, Ma and Hovy, 2016]</li></ul></li><li><p>用图模型的算法来解决复杂结构神经网络中的学习和推断问题</p><ul><li>图结构神经网络(Graph Neural Network)</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基本概念&quot;&gt;基本概念&lt;/h2&gt;
&lt;p&gt;概率图模型(Probabilistic Graphical Model，PGM)，简称图模型(Graphical Model，GM)，首先是一种概率模型，其次，它用图结构描述多个随机变量之间的依赖关系，它是研究高维空间中的概率</summary>
      
    
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="贝叶斯网络" scheme="https://chiechie.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C/"/>
    
    <category term="概率图" scheme="https://chiechie.github.io/tags/%E6%A6%82%E7%8E%87%E5%9B%BE/"/>
    
    <category term="贝叶斯优化" scheme="https://chiechie.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>哲学导论</title>
    <link href="https://chiechie.github.io/2021/06/18/reading_notes/zhexue/zhexue-summart/"/>
    <id>https://chiechie.github.io/2021/06/18/reading_notes/zhexue/zhexue-summart/</id>
    <published>2021-06-18T09:01:52.000Z</published>
    <updated>2021-06-28T02:11:59.256Z</updated>
    
    <content type="html"><![CDATA[<h1 id="定义">定义</h1><p>哲学，就我对这个词的理解来说，乃是某种介乎神学与科学之间的东西。它和神学一样，包含着人类对于那些迄今仍为科学知识所不能肯定之事物的思考；但它又像科学一样，是诉之于人类的理性而不是诉之于权威的，不论是传统的权威还是启示的权威。一切确切的知识都属于科学；一切涉及超乎确切知识之外的教条都属于神学。但介乎神学与科学之间还有一片受到双方攻击的无人之域，这片无人之域就是哲学。---罗素</p><h1 id="哲学的主分支">哲学的主分支</h1><p>哲学的主分支：形而上学、知识论、伦理学、逻辑学和美学 - <a href="https://zh.wikipedia.org/wiki/%E9%82%8F%E8%BC%AF%E5%AD%B8">逻辑学</a> - <a href="https://zh.wikipedia.org/wiki/%E5%BD%A2%E8%80%8C%E4%B8%8A%E5%AD%B8">形而上学</a>/<a href="https://zh.wikipedia.org/wiki/%E5%AE%87%E5%AE%99%E8%AB%96">宇宙论</a> - <a href="https://zh.wikipedia.org/wiki/%E7%9F%A5%E8%AD%98%E8%AB%96">知识论</a> - <a href="https://zh.wikipedia.org/wiki/%E5%80%AB%E7%90%86%E5%AD%B8">伦理学</a>/<a href="https://zh.wikipedia.org/wiki/%E5%83%B9%E5%80%BC%E8%AB%96">价值论</a> - <a href="https://zh.wikipedia.org/wiki/%E7%BE%8E%E5%AD%B8">美学</a></p><h1 id="特殊分支">特殊分支</h1><p>哲学的特殊分支：是交叉学科的哲学研究</p><ul><li><a href="https://zh.wikipedia.org/wiki/%E5%85%83%E5%93%B2%E5%AD%A6">后设哲学</a></li><li><a href="https://zh.wikipedia.org/wiki/%E5%AE%97%E6%95%99%E5%93%B2%E5%AD%A6">宗教哲学</a></li><li><a href="https://zh.wikipedia.org/wiki/%E5%BF%83%E9%9D%88%E5%93%B2%E5%AD%B8">心灵哲学</a></li><li><a href="https://zh.wikipedia.org/wiki/%E8%AF%AD%E8%A8%80%E5%93%B2%E5%AD%A6">语言哲学</a></li><li><a href="https://zh.wikipedia.org/wiki/%E7%A7%91%E5%AD%A6%E5%93%B2%E5%AD%A6">科学哲学</a>： 现代西方科学哲学的中心是<strong>科学方法论</strong>问题，具体包括<ul><li>统计哲学：统计假设检验（证伪），贝叶斯</li><li>数学哲学：</li><li>物理哲学</li><li>化学哲学</li><li>生物哲学</li><li>医学哲学</li><li>心理学哲学</li><li>经济哲学</li><li>社会科学哲学：代表之一---马克思</li></ul></li><li><a href="https://zh.wikipedia.org/wiki/%E6%94%BF%E6%B2%BB%E5%93%B2%E5%AD%A6">政治哲学</a></li><li><a href="https://zh.wikipedia.org/wiki/%E6%B3%95%E5%BE%8B%E5%93%B2%E5%AD%B8">法律哲学</a></li></ul><h2 id="西方的-科学哲学发展路径">西方的 科学哲学发展路径</h2><ul><li>到50年代为止，一直是作为“正统科学哲学”的<strong>逻辑实证主义</strong>占主导地位</li><li>从50年代末兴起，在60年代发展和完成：波普尔的<strong>批判理性主义</strong>和库恩-拉卡托斯的<strong>历史主义</strong>科学哲学。</li><li>至70年代，出现了两股发展趋势。<ul><li>一股是<strong>复兴</strong>和发展“正统<strong>的”逻辑主义方法论</strong>，</li><li>另一股就是法伊尔阿本德的<strong>非理性主义</strong>，它在很大程度上是把<strong>历史主义</strong>中的非理性因素贯彻到极端程度的产物。</li></ul></li><li>本书对<strong>逻辑实证主义</strong>和波普尔、库恩与拉卡托斯的科学哲学等现代西方理性主义科学哲学学说一一作了批判，并在这个批判中阐发了自己的科学哲学——<strong>多元主义方法论</strong></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;定义&quot;&gt;定义&lt;/h1&gt;
&lt;p&gt;哲学，就我对这个词的理解来说，乃是某种介乎神学与科学之间的东西。它和神学一样，包含着人类对于那些迄今仍为科学知识所不能肯定之事物的思考；但它又像科学一样，是诉之于人类的理性而不是诉之于权威的，不论是传统的权威还是启示的权威。一切确切的</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="哲学" scheme="https://chiechie.github.io/tags/%E5%93%B2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>关于AGI？</title>
    <link href="https://chiechie.github.io/2021/06/17/meditation/about-AGI/"/>
    <id>https://chiechie.github.io/2021/06/17/meditation/about-AGI/</id>
    <published>2021-06-17T09:04:32.000Z</published>
    <updated>2021-06-28T02:11:37.160Z</updated>
    
    <content type="html"><![CDATA[<h2 id="chiechies-reflection">chiechie's reflection</h2><ol type="1"><li>理论突破不是技术爆发的必经之路，很多技术都没有理论，比如古代时候的发明，造船，造纸，造火药，爱迪森发明电灯泡，还有现代的量子计算机和深度学习，理论完备个P。</li><li>大部分发明都是做实验，通过试错迭代而产生的,而很多情况下理论都是滞后的。</li></ol><h2 id="无人驾驶现状">无人驾驶现状</h2><ol type="1"><li>一个技术在工业化生产之前，一般要经历三个阶段, 理论突破，技术验证，工程化<ol type="1"><li>理论突破，科学家在理论上证明其可行性，即产品要达到一个什么样的性能，在技术上是一定可以实现的；</li><li>技术突破，研究机构突破技术实现上壁垒，做出来达到预期的Demo；</li><li>工程化，主要解决产品设计，方案优化，功能完备，性能提升，良品率，鲁棒性，可用性提升，大规模复制的技术准备，成本降低等工程问题。</li></ol></li><li>通用无人驾驶在第一，第二阶段还彻底整明白的情况下，由资本驱动直接进入第三阶段.</li></ol><h2 id="agi的理论先行者">AGI的理论先行者</h2><ol type="1"><li>目前强化学习是最被看好的方向。</li><li>强化学习本质上是演化论的思路，跟自然界一样，给定一个reward，让机器放肆的学习探索。</li><li>目前还需要解决的问题是计算资源的问题。</li><li>自然界的演化大部分时间是平稳状态，只有极少数黑天鹅事件决定了演化的方向。</li><li>在计算机中模拟agent的演化过程，和自然界的演化类似，需要忍受长期的无秩序无进展。</li><li>如果全世界的资源往这方面倾斜，可能可以加快黑天鹅事件出现。</li><li>理论突破不是AGI成熟的必要条件，有可能是2者互相促进发展。</li><li>目前收到关注较多的公司--自动标注样本公司scale</li></ol><h2 id="参考">参考</h2><ol type="1"><li>https://www.zhihu.com/question/404870865/answer/1324577689</li><li>https://www.zhihu.com/question/464616760/answer/1940847401</li><li><a href="https://www.sciencedirect.com/science/article/pii/S0004370221000862">reward is enough ,david silver</a></li><li><a href="https://www.notboring.co/p/scale-rational-in-the-fullness-of?token=eyJ1c2VyX2lkIjoxNzY2NjQ2OSwicG9zdF9pZCI6Mzc4NDY2MzEsIl8iOiJrTHFWcCIsImlhdCI6MTYyNDQyNDU4NCwiZXhwIjoxNjI0NDI4MTg0LCJpc3MiOiJwdWItMTAwMjUiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.zWmuXLn35R720iDVtX7yTuTpM4kCMk25457XzZN8_Ks">not boring</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;chiechies-reflection&quot;&gt;chiechie&#39;s reflection&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;理论突破不是技术爆发的必经之路，很多技术都没有理论，比如古代时候的发明，造船，造纸，造火药，爱迪森发明电灯泡，还有现代的量子计算机</summary>
      
    
    
    
    <category term="沉思录" scheme="https://chiechie.github.io/categories/%E6%B2%89%E6%80%9D%E5%BD%95/"/>
    
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="科技史" scheme="https://chiechie.github.io/tags/%E7%A7%91%E6%8A%80%E5%8F%B2/"/>
    
    <category term="人工智障" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E9%9A%9C/"/>
    
  </entry>
  
  <entry>
    <title>关于Scale AI</title>
    <link href="https://chiechie.github.io/2021/06/16/reading_notes/reality/about-scale/"/>
    <id>https://chiechie.github.io/2021/06/16/reading_notes/reality/about-scale/</id>
    <published>2021-06-16T02:39:20.000Z</published>
    <updated>2021-06-28T02:08:34.891Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>看到packy激情满满写了一篇关于Scale AI的公关文，比较好奇这个年轻的小公司有何特别之处，为什么会受到资本的一致认可。</p><p>印象中scale就是一家硅谷的数据标注公司，主要靠外包给第三方国家，赚取中间费用，这种公司有什么竞争力呢？跟大厂比起来？</p></blockquote><h2 id="总结">总结</h2><ol type="1"><li><p>Scale AI创立至今5年，最近一次估值73亿$。它跟stripe有点像，在一个蓬勃发展的行业，找到一个关键但是不起眼的小地方，深耕细作。</p></li><li><p>刚开始成立的时候，Scale AI专注做数据标注，但是他们的野心不限于此，他们想做更好用的数据标注工具，即人机互助的方式，Human-in-the-Loop（HIL）。</p></li><li><p>Scale AI的故事是：随着标记数据越来越多，标注数据的边际成本会降低，因为标记样本越多，标记机器人的性能越好，能hold的事情就越多，需要分配出去的工作就越少。</p><blockquote><p>这里有一个问题，怎么确定，哪些是机器可以搞定的，哪些是机器搞不定的？这个是不是又要多一层人工监督了？</p><p>可以从环境中获取到反馈，也可以人工抽查。</p><p>总的来说，都不是很完善的方案。</p></blockquote></li><li><p>Scale AI还有一个亮点，他的客户群体很分散，从国防部到无人驾驶公司，eg OpenAI, Airbnb and Lyft。这有一个好处就是。AI公司去去留留，竞争之后，留下了最有效的ml应用场景，但是Scale AI始终有机会，因为是做基础设施的。</p></li><li><p>除了标注API，Scale AI还做了一个样本调试的产品--Nucleus，data debugging SaaS product。目的是做全链路基建嘛。 <img src="./img.png" alt="Nucleus" /></p></li><li><p>Scale AI的CEO Alexandr Wang 说的一段话</p><blockquote><p>At Scale, we’re building the foundation to enable organizations to manage the entire AI lifecycle. Whether they have an AI team in-house or need a fully managed models-as-a-service approach, we partner with our customers to build their strategy from the ground up and ensure they have the infrastructure in place to systematically deliver highly-performant models.</p></blockquote></li></ol><p>简单点说，他们的方法是，帮助企业从0到1落地一个AI应用--不管这个企业内部有没有AI团队--企业能够使用这个基建更高效地构建模型. 就是win-win,后生可畏.</p><ol start="10" type="1"><li><p>对于没有AI团队的传统企业，Scale AI定制化合作（跟必示一样），客户例如Brex和Flexport。</p><figure><img src="./img1.png" alt="img.png" /><figcaption aria-hidden="true">img.png</figcaption></figure></li><li><p>这里有一个小故事：Brex doesn’t have an AI team working on the model; they outsource it to Scale. .Brex一开始找的是专门做OCR的大公司，帮他们做发票文本提取，但是效果一般（“they were all mediocre.” ）。后面找到scale，通过深入合作定制化了一个模型，效果100%。后面沉淀出了一个产品document。</p></li><li><p>scale的产品还有蛮多的：地图/文档/图像。。 <img src="img2.png" alt="img.png" /></p></li></ol><blockquote><p>btw, 知乎上有一个相关提问--如何评价Scale AI？大家似乎认识非常有限（只知道它是做数据标注的），还讨论的热火朝天。由此可见的，噪声膨胀的速度远远超过信息增长的速度。</p></blockquote><h2 id="chiechies-reflection">chiechie's reflection</h2><ol type="1"><li><p>packy这篇文章的公司分析框架蛮好的，后面分析科技公司可以套用：</p><ul><li>行业介绍：The State of AI and ML</li><li>公司介绍：Getting to Scale.</li><li>相同模式的成功案例对比：Scaling Like Stripe.</li><li>关于公司的负面观点：The Bear Case for Scale.</li><li>关于公司的正面观点：The Bull Case for Scale.</li><li>前景展望：Scale’s Compounding Vision.</li></ul></li><li><p>AI市场未来还有这么大的成长空间，当前只有8%的公司应用了AI技术,看到这个数字有点吃惊。但是，即便如此，AI从业人员的需求也不用过分乐观估计。</p></li><li><p>AI应用目前还在探索期。Scale AI比较鸡贼，让AI公司在前面探路，让他们相互pk，把有价值可落地的场景摸索清楚，自己在后面提供军火库，妥妥的赢家。</p></li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.notboring.co/p/scale-rational-in-the-fullness-of">not boring</a></li><li><a href="https://zhuanlan.zhihu.com/p/384012257">吴恩达发起新型竞赛范式！模型固定，只调数据？</a></li><li><a href="https://scale.com/blog/series-e">Scale AI’s Series E: Deploying AI Across Every Industry</a></li><li><a href="https://dashboard.scale.com/nucleus/">nucleus</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;看到packy激情满满写了一篇关于Scale AI的公关文，比较好奇这个年轻的小公司有何特别之处，为什么会受到资本的一致认可。&lt;/p&gt;
&lt;p&gt;印象中scale就是一家硅谷的数据标注公司，主要靠外包给第三方国家，赚取中间费用，这种公司有什么竞争力呢？</summary>
      
    
    
    
    <category term="投资" scheme="https://chiechie.github.io/categories/%E6%8A%95%E8%B5%84/"/>
    
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="投资" scheme="https://chiechie.github.io/tags/%E6%8A%95%E8%B5%84/"/>
    
    <category term="行业研究" scheme="https://chiechie.github.io/tags/%E8%A1%8C%E4%B8%9A%E7%A0%94%E7%A9%B6/"/>
    
  </entry>
  
  <entry>
    <title>贝叶斯网络推断</title>
    <link href="https://chiechie.github.io/2021/06/15/data_structure/graph/bayesnetwork/"/>
    <id>https://chiechie.github.io/2021/06/15/data_structure/graph/bayesnetwork/</id>
    <published>2021-06-15T06:28:18.000Z</published>
    <updated>2021-06-28T01:34:19.335Z</updated>
    
    <content type="html"><![CDATA[<p>如何应用贝叶斯网络来做决策？</p><ul><li>首先需要将先验知识表达成一个因果图--贝叶斯网络，（准确来说贝叶斯网络的边不仅仅表达因果关系，他表达所有的信息传播的方向）。</li><li>做推断</li></ul><ol type="1"><li><p>构造贝叶斯网络 <img src="img.png" alt="img.png" /></p></li><li><p>推断</p></li></ol><p>已知P(R,W,S,C）, 求P(r)</p><h3 id="枚举法">枚举法</h3><ol type="1"><li>先推到条件概率分布</li></ol><figure><img src="img_1.png" alt="img_1.png" /><figcaption aria-hidden="true">img_1.png</figcaption></figure><ol start="2" type="1"><li><img src="img_2.png" title="fig:" alt="img_2.png" /></li></ol><h3 id="变量消除法">变量消除法</h3><figure><img src="img_3.png" alt="img_3.png" /><figcaption aria-hidden="true">img_3.png</figcaption></figure><figure><img src="img_4.png" alt="img_4.png" /><figcaption aria-hidden="true">img_4.png</figcaption></figure><p>所有非query变量祖先的变量，都应该被消去，当然不是真的消去啦，是对该消去变量求和，然后变成一个新的因子f。</p><p>依次迭代，直到没有可以消除的变量。</p><figure><img src="img_5.png" alt="img_5.png" /><figcaption aria-hidden="true">img_5.png</figcaption></figure><h3 id="贝叶斯网络中的依赖性">贝叶斯网络中的依赖性</h3><ol type="1"><li>每一个随机变量都是条件独立于他的非后代节点，给定他的父母节点时，</li><li>如下，给定A，B时，C和D是独立的。</li></ol><figure><img src="img_6.png" alt="img_6.png" /><figcaption aria-hidden="true">img_6.png</figcaption></figure><ol start="3" type="1"><li>每个随机变量独立其他任何变量，当给定他的马尔可夫毯（Markov Blanket）<ul><li>父亲，孩子，以及孩子的父母亲（配偶）</li></ul></li></ol><figure><img src="img_7.png" alt="Markov Blanket" /><figcaption aria-hidden="true">Markov Blanket</figcaption></figure><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.youtube.com/watch?v=TuGDMj43ehw">Bayesian Networks-youtuybe</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;如何应用贝叶斯网络来做决策？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先需要将先验知识表达成一个因果图--贝叶斯网络，（准确来说贝叶斯网络的边不仅仅表达因果关系，他表达所有的信息传播的方向）。&lt;/li&gt;
&lt;li&gt;做推断&lt;/li&gt;
&lt;/ul&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;构</summary>
      
    
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="贝叶斯网络" scheme="https://chiechie.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>为什么要工作？</title>
    <link href="https://chiechie.github.io/2021/06/14/meditation/why-do-We-work/"/>
    <id>https://chiechie.github.io/2021/06/14/meditation/why-do-We-work/</id>
    <published>2021-06-14T09:28:02.000Z</published>
    <updated>2021-06-28T00:33:05.522Z</updated>
    
    <content type="html"><![CDATA[<p>类似的问题，</p><ul><li>我们高中为什么要学数理化和文言文？长大之后并没有用上。</li><li>面试造火箭工作拧螺丝。</li></ul><p>工作除了挣钱，还能带来点别的东西，这个东西是什么呢？似乎做完了才知道。</p><p>最近的一份工作，本来是想提升技术，但是事实上，并没有磨练技术的机会，大部分时间是在做产品设计。做产品设计的过程中，越做越困惑，本能地想要找到答案，先在本领域里面寻找，但是大部分所谓的专家，写的文章都是空洞的方法论，言之无物。我不满意，遂去寻找其他领域的文章，比如哲学，社会科学，心理学，经济学。我发现，产品设计上遇到的一些问题，追问到其本质，似乎跟其他领域也想通，原来大家都在研究差不多的问题。</p><p>潜移默化，思考问题的方式发生了改变，从追求触手可及的答案（捷径往往不是正确的道路），到追求更深层次的更本质的问题，当然也更花时间和精力。 从之前迷信权威，到现在delay judgement。</p><p>得知东隅，失之西隅。</p><p>再想一想高中学习的那些东西，可能真不见得有什么实际收益，但是在不可见的维度，可能还是有收获的。比如磨练了我们的意志力，让我们做事情能够吃苦耐劳，或者对性格的其他方面有一些潜在的影响。这个影响显然不是设计高考制度的人想出来的，而是人在做事，在实践的过程中，意外得到的，可能去种地也会起到同样的作用。只有事后，自己才可以总结出来。</p><p>一些联想：观察到事件A和事件B在现实中存在某种若隐若现的关联时，不一定A和B就有直接的因果关系。背后可能存在着某个状态不可见的混杂因子。很多情况下，因为我们没有足够的人生经验，所以做事之前，我们都不知道这个混杂因子是个什么，做完之后才恍然大悟。</p><p>因缘际会，凡事用心投入，大概率会是有好结果的吧，这个结果可能发生在另外一件事情上。</p><p>"做之前想的再多没用，做着做着就知道意义了"。现在似乎有点明白这个意思，人的能力太有限，世界变幻莫测，哪有可能预测到事情的演化方向。直到走完这条路，并且回过头来看这条路，才知道终点是什么，才能总结出这一路的意义是什么。</p><blockquote><p>莫听穿林打叶声，何妨吟啸且徐行。竹杖芒鞋轻胜马，谁怕？ 一蓑烟雨任平生。</p><p>料峭春风吹酒醒，微冷，山头斜照却相迎。回首向来萧瑟处，归去，也无风雨也无晴。</p><p>-- 定风波 苏轼</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;类似的问题，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们高中为什么要学数理化和文言文？长大之后并没有用上。&lt;/li&gt;
&lt;li&gt;面试造火箭工作拧螺丝。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;工作除了挣钱，还能带来点别的东西，这个东西是什么呢？似乎做完了才知道。&lt;/p&gt;
&lt;p&gt;最近的一份工作，本来是</summary>
      
    
    
    
    <category term="沉思录" scheme="https://chiechie.github.io/categories/%E6%B2%89%E6%80%9D%E5%BD%95/"/>
    
    
    <category term="阅读" scheme="https://chiechie.github.io/tags/%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>《社会心理学》读书笔记</title>
    <link href="https://chiechie.github.io/2021/06/13/reading_notes/reality/shehuixinlixue/"/>
    <id>https://chiechie.github.io/2021/06/13/reading_notes/reality/shehuixinlixue/</id>
    <published>2021-06-13T01:24:54.000Z</published>
    <updated>2021-06-28T00:33:05.525Z</updated>
    
    <content type="html"><![CDATA[<h2 id="社会中的自我">1. 社会中的自我</h2><h3 id="焦点效应">焦点效应</h3><ol type="1"><li>人总是高估他们内在状态外露的程度，但是事实上，他人并没有你想象的那样注意你。</li><li>焦点效应（spotlight effect）：把自己看作世界中心，直觉地高估别人对我们的关注程度。几个例子：</li></ol><ul><li>会聚焦在自我与当前社会环境的差异性，会关注差别最大的那个维度。</li><li>自我服务：当关系出现问题时，个体通常会把责任更多推到配偶身上，情况好转时，确认为自己起了更重要的作用。</li><li>自我关注引发的很多行为：我们关注他人的行为和期望，并随之调整自己的行为。</li><li>在不同的关系中，自我也在发生变化。</li></ul><ol start="2" type="1"><li><p>透明度错觉（illusion of transoarency）：我们能敏锐觉察到自己的情绪，很自然地表现出来，并且直觉的认为别人会通过我们的表情觉察到我们的情绪。</p><blockquote><p>其实不是的，1是我们的表现可能模糊不清，2是别人的关注点可能在他自己。</p></blockquote></li><li><p>公众心理疏忽（public mental slips）：如果我们五一冒犯了别人，我们可能懊恼，但是别人经常注意不到，即使注意到也可能很快就会忘记。</p></li><li><p>我们的大多数行为不受意识控制，是自动。显示的自我会制定长期计划，设定目标和进行约束，设想各种可能，将自己和他们相比较，管理自己的reputation和社会关系，但是更多时候可能成为幸福的障碍。</p></li></ol><h3 id="我是谁">我是谁</h3><ol type="1"><li>self-schemas：对自己的认识，比如聪明，自省，勤奋，怀疑，个人主义。</li><li>self-schemas影响我们对社会信息的加工，也影响我们感知，回忆和评价他人/自己。</li><li>我们对跟self-schemas相关的信息会特别关注。</li><li>possible selves：可能的自我，梦想中自我的样子，比如富有，充满激情，自信，丛容，智慧。</li><li>possible selves会激发一种我们渴望的生活愿景，对我们产生巨大的激励作用，或促进我们避免成为自己害怕的样子。</li></ol><h3 id="社会自我">社会自我</h3><ol type="1"><li>基因对人格和自我概念有重要的影响，社会经验也有：扮演的角色，社会同一性，和别人的比较，成功和失败，他人如何评价我们，周围的文化。</li><li>扮演的角色：我们为这个角色说了很多好话，不知不觉，我们会越来越相信这些话，为这些话提供证据。就这样，角色扮演变成了事实。</li><li>社会比较：判断自己是否聪明/智慧？通过社会比较。生活的大部分是围绕比较进行的，因此人们可能会因为别人的失败而暗自高兴。当人嗯攀爬成功的阶梯时，通常会向上看，将自己与做的更好的人比。面对竞争时，常常认为竞争对手本来就有一些优势，以此来保护我们业已动摇的自尊。</li><li>别人的评价：镜像自我--别人对我们的看法，我们把别人作为镜子，我们认为的别人眼中的我，据此来认识自己。换句话说，重要的不是别人实际上如何评价我们，而是我们想象中他们如何评价我们。</li></ol><h3 id="自我与文化">自我与文化</h3><ol type="1"><li>对于部分群体，“个人主义”十分盛行，他们的额经历大部分是这样：青春期与负米分离，各异开始依靠自己，定义独立的自我。即使个体来到一片陌生的土地上，他的特性：有特殊能力，特点，价值和梦想的个体也会保留。当经历过富裕，地位改变，城市化和大众传媒后，个人主义开始迅速发展，</li><li>亚洲文化则更重视集体主义（collectivism）。</li><li>保守派，经济上的个人主义（不要征税）和道德上的集体主义（制定法律来约束不道德）</li><li>自由主义者，经济上的集体主义（支持全民健康保障）和道德上的个人主义（不要用法律来约束我）</li><li>许多文化似乎正在走向个人主义。</li><li>究竟是人们更加关注自我，所以喜欢听关注自我的歌曲，还是反过来？还是存在混杂因子？</li></ol><h3 id="文化与认知">文化与认知</h3><ol type="1"><li>东亚人的思维更具有整体性，从人际关系和环境的角度思考人和物。东方人不重视表达自己的独特性，更重视分享，很少强调个人的选择和自由。</li><li>西方的文化强调个体的力量，个体的价值。</li><li>相互依赖的自我是多个自我的组合，如为人子女的我，职场中的我，作为朋友的我。一个具有相互依赖自我的人会有强烈的归属感，当跟组织分开之后，会丢失掉自我定义。相互依赖的自我存在于社会关系中，社会生活的目标是协调和支持群体。相互依赖的自我聚焦寻求社会支持，比独立自我更深入地融入他人。在相互依赖的文化中，</li><li>自我概念会适应环境，如果一生都与一群人交往，身边人对你的影响很重要；反之，如果每几年换一个环境，身边的人就没有那么重要，而「自我」变成忠实伙伴。“无论你去哪儿，你就是你”。</li></ol><h3 id="自我认识">自我认识</h3><ol type="1"><li>我们对自己行为的解释，在原因有点微妙时候，通常答案都是错误的，我们会忽视重要因素，而夸大一些无关紧要的因素。</li></ol><h2 id="社会关系">社会关系</h2><ol type="1"><li>内疚感：没有帮助别人或者说谎时，会产生内疚感，人会通过在其他方面的行动来弥补这一种感觉。</li><li>经历过极度悲痛的人，会经历一种强烈的自我关注时期。</li><li>悲痛并且自我关注的人，较少意愿去帮助他人；悲痛并且关注别人的人，较多意愿去帮助他人。</li><li>快乐的人更愿意帮助别人。</li><li>帮助行为可以缓解不好的情绪，也可以维持好的情绪。比如给某人指路之后，自我感觉会更好。接着，好的心情又回产生积极的思维，从而指导在其他事情上产生积极的行为。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;社会中的自我&quot;&gt;1. 社会中的自我&lt;/h2&gt;
&lt;h3 id=&quot;焦点效应&quot;&gt;焦点效应&lt;/h3&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;人总是高估他们内在状态外露的程度，但是事实上，他人并没有你想象的那样注意你。&lt;/li&gt;
&lt;li&gt;焦点效应（spotlight effe</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="心理学" scheme="https://chiechie.github.io/tags/%E5%BF%83%E7%90%86%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>《行为经济学》读书笔记</title>
    <link href="https://chiechie.github.io/2021/06/12/reading_notes/economics/xingweijingjixue/"/>
    <id>https://chiechie.github.io/2021/06/12/reading_notes/economics/xingweijingjixue/</id>
    <published>2021-06-12T01:26:37.000Z</published>
    <updated>2021-06-28T00:33:05.523Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第二讲">第二讲</h1><h2 id="第二部分-社会网络研究">第二部分 社会网络研究</h2><h3 id="选择选择什么">选择选择什么？</h3><ol type="1"><li>“群体选择”:群体之间的竞争可能使内部合作的群体最终胜出并淘汰那些内部不合作的群体.群体选择这一主题兼具个体视角和群体视角。</li><li>"利他行为"：体为增加群体的适存度而降低自己的适存度，它的行为是利他行为。适存度，fitness。</li><li>生物学家怎样测度呢？他们用后代与母代之比，来测度适存度。如果一个人的生存策略有利于增加自己的适存度，那么在一名旁观者看来，他的后代的数目必须逐渐超过母代的数目，这就是繁衍，否则就是消亡</li><li>行为模式是可观测的，行为动机是不可观测的。策略是对行为模式的一种描述，所以是可观测的。心理学描述心理事实，包括动机，通常是不可观测的。如生物学家那样，行为经济学试图做的，是从可观测的“显型”策略，推测那些不可观测的“基因型”行为动机。</li><li>什么是传统：：一切经过长期历史的检验有利于生存和繁衍的知识。其中可交流的传统就是常识。传统的大部分不能交流，只能模仿。</li><li>为什么蚂蚁懂得合作没有淘汰人类？蚂蚁行为的驱动力量是族群惯性，但是他没有灵活性。人的行为驱动力量一部分是族群惯性，一部分是灵活性，这样就使得可以保持创新的同时，又能够保持一定的合作秩序。</li><li>在古尔德看来，漫长的地球演化史，首先由一些漫长的稳态构成，其次，这些稳态之间有一些瞬间的黑天鹅事件打破既有的均衡态，然后陷入新的均衡态，再等待新的黑天鹅事件</li><li>人类的出现，就是其中一个黑天鹅事件，它只占演化史的一个瞬间，是大约900万年以内的事情</li><li>古尔德的结论是：历史从来不是决定论的，由许多偶然因素决定历史路径，只在事后才可能知道 自然选择的力量从来不是惟一的演化力量，类似地，为什么最优越的物种只在以往漫长历史的最后一秒之内发生呢？</li><li>在多因多果的网络里，科学家怎样令人信服地指出哪一条因果链条是最重要的呢？理想方法是通过实验，在实验中，我们可以只让一条因果链发生作用，我们控制所有其他因果关系不许它们起作用</li></ol><h3 id="社会网络研究什么">社会网络研究什么？</h3><ol type="1"><li>如何界定一项知识的重要性？用途。手段的质，依赖于目的本身。</li></ol><h3 id="爱因斯坦的自由论">爱因斯坦的自由论</h3><ol type="1"><li>整体论可爱，但不可信，因为它缺少可行的研究方法。个体论可信，却不可爱。</li><li>爱因斯坦:创造是个体的，从来就是个体行为。但是自由，却是整体的. 没有宽容的社会，个人自由也将消失。</li></ol><h3 id="哈耶克的涌现秩序">哈耶克的涌现秩序</h3><ol type="1"><li><p>马克思理论的逻辑矛盾在第一卷里尚未出现，非要在第二卷和第三卷才成为无法挣脱的内在矛盾。</p></li><li><p>马克思主义和哈耶克：哈耶克论证，没有一个微观主体（个体或群体），不论多么聪明，有能力预先知道从大量哪怕是极简单的微观主体的相互作用中涌现出来的宏观秩序是怎样的。这当然意味着社会计划的不可能和理性的狂妄。理性实在很渺小，不可能完成社会主义者赋予它的资源有效配置任务。</p></li><li><p>人类互动问题的复杂性，时间与结构的复制以及涌现，宏观秩序的涌现</p></li><li><p>哈耶克的“涌现秩序"：演化理论，假以时日，从大量的简单局部结构之间的相互作用中必能涌现更复杂的结构。</p><blockquote><p>涌现秩序的思想，可以溯源至柏格森和怀特海。</p></blockquote></li><li><p>哈耶克使用的关键词：简单结构、复制过程、优胜劣汰、适应性。</p></li><li><p>哈耶克的社会演化基本原理：单子复杂交往涌现宏观秩序的不可预见性。</p><ul><li>“单子”，是莱布尼茨的概念，它们如“素数”那样单纯，具有不可再分性。只不过，莱布尼茨假设单子之间没有交往，而哈耶克假设单子之间的交往是事物演化的原因。</li></ul></li><li><p>多主体仿真（multi-agent simuiation）:一种模拟不确定性的环境与社会变迁的程序.哈佛的诺瓦克小组在使用软件仿真时，将每一个agent都设置为具有最简单的行为规则。然后，一个环境中有数千个agent，相互作用之后，宏观秩序涌现出来，这个宏观秩序是不可预期的。最初研究这样的仿真程序的，是2005年与奥曼分享诺贝尔经济学奖的谢林，这一程序称为“谢林程序”。</p></li><li><p>《解释的程度》中，哈耶克的论述十分接近“社会现象是多因多果”这一见解。</p></li><li><p>《复杂现象论》中，哈耶克全面论述了他设想的演化理论的各要素。目前，社会网络的研究方法，是最适合研究哈耶克涌现秩序的实证方法。</p></li><li><p>哈耶克对于统计学的看法：通过消除复杂性来处理大量数据。</p></li></ol><h3 id="多因多果模型">多因多果模型</h3><ol type="1"><li><p>多因多果网络中，那一条因果链条是重要的？以及如何论证出这个结论是对的？前者靠直觉，或者说taste/判断力。后者用控制变量的方法。</p><blockquote><p>社会心理学和行为经济学都会用到控制变量的方法来确定因果关系。</p><p>判断力哪里来？靠日积月累的实践。</p></blockquote></li><li></li></ol><h1 id="第三讲">第三讲</h1><ol type="1"><li>杨格的“策略学习的不可能性定理”：</li></ol><h1 id="参考">参考</h1><ol type="1"><li><a href="https://weread.qq.com/web/reader/b48321a058a8aeb48d182ac">行为经济学讲义-演化论视角</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;第二讲&quot;&gt;第二讲&lt;/h1&gt;
&lt;h2 id=&quot;第二部分-社会网络研究&quot;&gt;第二部分 社会网络研究&lt;/h2&gt;
&lt;h3 id=&quot;选择选择什么&quot;&gt;选择选择什么？&lt;/h3&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;“群体选择”:群体之间的竞争可能使内部合作的群体最终胜出并淘汰那些</summary>
      
    
    
    
    <category term="经济学" scheme="https://chiechie.github.io/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6/"/>
    
    
    <category term="经济学" scheme="https://chiechie.github.io/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6/"/>
    
    <category term="行为经济学" scheme="https://chiechie.github.io/tags/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A6/"/>
    
    <category term="幂律" scheme="https://chiechie.github.io/tags/%E5%B9%82%E5%BE%8B/"/>
    
    <category term="哈耶克" scheme="https://chiechie.github.io/tags/%E5%93%88%E8%80%B6%E5%85%8B/"/>
    
    <category term="群体选择" scheme="https://chiechie.github.io/tags/%E7%BE%A4%E4%BD%93%E9%80%89%E6%8B%A9/"/>
    
  </entry>
  
  <entry>
    <title>关于图数据结构，图模型和图算法</title>
    <link href="https://chiechie.github.io/2021/06/11/meditation/graph-summary/"/>
    <id>https://chiechie.github.io/2021/06/11/meditation/graph-summary/</id>
    <published>2021-06-11T10:42:27.000Z</published>
    <updated>2021-06-26T10:56:35.487Z</updated>
    
    <content type="html"><![CDATA[<ol type="1"><li>图数据是一种数据结构，对于图数据有一些常见的任务，比如单源最短路径，等。</li><li>当图数据的点和边具备一定的含义，如边代表概率，这个时候就是一个概率图模型。通常用于对多个变量之间的因果关系或者相关关系进行建模。</li><li>概率图模型可以细分为有向图和无向图。有向图比如贝叶斯网络，无向图比条件随机场（CRF）。</li><li>有向图又可进一步细分，如果边的方向代表因果关系，就是一个因果图。通常因果图都是需要专家构建的。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;图数据是一种数据结构，对于图数据有一些常见的任务，比如单源最短路径，等。&lt;/li&gt;
&lt;li&gt;当图数据的点和边具备一定的含义，如边代表概率，这个时候就是一个概率图模型。通常用于对多个变量之间的因果关系或者相关关系进行建模。&lt;/li&gt;
&lt;li&gt;概率</summary>
      
    
    
    
    <category term="沉思录" scheme="https://chiechie.github.io/categories/%E6%B2%89%E6%80%9D%E5%BD%95/"/>
    
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="图数据" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>深度学习基础1 数据表示和神经网络基础</title>
    <link href="https://chiechie.github.io/2021/06/10/AI/machine_learning/deeplearning/dl-basic0/"/>
    <id>https://chiechie.github.io/2021/06/10/AI/machine_learning/deeplearning/dl-basic0/</id>
    <published>2021-06-10T08:35:36.000Z</published>
    <updated>2021-06-24T01:38:53.493Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据表示">数据表示</h1><p>在深度学习中如何表示现实中的事物？</p><p>Let’s make data tensors more concrete with a few examples similar to what you’ll encounter later. The data you’ll manipulate will almost always fall into one of the following categories:</p><ul><li>Vector data:2D tensors of shape(samples, features)</li><li>Timeseries data or sequence data:3D tensors of shape (samples, timesteps, features)</li><li>Images:4D tensors of shape(samples,height,width,channels) or (samples,channels, height, width)</li><li>Video:5D tensors of shape (samples, frames, height, width, channels) or (samples, frames, channels, height, width)</li></ul><h2 id="表数据">表数据</h2><ul><li>两个轴：samples axis 和 features axis.</li><li>文本数据, 假设词典长度为2k，每一个doc可以表示为1个2k维的向量，位置的值代表词在文本中出现的次数。</li><li>500个文件可以存储为(500, 20000).</li></ul><h2 id="时间序列数据">时间序列数据</h2><ul><li><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2F_vMGBboznU.png?alt=media&amp;token=73c12f97-acdb-4680-b4eb-79a9a07581f9" /></li></ul><p>时间序列数据一般表示成3-d的张亮，tf中使用3d张量存储，(samples, timestamp, features) 每一个sample可以被编码成一个2d张量， 具体的两个例子</p><ol type="1"><li>股票数据：每年有250个交易日，每个交易日的交易时长有390分钟，每个分钟可以抽取3个重要特征：当前价格，上一分钟最高成交价格，上一分钟最低价格<ul><li>以每一天的交易数据为1个样本，构建的样本的shape为(250,390,3)</li></ul></li><li>TWEET数据：一条twitter长度不超过256，每个位置的字符来自128个assical码中的一个。每一条twitter的shape为（256， 128），1 百万 tweets 的shape为(1000000, 280, 128)</li></ol><h2 id="图像数据">图像数据</h2><p>图像数据一般表示成4维tensor，一个图像数据就是一个3d张量</p><p><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2FD24ghIvE2L.png?alt=media&amp;token=4a68bc5a-7b95-46d2-8418-deed053d4301" /></p><ul><li>tensorflow： (samples, height, width, color_depth)</li><li>theano：(samples, color_depth, height, width).</li><li>keras两者都支持</li></ul><h2 id="视频数据的表示">视频数据的表示</h2><p>视频数据表示成5维张量：(samples, frames, height, width, color_depth).</p><h1 id="模型超参">模型超参</h1><h2 id="结构超参数">结构超参数</h2><p>结构超参数包括层数、层的类别、层的大小等数值。以一个卷积层为例，其中的超参数包括卷积核 (filter) 的大小，卷积核的数量，步长 (stride) 的大小，unit：单元，hidden_layers: 隐藏层，cell：单元 ，dropout_rate丢弃率。这些超参数决定了神经网络的结构。</p><h3 id="layers的基本类型">layers的基本类型</h3><p>keras中layer的基本类型：</p><ul><li>卷积(Conv1D)</li><li>池化(MaxPooling1D/GlobalAveragePooling1D)</li><li>dropout(Dropout)</li><li>线性全连接层(Dense)</li><li>high-level层(LSTM)</li></ul><h3 id="卷积层">卷积层</h3><ol type="1"><li>卷积的维度有1Ｄ，2Ｄ，3D, 区别在于?</li></ol><p>输入数据的shape以及卷积核如何滑动</p><ul><li><img src="https://miro.medium.com/max/1621/1*aBN2Ir7y2E-t2AbekOtEIw.png" title="fig:" alt="I１维卷积和２维卷积的区别" /></li><li>1维卷积（Conv1D）：只有1个维度可以滑动，但是另一维度也是有待估参数的</li><li>2维卷积（Conv2D）：有两个维度可以滑动，</li><li>相同点：从参数视角都是2维的，每一个卷积kernel，参数个数是 height × width +１　（off_ set）</li></ul><ol start="2" type="1"><li>什么情况下，1d比2d好用呢？其中2个维度上，做卷积没有意义(high,close,open,close)</li></ol><h3 id="关于dropout">关于dropout</h3><p>keras中对dropout的处理，因为训练阶段需要dropout ，但是inference阶段不需要dropout，keras中如何设置？</p><p>Keras does this by default. In Keras dropout is disabled in test mode. You can look at the code<a href="https://github.com/keras-team/keras/blob/dc95ceca57cbfada596a10a72f0cb30e1f2ed53b/keras/layers/core.py#L109">here</a> and see that they use the dropped input in training and the actual input while testing.</p><p>As far as I know you have to build your own training function from the layers and specify the training flag to predict with dropout (e.g. its not possible to specify a training flag for the predict functions). This is a problem in case you want to do GANs, which use the intermediate output for training and also train the network as a whole, due to a divergence between generated training images and generated test images.</p><h2 id="算法超参数">算法超参数</h2><p>算法超参数包括学习率 (learning rate),批量大小 (batch size)、epoch数量(迭代周期个数)、正则，损失，激活函数等。由于神经网络的非凸性，用不同的算法超参数会得到不同的解。</p><h3 id="归一化">归一化</h3><p>归一化层，目前主要有这几个方法：</p><ul><li>Batch Normalization（BN， 2015年）</li><li>Layer Normalization（LN， 2016年）</li><li>Instance Normalization（IN， 2017年）</li><li>Group Normalization（GN， 2018年）</li><li>Switchable Normalization（SN， 2018年）；</li></ul><figure><img src="img_1.png" alt="几种归一化方法g" /><figcaption aria-hidden="true">几种归一化方法g</figcaption></figure><h4 id="问题1-transformer-为什么要使用ln而不是-bn">问题1 transformer 为什么要使用LN而不是 BN？</h4><p>在<a href="https://arxiv.org/pdf/2003.07845.pdf">paper: Rethinking Batch Normalization in Transformers</a>中, 作者对比了cv和nlp的BN, 得出的结论是在nlp数据上基于batch的统计信息不稳定性过大(相比cv的数据)，导致bn在nlp上效果差。相比之下layer norm能够带来更稳定的统计信息，有利于模型学习</p><p>Batch Normalization主要的问题是计算归一化统计量时计算的样本数太少，在RNN等动态模型中不能很好的反映全局统计分布信息，而Layer Normalization根据样本的特征数做归一化，是batch size无关的，只取决于隐层节点的数量，较多的隐层节点数量能保证Layer Normalization归一化统计分布信息的代表性。</p><h4 id="问题2.-in直观上怎么理解">问题2. IN直观上怎么理解？</h4><p>在计算机视觉中，IN本质上是一种Style Normalization，它的作用相当于把不同的图片统一成一种风格。另外，既然IN和BN都会统一图片的风格，那么在Generator里加IN或BN应该是不利于生成风格多样的图片的，论文中也进行了展示：</p><p><img src="https://pic2.zhimg.com/v2-235433127838fca762ebd10511de9ca7_b.jpg" /></p><p>图e是在generator中加了BN的结果，图f是在generator中加了IN的结果。果然崩了，IN崩得尤其厉害。</p><h3 id="激活函数">激活函数</h3><ul><li><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2F4_fjPJ90ir.png?alt=media&amp;token=9fb9e321-aed2-4c7b-bb6b-4762b7a38c81" /></li><li><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2FADUH_mebAQ.png?alt=media&amp;token=65efc150-0f7b-42f9-8657-1ca131bfd8b5" /></li><li><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2FMWiLJVveHv.png?alt=media&amp;token=55bc24ce-0531-4702-8d3d-394595bd4d6e" /></li><li><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2FFztLjU8MxY.png?alt=media&amp;token=d7421445-afca-439e-85be-8631db133a41" /></li><li>https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/</li></ul><h3 id="损失函数">损失函数</h3><p>tensorflow中的损失函数:</p><ul><li>sparse_categorical_crossentropy: target是interger list，形状n*1；</li><li>categorical_crossentropy: target 是one-hot vector，target的shape跟模型输出一致，是n*k(类)。<ul><li><span class="math display">\[C E(x)=-\sum\limits_{i=1}^{C} y_{i} \log f_{i}(x)\]</span></li></ul></li><li>binary_crossentropy: target 是interger list。 <span class="math display">\[B C E(x)_{i}=-\left[y_{i} \log f_{i}(x)+\left(1-y_{i}\right) \log \left(1-f_{i}(x)\right)\right]\]</span></li><li>如果输出标签维度为1，只能使用binary_crossentropy，否则程序会报错。不能直接使用categorical_crossentropy 或者sparse_categorical_crossentropy</li><li>如果输出标签维度为K：使用categorical_crossentropy 或者sparse_categorical_crossentropy</li><li>单标签多分类（multi-class）：softmax + CE</li><li>二分类：sigmoid + BCE</li><li>多标签多分类（multi-label）的情况：sigmoid + BCE</li><li>最小化交叉熵损失函数等价于最大化训练数据集所有标签类别的联合预测概率。</li></ul><h4 id="优化算法">优化算法</h4><h1 id="参考资料">参考资料</h1><ol type="1"><li><a href="https://arxiv.org/pdf/1502.03167.pdf">Batch Normalization</a></li><li><a href="https://arxiv.org/pdf/1607.06450v1.pdf">Layer Normalizaiton</a></li><li><a href="https://arxiv.org/pdf/1607.08022.pdf">Instance Normalization</a></li><li><a href="https://github.com/DmitryUlyanov/texture_nets">code</a></li><li><a href="https://arxiv.org/pdf/1803.08494.pdf">Group Normalization</a></li><li><a href="https://arxiv.org/pdf/1806.10779.pdf">Switchable Normalization</a></li><li><a href="https://github.com/switchablenorms/Switchable-Normalization">code</a></li><li><a href="https://blog.csdn.net/liuxiao214/article/details/81037416">有公式推导，写的很棒</a></li><li><a href="https://www.jianshu.com/p/05de1f989790">用书比喻图像很好理解</a></li><li><a href="https://zhuanlan.zhihu.com/p/61248211">Conditional Batch Normalization 详解</a></li><li><a href="https://zhuanlan.zhihu.com/p/57875010">从Style的角度理解Instance Normalization</a></li><li><a href="https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf">在时序数据上应用conv1D</a></li><li>https://zhuanlan.zhihu.com/p/57875010</li><li>https://stackoverflow.com/questions/47787011/how-to-disable-dropout-while-prediction-in-keras</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;数据表示&quot;&gt;数据表示&lt;/h1&gt;
&lt;p&gt;在深度学习中如何表示现实中的事物？&lt;/p&gt;
&lt;p&gt;Let’s make data tensors more concrete with a few examples similar to what you’ll encount</summary>
      
    
    
    
    <category term="AI" scheme="https://chiechie.github.io/categories/AI/"/>
    
    
    <category term="深度学习" scheme="https://chiechie.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="最佳实践" scheme="https://chiechie.github.io/tags/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    
    <category term="low level" scheme="https://chiechie.github.io/tags/low-level/"/>
    
  </entry>
  
  <entry>
    <title>《the book of why》读书笔记-7</title>
    <link href="https://chiechie.github.io/2021/06/10/reading_notes/the-book-of-why/judea-pearl_the-book-of-why7/"/>
    <id>https://chiechie.github.io/2021/06/10/reading_notes/the-book-of-why/judea-pearl_the-book-of-why7/</id>
    <published>2021-06-10T00:33:38.000Z</published>
    <updated>2021-06-24T07:10:06.042Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>the book of why 的第7章 征服干预之峰</p></blockquote><h2 id="前门规则和后门调整">前门规则和后门调整</h2><ol type="1"><li>do条件概率和条件概率的区别是：当有混杂因子存在时，使用条件概率可能得出假的相关性。</li><li>那么除了随机对照试验，还有什么办法能够排除掉混杂因子带来的影响呢？后门调整和前门标准。后门调整即使用便相关系数代替相关系数，前门调整是，在特殊的因果模型的情况下，使用条件概率代替do算子。 <img src="./img.png" alt="img.png" /></li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="http://bayes.cs.ucla.edu/WHY/why-intro.pdf">the book of why-微信读书</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;the book of why 的第7章 征服干预之峰&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;前门规则和后门调整&quot;&gt;前门规则和后门调整&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;do条件概率和条件概率的区别是：当有混杂因子存在时，</summary>
      
    
    
    
    <category term="AI" scheme="https://chiechie.github.io/categories/AI/"/>
    
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="哲学" scheme="https://chiechie.github.io/tags/%E5%93%B2%E5%AD%A6/"/>
    
    <category term="根因分析" scheme="https://chiechie.github.io/tags/%E6%A0%B9%E5%9B%A0%E5%88%86%E6%9E%90/"/>
    
    <category term="因果分析" scheme="https://chiechie.github.io/tags/%E5%9B%A0%E6%9E%9C%E5%88%86%E6%9E%90/"/>
    
    <category term="因果推断" scheme="https://chiechie.github.io/tags/%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD/"/>
    
    <category term="贝叶斯" scheme="https://chiechie.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    
  </entry>
  
  <entry>
    <title>多世界理论</title>
    <link href="https://chiechie.github.io/2021/06/09/reading_notes/phisics/duoshijie/"/>
    <id>https://chiechie.github.io/2021/06/09/reading_notes/phisics/duoshijie/</id>
    <published>2021-06-09T06:26:46.000Z</published>
    <updated>2021-06-28T02:09:13.990Z</updated>
    
    <content type="html"><![CDATA[<h2 id="总结">总结</h2><ol type="1"><li>多世界理论是埃弗里特（Hugh Everett III, 1930 - 1982）在1957年提出的. 这个理论的核心是：量子理论是一个自洽的理论，不需要借助经典概念和任何额外的假设就能描述和解释一切现象，包括我们日常生活感受的经典世界和量子测量。根据这个理论，波包永远也不会塌缩，任何物体无论大小都是量子的，都可以用波函数描述。 整个宇宙的波函数<span class="math inline">\(\Psi\)</span>可以写成很多个分量的叠加 <span class="math display">\[\Psi=\varphi_{1}+\varphi_{2}+\ldots+\varphi_{n}+\ldots\]</span></li><li>其中的每一个分量<span class="math inline">\(\varphi_{n}\)</span>代表一个平行世界，这些平行世界真实存在、平行演化、互不干扰，偶尔发生干涉。 3 对多世界理论持反对意见的人其实无法给出任何令人信服的理由，主要是心理上无法接受其他平行世界的存在。</li><li>埃弗里特一开始就指出了波包塌缩理论的逻辑缺陷：当存在两个或两个以上观察者的时候，观察者们会给出不同的波包塌缩时间。埃弗里特用了一个例子来说明这个逻辑缺陷，他的例子和维格纳朋友佯谬类似。</li></ol><h2 id="薛定谔的猫猫">薛定谔的猫猫</h2><ol type="1"><li>薛定谔猫是一个关于量子测量的思想实验。在薛定谔的最初设想中，被测量的是正在衰变的放射性元素，这里用光子的偏振代替。 <img src="img.png" alt="img.png" /></li><li>每一个光子有两个可能的偏振态，水平偏振和垂直偏振。一般情况下，光子既不是水平偏振也不是垂直偏振，而是处于它们的叠加态。（类似复数）</li><li>现在假设有一个封闭的实验室，里面有一只猫猫，和光子偏振的测量设备。实验开始时，一个光子入射穿方解石，出来后落在检测屏上。如果落在检测评上方，什么也不会发生，猫猫依然是活的，如果落在下方，会触发打开毒气瓶的开关，把猫猫毒死。</li><li>光子落在屏幕上之后，猫猫和光子发生了纠缠。</li><li>现在让我们用量子力学来描述这个实验。实验开始前，实验室的波函数可以写成: <span class="math display">\[\left|\Psi_{0}\right\rangle=(\alpha|H\rangle+\beta|V\rangle) \otimes \mid live cat \rangle\]</span> 这时猫和光子没有任何关联。实验结束后，实验室的波函数变成了: <span class="math display">\[\begin{aligned}\left|\Psi_{1}\right\rangle&gt;=\alpha &amp;|H\rangle \otimes \mid \text { live cat }\rangle+\\ &amp;\beta|V\rangle \otimes \mid \text { dead cat }\rangle \end{aligned}\]</span></li><li>现在的问题是，上面的波函数有两部分：在第一部分里，猫是活的；在第二部分里，猫是死的。那这猫究竟是活的还是死的呢？如果你重复这个实验1000次，每次实验结束后打开实验室查看猫的死活，那么你会发现大约有 1000 |α|2次猫是活的，大约1000 | β |2次猫是死的。你不会看到一只既活又死的猫。</li><li>这个实验的本质是，波函数里明明有两个实验结果，当我们去观察时，却只能看到一个。为什么会这样? <img src="img_1.png" alt="img_1.png" /></li><li>在量子力学的框架下，如何解释这个现象？波包塌缩理论：当我们打开实验室去观察时，波函数发生了塌缩。它有<span class="math inline">\(\alpha^2\)</span>的几率发生如下塌缩： <span class="math display">\[\left|\Psi_{0}\right\rangle=\alpha|H\rangle \otimes \mid live cat \rangle\]</span> <span class="math inline">\(\beta^2\)</span>的几率发生如下塌缩： <span class="math display">\[\left|\Psi_{0}\right\rangle=\beta|V\rangle \otimes \mid dead cat \rangle\]</span> 也就是说，有一部分波函数会神秘的消失。</li><li>虽然波包塌缩理论能解释实验结果，但有很多缺点，比如没有描述塌缩究竟怎样发生的，持续了多长时间</li><li>另外一种理论就是多世界理论，系统的波函数<span class="math inline">\(\Psi\)</span>中两个分量，分别代表两个不同世界：一种世界里面，猫猫是活的，另外一种世界，猫猫是死的。这两种世界一样真实，并行存在。由于量子力学的演化是线性的，这两种世界会独立演化，互不影响。当观测者打开实验室的门，在一种世界里，他会看到一直活着的猫猫，感觉不到死猫，这个时候，似乎波函数发生了公式描述的塌缩。在另外一个世界，他会看到相反的景象，这似乎象征着波函数发生了第二种塌缩。从这个角度看，波包塌缩其实是多世界理论的推论，迄今没有任何实验可以推翻多世界理论。</li><li>当一个世界一分为二时，多世界理论是不是预示着能量不守恒了？并没有，分裂之后，只是几率变化了。分类之后的<span class="math inline">\(\Psi_1\)</span>表示，一个实验室有两种状态，一种状态里光子是水品偏振和猫是活的，另外一种状态里，光子是垂直偏振，猫猫却死了。这时，仍然只有一个光子，和一只猫。测量，让猫猫和光子的状态发生了纠缠，并没有增加数量 11。 量子图灵机非常推崇多世界理论，这个宇宙有无限个世界，跟0到1之间的实数一样多，对于薛定谔猫猫实验，一开始有无限多个世界，他们都完全相同。光子偏振测量结束后，这无穷多个世界分成了两组，分别由<span class="math inline">\(\Psi_1\)</span>中的两个分量描述，两组所占的比重分别为</li><li>多世界理论的核心：整个宇宙都是由微观粒子构成，宏观物体和围观粒子没有本质区别，他们也由波函数描述。一个波函数的不同分量代表不同的世界，每个分量都同样真实的，他们并行存在。相对于其他量子力学的解释，多世界理论不需要在量子力学的基本框架之外的额外假设。</li></ol><h2 id="谁对谁错">谁对谁错?</h2><blockquote><p>以薛定谔猫为例介绍了波包塌缩理论和多世界理论，它们都能解释现有实验结果。而且迄今为止没有人能设计一个实验来区别这两种理论，比如直接观测到另外一个世界或波包塌缩过程。那么究竟哪一个理论是正确的呢？实验是科学理论的试金石，现在这块试金石失效了，我们该如何判断这两种理论的对错？埃弗里特在他长论文的最后一个附录里谈到了物理理论的对错优劣问题，他认为除了寻求实验的验证，我们还应该考查理论的逻辑性、有用性、简单性等。下面我们就从这些方面详细对比波包塌缩理论和多世界理论。</p></blockquote><h3 id="逻辑性">逻辑性</h3><p>埃弗里特指出波包塌缩理论的逻辑缺陷：当存在两个或两个以上观察者的时候，观察者们会给出不同的波包塌缩时间。埃弗里特用了一个例子来说明这个逻辑缺陷，他的例子和维格纳朋友佯谬类似。在图3描述的实验中，我们把猫换成观察者爱丽丝，同时移走毒气瓶。如果光子落在检测屏上方，她就记录“上”；如果光子落在检测屏下方，她就记录“下”。对于爱丽丝来说，波包塌缩在光子和检测屏碰撞的一刻就已经发生了，因为她每次都明确地观察到了光子落在了上方或下方。现在假设实验室外面还有一个观察者鲍勃，在实验完成前，他和实验室没有任何相互作用。对于鲍勃来说，在他打开实验室以前，实验室由如下波函数描述 <span class="math display">\[\left|\Psi_{3}\right\rangle=\alpha|H\rangle \otimes|\mathrm{Up}\rangle+\beta|V\rangle \otimes \mid Down \rangle \]</span> 波包还没塌缩。假设鲍勃在实验结束后一周打开了实验室，这时波包塌缩了。他对爱丽丝的记录没有任何异议，但他坚持说波包塌缩是在他进入实验室的一刻发生的，爱丽丝当然不同意。于是矛盾产生了。这就是波包塌缩理论的逻辑缺陷。文献[10]对这个逻辑问题有更详细的描述。</p><h3 id="简单性">简单性</h3><p>这里指的是概念和理论框架的简单。多世界理论显然在概念上更简单，除了量子力学的基本框架，它不需要任何额外的假设。而波包塌缩是量子力学基本框架之外的一个额外假设。在量子力学里，量子态都是随时间进行连续和幺正的演化；而波包塌缩是不连续和非幺正的。因此，波包塌缩必须是一个独立的假设，不可能从量子力学的基本框架推出来。这个假设非常的不物理：塌缩是怎样的物理过程？经历了多长时间？如何界定外部观察者？这些问题迄今没有令人满意的答案。当我们考虑整个宇宙时，波包塌缩假说显得更是不合理。一方面，宇宙的外部没有观察者，所以整个宇宙的波函数应该连续地随时间幺正演化，不会经历随机的波包塌缩；另一方面，我们人类又时时刻刻在进行类似图3的实验，波包在随机的塌缩。这样宇宙的波函数由于我们的观察不再随时间幺正演化。多世界理论则不会导致这样矛盾的结果。</p><h3 id="刚性">刚性</h3><p>如果一个理论不能随意改动，我们就说这个理论具有刚性。多世界理论在概念上更简单，因为它不需要任何额外的假设。这也使它具有了刚性。量子力学已经被大量实验证实，它的基本理论框架是不能随意改动的。如果你能改动量子力学的基本框架，那你一定在引导一场新的物理革命。与之相反，波包塌缩理论显然是可以随意改动的。比如，我可以假设波包塌缩有一个中间过程：任何波函数都先塌缩为一个等权重量子态然后再塌缩到目标态。根据这个假设，公式(6) 描述的塌缩应该改写为</p><p><span class="math display">\[\left|\Psi_{1}\right\rangle \rightarrow \frac{1}{\sqrt{2}}(|H\rangle \otimes \mid live cat \rangle+|V\rangle \otimes \mid dead cat \left.\rangle\right) \rightarrow|H\rangle \otimes \mid live cat \rangle\]</span></p><p>这个修改后的波包塌缩理论同样能解释图3中的实验结果和其他量子测量结果。更糟糕的是，我们可以对波包塌缩理论做任意类似的改动。所以波包塌缩理论刚性非常差，完全是一团可以被随意揉捏的面。笔者认为任何真理和美都具有类似的刚性。一首动听的乐曲具有刚性：它的每一个音符都不能随意改动；一首美的诗具有刚性：它的每一个字都不能随意改动；一朵漂亮的鲜花具有刚性：花瓣的颜色、形状等都不能随意变动，所以花店老板总是对她店里的鲜花小心呵护。由于篇幅限制，这里不展开讨论了。</p><h3 id="有用性">有用性</h3><p>波包塌缩理论似乎只能用来解释类似图3中的量子测量实验，笔者不清楚它还有什么其他用处。多世界理论则帮助笔者解开了一些长久的困惑。按照进化论，我们人类是由非常初级的化学分子一步一步进化而来。每一步进化都是一个小概率事件，所以最后一步一步进化成具有智慧的人，概率是非常、非常小的。即使整个进化过程的时间很长，依然让人觉得不好接受：这么小概率的事件居然发生了。按照多世界理论，这种进化则是必然的，因为在多世界理论中任何小概率事件都会实现。波函数|Ψ1〉中有两个分量：无论α多小，活猫的世界都存在；无论β多小，死猫的世界都存在。也就是说，宇宙从来都不做选择，它只是按照比重不停地分裂为更多的世界。基于这个认识，让我们再来看生物进化。每一步进化其实都是一个化学反应过程：早期的进化是小分子组合成大分子，后来则是基因突变。而任何化学反应都是一个量子演化过程。按照多世界理论，无论事件发生的概率多小它都会发生。概率小只是说明在众多的世界里只有很少一部分生活着我们这样的智慧生物，绝大多数世界里地球上没有生命或者生命处于极其初始的状态。</p><h2 id="自由意志和多世界">自由意志和多世界</h2><p>按照经典物理，一旦初始条件给定，系统随后的演化就是唯一确定的。形象点说就是你所做的一切都是命中注定的，你的一生在你出生的那个时刻就已经确定了，自由意志只是一种假象。从经典物理理论出发，这个观点真是难以辩驳。后来有了量子力学，理论框架里含有内禀的几率，自由意志似乎不再是假象。但仔细一想，即使有了量子力学，自由意志似乎依然是假象。按照波包塌缩理论，几率只发生在外部观察者进行观察时。整个宇宙并没有外部观察者，宇宙的波函数依然按照量子力学进行确定的演化，所以自由意志依然是假象。但是按照多世界理论，整个宇宙的波函数虽然在确定地演化，但是它却在不停地分裂成不同的世界，观察者究竟感受和经历哪一个特定的世界是随机的，他不确定自己的未来是属于哪一个世界。这样，对于每一个世界来说，人是有自由意志的。于是我们有了一个非常美妙的结论：在一个确定演化的宇宙里存在真正的自由意志。</p><h2 id="世界是量子的">世界是量子的</h2><p>量子力学是一场颠覆性的物理革命，彻底推翻了很多经典的概念。但是非常有意思的是，几乎所有的量子力学的创立者都始终没有彻底摆脱经典物理的枷锁。这个问题的根源是波函数。波函数是抽象的希尔伯特空间中的一个向量，它和我们感知的世界没有直接的联系。为了建立波函数和现实世界的联系，这些伟大的物理学家开始回头在经典物理中寻求答案。爱因斯坦认为波函数根本就不能完整地描述自然，最终的理论一定是一个经典的理论，即所谓的隐变量理论。以玻尔和海森伯为代表的哥本哈根学派虽然认为波函数完整地描述了自然，但波函数和现实世界的联系需要通过经典仪器来完成。但最令人迷惑的事情是，没有一篇文章或一本书清晰明确阐明哥本哈根学派，他们的观点弥散在玻尔和他门徒无穷的文章和讲话里，每次他们似乎在谈论同一个观点，仔细一读似乎又总是有些变化。朗道在他的《量子力学》第一节中写了这样一段话，量子力学在物理理论中占有一个很不平常的地位；它把经典力学作为一种极限情形而包含之，但在它的自身表述中，同时又需要这一极限情形。</p><p>这或许能概括哥本哈根学派关于量子力学和经典力学之间关系的模棱两可的态度吧。哥本哈根学派无论怎么表述他们的观点，有一点很明确，他们没有彻底摆脱经典力学的枷锁。德布罗意试图将波函数解释成一种经典波，发展了导波理论，后来玻姆独立发展这个理论。这个理论认为粒子本质上是经典的。薛定谔似乎是这些量子先贤中唯一一位不走回头路的。他曾经在1952年的一次演讲中批评了当时流行的哥本哈根学派，指出波函数中的每一个分量都可能同时存在[11]。这当然就是多世界理论的本质。但是很遗憾，薛定谔并没有进一步发展这个想法。</p><h2 id="参考">参考</h2><ol type="1"><li><a href="https://weibo.com/ttarticle/p/show?id=2309404646458711212151#_0">埃弗里特和他的多世界理论-吴飙-weibo</a></li><li><a href="https://www.phy.pku.edu.cn/wubiao/dfiles/pw/aifulitehetadeduoshijielilun.pdf">埃弗里特和他的多世界理论-吴飙-paper</a></li><li><a href="https://www.phy.pku.edu.cn/wubiao/pxsj.htm">吴飙-主页</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;多世界理论是埃弗里特（Hugh Everett III, 1930 - 1982）在1957年提出的. 这个理论的核心是：量子理论是一个自洽的理论，不需要借助经典概念和任何额外的假设就能描述和解释一切现象</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="物理" scheme="https://chiechie.github.io/tags/%E7%89%A9%E7%90%86/"/>
    
    <category term="平行世界" scheme="https://chiechie.github.io/tags/%E5%B9%B3%E8%A1%8C%E4%B8%96%E7%95%8C/"/>
    
    <category term="自由意志" scheme="https://chiechie.github.io/tags/%E8%87%AA%E7%94%B1%E6%84%8F%E5%BF%97/"/>
    
    <category term="薛定谔的猫猫" scheme="https://chiechie.github.io/tags/%E8%96%9B%E5%AE%9A%E8%B0%94%E7%9A%84%E7%8C%AB%E7%8C%AB/"/>
    
  </entry>
  
  <entry>
    <title>《编程:隐匿在计算机硬件背后的语言 》的读书笔记</title>
    <link href="https://chiechie.github.io/2021/06/08/reading_notes/computer/coding/"/>
    <id>https://chiechie.github.io/2021/06/08/reading_notes/computer/coding/</id>
    <published>2021-06-08T01:09:12.000Z</published>
    <updated>2021-06-11T02:39:26.044Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二进制加法器">12 二进制加法器</h2><ol type="1"><li>电路中的逻辑门能实现二进制加法。</li></ol><blockquote><p>逻辑门是认为设计的一种电路走线，为了映射到逻辑上的加法运算。</p><p>逻辑门是链接物理世界和信息世界的桥梁，信息世界以逻辑求和为根基，开始构建信息世界的高楼大厦。</p></blockquote><h2 id="存储器组织">16 存储器组织</h2><ol type="1"><li><p>我们习惯于将可能用到的事物先存起来，在需要时将它们取出。从技术角度来讲，这个过程称为先存储后访问。存储器的职责和作用就在于此，它负责保障这两个过程之间信息完好无损。</p></li><li><p>存储信息都要利用不同种类的存储器。比如，保存文本信息的不二之选就是纸张，而磁带则更适于存储音乐和电影。</p></li><li><p>电报继电器（Telegraph Relays）——以一定形式组织起来构成逻辑门，然后再形成触发器——同样具备保存信息的能力</p></li><li><p>随机访问存储器（RAM）一断电，数据就消失了。因此随机访问存储器也叫易失性（volatile）存储器。</p><blockquote><p>一个辛辛苦苦装满65,536字节珍贵数据的64 K×8 RAM阵列，如果断掉电源，首先所有的电磁铁都将因为没有电流而失去磁性，随着“梆”的一声，金属片将弹回原位，所有继电器将还原到未触发状态。RAM中存储的数据呢？它们将如风中残烛般消失在黑暗中</p></blockquote></li></ol><h2 id="从算盘到芯片">18 从算盘到芯片</h2><h2 id="两种微处理器">19 两种微处理器</h2><ol type="1"><li><p>微处理器将中央处理器的所有组建整合到一个硅芯片上。</p></li><li><p>第一个微处理器，intel 4004，包含了2300个晶体管</p></li><li><p>三十年过去了，一个微处理器中的晶体管数量逼近1000w个。</p></li><li><p>摩托罗拉公司，从20实际50年代生产半导体和晶体管，在1974年8月推出了6800处理器。</p></li><li><p>得克萨斯仪器在1974年，推处4位的处理器TMS1000，</p></li><li><p>英特尔为8080最初定的价格为360美元，8080是一个8位的微处理器，它包括6000个晶体管，运行的时钟频率为2 MHz，寻址空间为64 KB。</p></li><li><p>这些芯片被称为“单芯片微处理器”（single-chip microprocessors</p></li><li><p>除了处理器之外，计算机还需要其他一些设备，至少要包括存储器（RAM），输入设备（键盘），输出设备（显示屏），以及其他一些能把所有构件连接在一块的芯片（主板，机箱）。</p></li><li><p>通过观测芯片的输入、输出信号，特别是芯片的指令集来理解微处理器的工作原理。</p></li><li><p>微处理器通过管脚提供了处理器的输入和输出访问接入点 <img src="img.png" alt="img.png" /></p></li><li><p>所有电气或电子设备都需要某种电源来供电</p></li><li><p>8080的一个特殊的地方就是它需要三种电源电压：管脚20必须接到5V的电压；管脚11需要接到-5V的电压；管脚28需接12V的电压；管脚2接地。（英特尔在1976年发布了8085芯片，目的就是简化对这些电源的要求）.</p><ul><li>从芯片引出的箭头表明这是一个输出（output）信号，这种信号由微处理器控制，计算机的其他芯片对该信号响应。</li><li>指向芯片的箭头表明该信号是一个输入（input）信号，该信号由其他芯片发出，并由8080芯片对其响应。还一些管脚既是输入又是输出。</li></ul></li><li><p>8080有16个用于寻址的输出信号，标记为A0～A15，因此它的可寻址空间大小为<span class="math inline">\(2^16\)</span></p></li><li><p>在计算机中，所有的指令都是3个字节长（1个字节=8个bit），包括1字节的操作码和2字节的地址，指令长什么样？：</p><ul><li>有些指令使8080从存储器的一个特定地址读取字节到微处理器，</li><li>有些指令使8080将一个字节从微处理器写入存储器的特定地址；</li><li>还有些指令使8080在其内部执行而不需要访问RAM</li></ul><p>8080执行完第一条指令后，接着从「存储器」读取第二条指令，并依此类推。这些指令组合在一起构成了计算机程序</p></li><li><p>计算机的指令集包括两条非常重要的指令，我们称之为加载（Load）和保存（Store），每条指令占3个字节</p><ul><li>在Load指令中，第一个字节是操作码，其后的两个字节是要加载的操作数的16位地址。当处理器执行加载指令时，会把该指定地址中的字节加载到累加器。</li><li>当Store指令被执行时，累加器中的内容被保存到该指令指定的地址中。</li></ul></li><li><p>8080芯片的微处理器的内部除累加器外还设置了6个寄存器（register），每个寄存器可以存放一个8位的数。这些寄存器和累加器非常相似，事实上累加器被视为一种特殊的寄存器。</p></li><li><p>寄存器是计算机必不可少的部件吗？理论上不是。很多计算机程序都同时用到多个数据，将这些数据存放在寄存器比存放在存储器更便于访问，因为程序访问内存的次数越少其执行速度就越快。</p></li><li><p>利用指令，可以方便地把一个寄存器存放的数据转移到另一个寄存器</p></li><li><p>有一种存储器叫堆栈：以从底部到顶部的顺序把数据存入存储器，并以相反的顺序把数据从堆栈中取出，因此该技术也称作后进先出存储器（last-in-first-out，LIFO）。在计算机中使用堆栈技术是十分方便的。通常把将数据存入堆栈的过程称作压入（push），把从堆栈取出数据的过程称作弹出（pop）。</p></li><li><p>堆栈的功能是怎样实现的呢？首先，堆栈其实就是一段普通的RAM存储空间，只是这段空间相对独立不另作他用。8080微处理器设置了一个专门的16位寄存器对这段存储空间寻址，这个特殊的寄存器称为堆栈指针（SP，Stack Pointer）。</p></li><li><p>在8080中，执行PUSH指令实际上是把16位的数据保存到堆栈，执行POP指令是把这些数据从堆栈中取回至寄存器。</p></li><li><p>每执行一条PUSH指令，堆栈都会增加两个字节，这可能会导致程序出现一些小错误——堆栈可能会不断增大，最终覆盖掉存储器中保存的程序所必需的代码或数据。这种错误被称作堆栈上溢（stackoverflow）。类似的，如果在程序中过多地使用了POP指令，则会过早地取完堆栈中的数据从而导致类似的错误，这种情况称为堆栈下溢（stack underflow）。</p></li><li><p>根据摩尔定律（Moore’s Law），微处理器中的晶体管数量每18个月翻一倍，增加的这些大量的晶体管用来做什么呢？</p><ul><li>一些晶体管用来适应处理器不断增加的数据宽度——从4位、8位、16位到32位；</li><li>另一些新增的晶体管用来应对新的指令。</li></ul></li><li><p>现代处理器主要使用2种策略来提高运行速度:</p><ul><li>一种就是流水线技术（pipelining），即处理器在执行一条指令的同时读取下一条指令，</li><li>还有一种是Cache（高速缓冲存储器），它是一个设置在处理器内部，访问速度非常快的RAM阵列，用来存放处理器最近要执行的指令</li></ul><p>这两种策略都需要在处理器内部增加更多的逻辑组件和晶体管。</p></li></ol><h2 id="ascii码和字符转换">20　ASCII码和字符转换</h2><ol type="1"><li>存储器中唯一可以存储的东西是bit</li><li>如果我们想把一段文本存下来该怎么办呢？将文本表示成数字。</li><li>可以为每一个字母赋予一个唯一的编码，具有这种功能的系统叫 字符编码集（Coded CharacterSet），系统内的每个独立编码称为字符编码（Character Codes）</li><li>莫尔斯码: 常用字符的编码较短，而不常用字符的编码较长。这样的编码非常适合电报系统，但并不适用于计算机.</li><li>对一个句子进行编码后得到的连续字符通常被称为文本字符串（string）</li><li>电传打字机键盘上的每一个键实质上都起到了转换器的作用，它负责产生二进制编码并且通过输出电缆逐位传输出去</li><li>尽管ASCII码是计算机领域最重要的标准,但是它是太美国化了，在其他国家ASCII码并不适用。</li><li>近几十年来出现了许多不同版本的扩展的ASCII码，多个不同的版本严重影响了编码的一致性，导致了混淆和不兼容。ASCII码被扩展到极致，有的甚至可以对中文、日文和韩文进行编码</li><li>从1988年开始，几大著名计算机公司合作研究出一种用来替代ASCII码的编码系统，取名为Unicode（统一化字符编码标准）。相对于ASCII的7位编码，Unicode采用了16位编码，每一个字符需要2个字节。</li><li>Unicode编码不是从零开始设计的，前128个字符编码——即0000h～007Fh——与ASCII码是一致的</li><li>对于Unicode来讲，它唯一的问题，就是它改变了字符与存储空间之间“单字符，单字节”的等价对应关系。采用ASCII编码方式存储的著作《怒火之花》，其所占据的存储空间约为1 MB。而如果采用Unicode编码，约占2 MB。为了使编码系统兼容，Unicode在存储空间上付出了相应的代价。</li></ol><blockquote><p>UTF-8是unicode的升级版，减少存储空间。</p></blockquote><p>你看到的unicode字符集是这样的编码表： <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">I 0049</span><br><span class="line">t 0074</span><br><span class="line">&#x27; 0027</span><br><span class="line">s 0073</span><br><span class="line">  0020</span><br><span class="line">知 77e5</span><br><span class="line">乎 4e4e</span><br><span class="line">日 65e5</span><br><span class="line">报 62a5</span><br></pre></td></tr></table></figure></p><p>每一个字符对应一个十六进制数字。计算机只懂二进制，因此，严格按照unicode的方式(UCS-2)，应该这样存储： <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">I 00000000 01001001</span><br><span class="line">t 00000000 01110100</span><br><span class="line">&#x27; 00000000 00100111</span><br><span class="line">s 00000000 01110011</span><br><span class="line">  00000000 00100000</span><br><span class="line">知 01110111 11100101</span><br><span class="line">乎 01001110 01001110</span><br><span class="line">日 01100101 11100101</span><br><span class="line">报 01100010 10100101</span><br></pre></td></tr></table></figure></p><p>这个字符串总共占用了18个字节，但是对比中英文的二进制码，可以发现，英文前9位都是0！浪费啊，浪费硬盘，浪费流量。怎么办？UTF。</p><p>于是，”It's 知乎日报“就变成了： <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">I 01001001</span><br><span class="line">t 01110100</span><br><span class="line">&#x27; 00100111</span><br><span class="line">s 01110011</span><br><span class="line">  00100000</span><br><span class="line">知 11100111 10011111 10100101</span><br><span class="line">乎 11100100 10111001 10001110</span><br><span class="line">日 11100110 10010111 10100101</span><br><span class="line">报 11100110 10001010 10100101</span><br></pre></td></tr></table></figure> 和上边的方案对比一下，英文短了，每个中文字符却多用了一个字节。但是整个字符串只用了17个字节，比上边的18个短了一点点。</p><p><img src="img_1.png" alt="img_1.png" /> ## 参考</p><ol type="1"><li><a href="https://weread.qq.com/web/reader/64e32bf071fd5a9164ece6b">编程：隐匿在计算机硬件背后的语言</a></li><li>https://www.zhihu.com/question/23374078/answer/65352538</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二进制加法器&quot;&gt;12 二进制加法器&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;电路中的逻辑门能实现二进制加法。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;逻辑门是认为设计的一种电路走线，为了映射到逻辑上的加法运算。&lt;/p&gt;
&lt;p&gt;逻辑门是链接物理世</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="编程" scheme="https://chiechie.github.io/tags/%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>《the book of why》读书笔记-6</title>
    <link href="https://chiechie.github.io/2021/06/07/reading_notes/the-book-of-why/judea-pearl_the-book-of-why6/"/>
    <id>https://chiechie.github.io/2021/06/07/reading_notes/the-book-of-why/judea-pearl_the-book-of-why6/</id>
    <published>2021-06-07T00:33:38.000Z</published>
    <updated>2021-06-28T02:13:03.752Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>the book of why 的第6章-一些悖论</p></blockquote><h2 id="悖论1-蒙提-霍尔">悖论1-蒙提 霍尔</h2><h3 id="背景">背景</h3><p>一个竞猜游戏中，有三个用幕布遮住的们，其中有2个门后面是山羊，1个是汽车。有两种游戏规则，分别是：</p><ol type="1"><li>观众先选择三个门中的一个，然后主持人从另外两个门中选择一个没有汽车的们打开，然后这个观众可以选择要不要换门？</li><li>观众先选择三个门中的一个，然后主持人从另外两个门中随便选一个打开，然后这个观众可以选择要不要换门？</li></ol><p>第一种强况下，选择换门的话，赢到车车的概率是2/3， 第二种情况下，选择换门的话，赢到的车车的概率是1/2</p><figure><img src="./img789.png" alt="img.png" /><figcaption aria-hidden="true">img.png</figcaption></figure><h3 id="悖论的原因">悖论的原因</h3><ol type="1"><li><p>贝叶斯公式可以解释信息在非因果关系上的流动，也就是规则1，主持人选择了没有汽车的之后，第三个门的不确定性降低了（沿着门后有车的概率变大的方向），而整个空间的概率之和为1，所以第一个门有车的概率变小了。</p><blockquote><p>主持人的这个决策带来了系统的熵减，系统坍塌到2号门某个确定状态的子空间去了。</p></blockquote></li><li><p>为什么直觉上很难接受规则1的结论，反而会认为比赛的机制不公平？这个跟人类大脑结构有关系：</p><ul><li>大脑不擅长处理概率问题，</li><li>大脑自发抵制非因果关系的信息传递，这个是贝叶斯式变量控制的产物。</li><li>习惯将相关性等同于因果性</li><li>大脑天生难以接受</li></ul></li></ol><h2 id="悖论2-伯克森悖论">悖论2-伯克森悖论</h2><ol type="1"><li>生物统计学家约瑟夫.伯克森在医院做实验时，观察到了一个现象：两种疾病本来在一般人群中毫无关联，但是在住院人群中却会观察到似是而非的相关性。</li><li>医院样本实际上是一个冲撞模型，即，当一个人同时患了两种疾病时，一定会住院。</li><li>所以，「医院样本」就好像一个经过精心挑选过的样本，体现出来的相关关系是控制了「住院」变量之后，疾病1和疾病2的伪相关性。 <img src="img7890.png" alt="img.png" /></li><li>1956年，哲学家赖欣巴提出了一个猜想「共因原则」（common cause principle），他认为没有不含因果关系的相关关系，即，X和Y的相关不是偶然发生的，要么是一个变量导致另一个变量，要么是第三个变量，比如说出现在两个变量之前的Z变量，导致两者发生。</li><li>设计一个抛硬币的实验就可以推翻「共因原则」：假设同时抛两枚硬币，抛100次，只记录其中至少又一枚硬币为正面的结果，实验结束，发现记录的75条记录中，发现只要硬币1反面，硬币2就是正面，是因为两个硬币互通消息了吗？不是的，是因为人为记录改变了测度空间。</li><li>还有一个社会现象就是，在一些调查中发现，跟你约会的人中，哪些又魅力的人往往是混蛋。这个也是因为测度空间被你亲手改变了，因为长得丑的渣男最开始就被你过滤了。过滤之前，有魅力的渣男的概率是1/4，过滤之后有魅力的渣男概率是1/3。所以感觉这个比例增加了。</li></ol><h2 id="悖论3-辛普森悖论">悖论3-辛普森悖论</h2><ol type="1"><li>辛普森逆转：一个叫辛普森的医生，在文献上发现了一种新药D，可以治疗心脏病。论文的实验数据显示，女性患者服用药物之后，心脏病发作比例升高；男性患者服用药物之后，心脏病发作比例也升高。但是，在整体人群上，心脏病发作比例却降低了，因此该药物也被归为BBG（BAD/BAD/GOOD）型药物。然而，实际上这种药物不存在，虽然说在数学上没有什么问题。 <img src="judea-pearl_the-book-of-why7/img.png" alt="辛普森" /></li><li>对整体人群来说，正确的结论应该是什么呢？可以这么操作，先控制性别：<ul><li>do（性别）=女性，计算女性服药之后心脏病发作比例的变化 r1。</li><li>do（性别）=男性，计算男性服药之后心脏病发作比例的变化 r2。</li><li>假设整体人群中，男女比例为1：1，那么可以推断出整体人群，服药之后，心脏比发作比例的变化为（r1+r2）/2</li></ul></li><li>辛普森悖论是因为混杂因子的存在。</li><li>当我们考察两个变量的因果效应时：<ul><li>如果存在混在因子，只能用分层数据计算因果效应，采用控制混杂因子的方式，case by case，计算每个混在因子取值的情况下，两个变量的因果关系，然后按照混杂因子每个取值的概率汇总，得到整体上，两个变量之间的因果关系。 <img src="./img_2.png" alt="img_2.png" /></li><li>如果不存在混杂因子（有可能存在中介物），可以用聚合数据计算因果效应 <img src="./img_1.png" alt="中介物" /></li></ul></li><li>混杂因子存在的警告：根据聚合数据估计出来的因果效应大于，根据分层数据估计出来的因果效应。</li></ol><h2 id="关于悖论">关于悖论</h2><ol type="1"><li><p>什么是悖论？绝大部分人深信不疑的两个信念之间的冲突。</p><blockquote><p>辛普森逆转并不算悖论，只是纠正了不懂数学的人，对"平均表现"的错误认识。</p></blockquote></li><li><p>如何解决悖论？</p><ol type="1"><li>理解为什么大多数人会把它看成一个悖论？or大家对世界的直观看法到底在哪里存在重大缺陷？eg生理结构原因：大部分人不擅长处理概率问题；「过分擅长」处理因果问题</li><li>如何纠正：刻意训练，完成大脑重塑。</li></ol></li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="http://bayes.cs.ucla.edu/WHY/why-intro.pdf">the book of why-微信读书</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;the book of why 的第6章-一些悖论&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;悖论1-蒙提-霍尔&quot;&gt;悖论1-蒙提 霍尔&lt;/h2&gt;
&lt;h3 id=&quot;背景&quot;&gt;背景&lt;/h3&gt;
&lt;p&gt;一个竞猜游戏中，有三个用幕布遮住的们，其中有2</summary>
      
    
    
    
    <category term="AI" scheme="https://chiechie.github.io/categories/AI/"/>
    
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="哲学" scheme="https://chiechie.github.io/tags/%E5%93%B2%E5%AD%A6/"/>
    
    <category term="根因分析" scheme="https://chiechie.github.io/tags/%E6%A0%B9%E5%9B%A0%E5%88%86%E6%9E%90/"/>
    
    <category term="因果分析" scheme="https://chiechie.github.io/tags/%E5%9B%A0%E6%9E%9C%E5%88%86%E6%9E%90/"/>
    
    <category term="因果推断" scheme="https://chiechie.github.io/tags/%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD/"/>
    
    <category term="贝叶斯" scheme="https://chiechie.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    
  </entry>
  
  <entry>
    <title>《财务讲义》读书笔记</title>
    <link href="https://chiechie.github.io/2021/06/06/reading_notes/reality/caiwujiangyi/"/>
    <id>https://chiechie.github.io/2021/06/06/reading_notes/reality/caiwujiangyi/</id>
    <published>2021-06-06T08:25:08.000Z</published>
    <updated>2021-06-28T02:13:25.889Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>思考几个问题，选股的分析框架？看市盈率，看行业龙头股的baseline，跨版本的股票，看业务构成，找相应板块</p></blockquote><h2 id="第3章-花钱-投资与分配">第3章 花钱-投资与分配</h2><h3 id="chapter-21-固定资产">chapter 21 固定资产</h3><ul><li>固定资产：企业的大件资产，比如厂房，生产设备。不仅花费大，而且是企业准备长期 持有的资产。</li><li>与固定资产相对的 是流动资产，如 库存 ，短期投资 等</li><li>企业最大的开销是固定资产投资（类似搞基建，互联网公司可以弱化，但是实业公司不能弱化）</li><li>租赁的本质是债务融资（跟房贷一样）</li><li>财务决策中，在 同风险等级 的 投资决策 之间进行比较是一个重要原则。</li><li>投资的机会成本 是为了一个项目A 所放弃的 其他项目B 的收益，其他项目B的风险等级必须要和A一样。</li><li>所以，不应该考虑买还是租，而是考虑 租还是 借（钱）。也就是说 把 租赁这种 债务融资方式 和 借 这种债务融资方式 比较</li><li>如何降低租赁对负债率的影响<ul><li>在2018年 会计准则修改之前，将融资行负债 修改为 经营性负债</li><li>在2018年 会计准则修改之后，就没法专空子了。</li></ul></li><li>如何盘活租来的固定资产</li><li>融资性 售后回租：将固定资产 卖给 融资租赁公司，然后签订租赁合同，合同期满就可以买回来。</li></ul><h3 id="chapter-22-价值投资-用别人的错误赚钱">chapter 22 价值投资-用别人的错误赚钱</h3><h3 id="chapter-23-资本预算-项目之间是如何pk的">chapter 23 资本预算-项目之间是如何PK的</h3><ul><li>投资收益比较</li><li>（往上一层）投资的溢出效应：值新项目对企业其他项目 或者 外部事物的影响<ul><li>负向</li><li>正向-协同效应</li></ul></li><li>投资回收期平衡</li></ul><h3 id="chapter-24-风险量化">chapter 24 风险量化</h3><ul><li>点分析：项目的保本点是多少<ul><li>对美国上市公司的盈余公告进行研究：发现每一美元造成的股价下跌，几乎是每一美元盈利带来的股价上涨幅度的两倍</li><li>企业的盈利目标又三个层析：1. 保证不亏损 2 超过前一年同期的盈利 3 超过证券分析师的预期</li><li>局限：<ul><li>有的项目处于战略需要一定要投资，即时财务不赚钱</li><li>正向偏离也是一种风险</li></ul></li></ul></li><li>线分析：跟往年比是多少</li><li>面分析：分析师的预期是多少</li></ul><h3 id="chapter-25-实物期权-应对投资的不确定性">chapter 25 实物期权-应对投资的不确定性</h3><ul><li>案例：爱尔眼科怎样降低并购小诊所的风险？<ul><li>【道】增加投资的灵活性</li><li>【法】采用延迟期权，扩张期权，放弃期权策略</li><li>【术】联合PE成立 并购基金，联合孵化小型创业公司</li><li>https://www.pedata.cn/jsp/research.html</li></ul></li><li>互联网项目 的投资 适合实物期权投资 策略。</li></ul><h3 id="chapter-26-风险转移-保险和责任共担">chapter 26 风险转移-保险和责任共担</h3><ul><li>常见的企业风险转移方法：<ul><li>签订长期合同；利用金融工具；购买保险。</li></ul></li></ul><h3 id="chapter-27-并购策略-以小博大的智慧">chapter 27 并购策略-以小博大的智慧</h3><ul><li>基本概念：<ul><li>私有化：将一家上市公司从公众公司重新 变回 私人公司。</li><li>MBO： 管理层收购，manegement buy-out，指管理层要把公司其流通在市场上的股份全部回购。</li><li>LBO：杠杆收购，lenerage buy-out，企业用很少的自由资金，买下一家体谅比自己大很多的企业</li></ul></li><li>判断一家企业的复制扩张战略是否成功看两个指标：收入集中度，利润集中度</li><li>如何看待企业的并购活动？<ul><li>是企业实现规模和也业务扩张常用的一种方式</li><li>并购的效果与起亚的管理能力有关</li><li>杠杆收购的本质是利用财务杠杆以小博大，是一种高风险的资本运作方式</li></ul></li></ul><h3 id="chapter-28-并购隐患-商誉这只灰犀牛">chapter 28 并购隐患-商誉这只灰犀牛</h3><h3 id="chapter-29-减值时机">chapter 29 减值时机</h3><h3 id="chapter-30-分红政策-分红多就是好公司吗">chapter 30 分红政策-分红多就是好公司吗</h3><h2 id="第4章-精进-快速把脉一家上市公司">第4章 精进-快速把脉一家上市公司</h2><ul><li>我觉得这一章是 对所有 公司的 财务状况的 诊断，其中上市公司只是一个特例，并且上市公司暴露了更多的财务数据，也有公众对其未来盈利能力的估值（股价）</li></ul><h3 id="chapter-31-财务诊断-分析框架">chapter 31 财务诊断-分析框架</h3><ul><li>哈佛分析框架包括战略分析，会计分析，财务分析和前景分析。战略分析 和 会计分析都是比较 主观的分析，财务分析 和 前景分析是可以用量化的指标 分析出来的</li><li>战略分析：<ul><li>先看外部环境-“经营环境分析”<ul><li>宏观环境<ul><li>政治，经济，法律，社会文化</li></ul></li><li>行业环境<ul><li>行业规模，增长前景，利润空间，变革速度</li><li>增长前景，按照行业跟经济周期的关系可以将行业分类：<ul><li>增长型行业：如高科技行业</li><li>防御性行业：</li><li>周期性行业：如大宗原材料行业，房地产行业</li></ul></li><li>利润空间<ul><li>行业利润率估值方法-波特五力模型：<ul><li>行业内竞争的激烈程度</li><li>行业进入 壁垒的高低</li><li>供应商谈判能力的强弱</li><li>购买方谈判能力的强弱</li><li>替代产品威胁的大小</li></ul></li></ul></li><li>行业变革速度：哪些是核心驱动因素，以及核心因素的变化速度<ul><li>一个是客户群体以及消费偏好的变化：例如消费行业</li><li>一个是技术革新的速度：如新能源技术在汽车的应用</li></ul></li></ul></li></ul></li><li>再看自己-“企业自身战略”<ul><li>战略：差异化战略（星巴克），成本领先战略（沃尔玛）</li><li>前者毛利率是后者两倍</li></ul></li></ul></li><li>会计分析：检验财务指标的真实性，是否真实的反应了公司的运营状况，重点关注以下3个维度<ul><li>1， 对企业影响最大的<strong>会计政策</strong>是什么？<ul><li>高科技企业利润要重点关注对研发支出的处理</li><li>重资产企业利润要重点关注固定资产折旧的处理</li></ul></li><li>2 哪些会计政策发生了变化？<ul><li>比如某一年度钢铁公司<strong>突然</strong>调节了固定资产折旧政策--延长折旧时间，来降低档期折旧费用。那么就需要进一步了解是否“操纵利润”的嫌疑。（真实情况是，这个是为了避免退市的垂死挣扎）</li></ul></li><li>3，对标企业（同行，用一行业的其他公司）的会计政策有哪些不一样？<ul><li>如果发现一家高科技企业的研发支出资本化比例 明显超过同行，就要进一步分析背后的原因。</li></ul></li></ul></li><li>财务分析：从4个维度 用具体的数值 评价公司现在做的怎么样</li><li>前景分析：预测业绩的可持续性，以及未来的价值</li></ul><h3 id="chapter-32-财务分析-4个维度诊断公司健康">chapter 32 财务分析-4个维度诊断公司健康</h3><ul><li><p>我同可以通过建立一些核心的财务指标考察企业在偿债能力，营运能力，盈利能力，价值创造这4个维度的表现，这个分析方法被称为“比率分析”方法。偿债能力: 关注的是企业家必须守住的底线，其他三个指标考虑的是企业的发展问题。企业发展 要靠“开源节流”，也就是，一方面提升盈利，一方面提升管理效率（营运能力）。</p></li><li><p>偿债能力: 关注的是企业家必须守住的底线</p><ul><li>流动比率 = 流动资产 / 流动负债， 小于1说明有重大问题，a股平均值1.22</li><li>速动比率= （流动资产 - 存货） /流动负债，a股平均值0.5<ul><li>速冻比率 相对流动比率，剔除了资产中 变现能力 最差的 存货</li></ul></li><li>现金比率 = 货币资金 / 流动负债，a股平均值0.31<ul><li>现金比率相对速动比率剔除 了 应收帐款</li><li>这个比率不能过高，过高了虽然风险预防能力是具备了，但是也说明资金使用效率低了。</li></ul></li></ul></li><li><p>营运能力</p><ul><li>周转率：<ul><li>主要反应管理效率，</li></ul></li></ul></li><li><p>盈利能力</p></li><li><p>价值创造能力：市盈率 和 市净率 - ### chapter 33 财报工具-竖着比和横着比</p></li><li><p>竖着比就是跟自己往年业绩比</p></li><li><p>横着比就是跟同行业的竞争公司比</p></li></ul><h3 id="chapter-34-财务实战-哈佛分析框架的应用">chapter 34 财务实战-哈佛分析框架的应用</h3><ul><li>【chiechie】作业1-使用哈佛分析框架分析下腾讯</li><li>【chiechie】作业2-使用哈佛分析框架分析下现在在做的项目</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;思考几个问题，选股的分析框架？看市盈率，看行业龙头股的baseline，跨版本的股票，看业务构成，找相应板块&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;第3章-花钱-投资与分配&quot;&gt;第3章 花钱-投资与分配&lt;/h2&gt;
&lt;h3 id=&quot;cha</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="行业研究" scheme="https://chiechie.github.io/tags/%E8%A1%8C%E4%B8%9A%E7%A0%94%E7%A9%B6/"/>
    
    <category term="平台" scheme="https://chiechie.github.io/tags/%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="平台治理" scheme="https://chiechie.github.io/tags/%E5%B9%B3%E5%8F%B0%E6%B2%BB%E7%90%86/"/>
    
    <category term="商业模式" scheme="https://chiechie.github.io/tags/%E5%95%86%E4%B8%9A%E6%A8%A1%E5%BC%8F/"/>
    
    <category term="创业" scheme="https://chiechie.github.io/tags/%E5%88%9B%E4%B8%9A/"/>
    
  </entry>
  
  <entry>
    <title>时序预测最佳实践</title>
    <link href="https://chiechie.github.io/2021/06/05/AI/timeseries/quantml-practice/"/>
    <id>https://chiechie.github.io/2021/06/05/AI/timeseries/quantml-practice/</id>
    <published>2021-06-04T16:06:21.000Z</published>
    <updated>2021-06-11T01:47:17.437Z</updated>
    
    <content type="html"><![CDATA[<h1 id="建模pipeline">建模pipeline</h1><ol type="1"><li>搜集原始数据: 过去十年的成交数据</li><li>数据筛选: 选择交易日，固定时间段（９:30~15:30)的数据</li><li>对选好的数据进行采样，并不能保证每天都有整数个点</li><li>切分训练集 &amp; 验证集</li><li>模型训练<ul><li>归一化训练集，&lt;x， target&gt;</li><li>训练</li></ul></li><li>模型评估<ul><li>归一化验证集</li><li>预测&amp;画图：</li></ul></li></ol><p>实践过程中遇到的一些问题，需要逐一解决，下面记录其中一些</p><h1 id="问题集合">问题集合</h1><h2 id="问题1.-验证集的mse比训练集低但相关系数训练集远远大于调参集这是bug">问题1. 验证集的mse比训练集低，但相关系数训练集远远大于调参集，这是bug？</h2><p>没有bug，mse和correlation评估的侧重点不一样。</p><p>mse小，但是correlation也小的例子，如下图：</p><p><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2FNUSWvXNmWb.png?alt=media&amp;token=8c03a9f3-60e1-424d-879e-3371c1516623" /></p><p>几个距离：</p><ul><li>欧式距离（mse）量化的 是两个实体（或者两个群体）之间的绝对物理距离</li><li>余弦距离（correlation）量化的是 两个实体（或者两个群体）相对原点的角度的距离</li><li>pearson衡量的是 两个变量 之间的 线性相关性，具体做法是使用一个直线去拟合多组样本点&lt;变量1，变量2&gt; ，直线斜率就是相关性大小。</li></ul><h2 id="问题3怎么解决分布漂移的问题">问题3：怎么解决分布漂移的问题？</h2><p>分布漂移在时序预测中尤其常见，使用滑动窗口的均值来 做中心化</p><h2 id="问题4还有哪些措能提升实验效果">问题4：还有哪些措能提升实验效果？</h2><p>取效果好和效果差的两组实验进行对比，观察到1个现象：使用短期趋势中心化后，在使用长期趋势归一化，能使效果变好，背后的理论依据是什么？</p><p>分析下：因为用到了更长的历史数据作为参考,本身模型是记不住那么长的历史信息的。（输入才半个小时）</p><p><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2Fg6FAdLzkOj.png?alt=media&amp;token=362ed41e-1773-4ff5-ac41-a3095f75bb86" /></p><p>参考: <a href="https://github.com/Arturus/kaggle-web-traffic/blob/master/how_it_works.md">doc</a></p><h2 id="问题5-过拟合的原因">问题5： 过拟合的原因</h2><p>训练集 的比例远大于 验证集 和测试集</p><h2 id="问题6-是不是预测的准就能挣钱了">问题6： 是不是预测的准就能挣钱了？</h2><p>不是，回测的时候要考虑滑点，交易费用，爆仓风险</p><h2 id="问题7同样一个预测模型lstm商品期货准确率比股指差这么多">问题7：同样一个预测模型（LSTM），商品期货准确率比股指差这么多？</h2><ul><li>因为1min的股指期货数据平滑，噪声少，而1min的商品期货毛刺非常多</li><li>将1min的商品期货聚合成5min之后，再使用过去1h的数据预测未来1h的数据，准确率非常之高</li></ul><p>数据颗粒度太细时 噪声很大， 直接丢给模型，也可能造成模型学不好。（这个已经在quantML实践上面得到了证实）</p><h2 id="问题8直接用回归模型预测价格可能有负数怎么处理">问题8：直接用回归模型预测价格，可能有负数怎么处理</h2><p>预测增长率</p><h2 id="问题9除了直接回归还有哪些方法">问题9：除了直接回归，还有哪些方法？</h2><p>转化为分类问题，换预测涨跌幅</p><h1 id="其他经验">其他经验</h1><ol type="1"><li><p>不同品种的训练数据，分组训练 比 汇总训练 效果好。</p><blockquote><p>一定要汇总训练的话，要加入每个品种的静态特征，不然会学到混乱的模式。</p></blockquote></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;建模pipeline&quot;&gt;建模pipeline&lt;/h1&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;搜集原始数据: 过去十年的成交数据&lt;/li&gt;
&lt;li&gt;数据筛选: 选择交易日，固定时间段（９:30~15:30)的数据&lt;/li&gt;
&lt;li&gt;对选好的数据进行采样，并不能保证每</summary>
      
    
    
    
    <category term="实践" scheme="https://chiechie.github.io/categories/%E5%AE%9E%E8%B7%B5/"/>
    
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="量化交易" scheme="https://chiechie.github.io/tags/%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93/"/>
    
    <category term="最佳实践" scheme="https://chiechie.github.io/tags/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    
    <category term="时序预测" scheme="https://chiechie.github.io/tags/%E6%97%B6%E5%BA%8F%E9%A2%84%E6%B5%8B/"/>
    
  </entry>
  
</feed>
