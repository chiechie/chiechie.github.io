---
title:  深度学习8 gpt
author: chiechie
mathjax: true
date: 2021-07-08 14:48:13
tags: 
- NLP
- 神经网络
- 模型可视化
- Transformer
- Bert
- attention
categories:
- 深度学习
---


## 总结
- GPT的全称是generative pre-training，通用预训练模型，
- elmo有94m个参数，bert有340m个参数，GPT有1542m个参数
- GPT是transformer的decoder network
- GPT的学习任务是，给定一些word，预测接下来的word是什么？
- GPT神奇的地方：没有训练数据的情况下，可以做阅读理解（表现很好），生成摘要（一般般），翻译（一般般）。做到了zero-shot learning
- 




## 参考
1. [GPT](https://www.youtube.com/watch?v=UYPa347-DdE)