---
title: 《the book of why》读书笔记-1
author: chiechie
mathjax: true
date: 2021-03-06 08:33:38
tags: 
- 因果分析
- 人工智能
- 哲学
- 贝叶斯
- 因果推断
categories: 
- AI
---

> 《the book of why》是一本关于因果关系的科普书，作者是judea pearl，该书于2019年出版。
>
> 最近工作正好涉及根因分析，加上我对因果推断领域比较感兴趣，所以将本书作为入门读物。打算以此为基础，再看技术paper。
>
> 这个是第一篇-引言-思维胜于数据
> 
> 重新review了一下读书笔记，感觉还是没有消化里面的内容


## 因果推断流程图


![图一--因果推断引擎](inference_engine.png)

- 【1号框-知识】「知识」（knowledge）指「推断主体」（reasoning agent）过去的经历（experience），包括过去的观察（observation），过去的行为（actions），教育和文化（hearsay）等跟目标问题有关的内容。「知识」的虚线框表示，它仍存在于推断主体（reasoning agent）的心智中，是隐式的，而不是显示地在表达在模型中。
- 【2号框-假设】科学研究经常需要简化「假设」（assumptions），即值得显式表达的「陈述」（statements）。
   虽然大部分研究人员的知识都隐式地存在于他脑中，只有「假设」得见天日，并且「封装」（encapsulated）在模型之中。「假设」可以从模型中读到，这让一些逻辑学家得出结论：模型不过是一堆「假设」而已。计算机专家对此观点持有异议，他们提出需注意「假设」呈现的方式，因为人的不同解读而产生很大区别。
- 【3号框-因果模型】「因果模型」（causal model）有多种表达语言：「因果图」（causal graph），「结构方程」（structural equation），「逻辑陈述」等。以「因果图」为例，如果X是Y的因（cause），即Y听从X，就会在因果图中，画一个X到Y的箭头。
- 【4号框-可测试蕴含】从「因果图」中推导出来的一些统计性质，可以使用数据去证伪
- 【5号框-查询】提交到推荐引擎的查询（queries），是一个科学的问题我们要回答的，他们可以用一个因果词汇来表达，例如，P（L | do(D)）是多少，eg我努力了的话成功的概率是多少？因果革命的一个主要的成就，就是让因果语言在科学上容易理解，在数据上精确严谨。
- 【6号框-被估量】「被估量」（estimand），是一个统计量，需要从数据中算出，可被写成概率公式，例如P（L｜ D，Z）* P（Z）。 
  > 跟传统统计学不一样，在当前因果模型中，有些问题是没有答案的，即使收集了再多数据也没用。这个时候要做的是，回去修正「因果模型」--加入新「知识」，或者简化「假设」（注意吃出存在犯错风险）

- 【7号框-数据】数据（data）是填充「被估量」的原料，需要认识到，数据本身不能表达因果关系。数据只能告诉我们P（L｜D），或者P（L｜D，Z）。而「被估量」将这些观测概率转为干预概率P(L|do(D))。

- 【8号框-统计估计量】 「统计估计量」（statistical estimation）是一个新鲜出炉的东西，然而，它仅仅是一个估计值，因为基于事实：我们能获取到的仅仅是无限总体的有限样本。幸运的是，统计学给了我们很多方法来应对这些不确定性--最大似然估计，propensity分数，置信区间，显著性检验。
   
- 【9号框-估计】「估计」（estimate）即为「查询」的答案。如果我们的「因果模型」是对的，并且我们的数据是充分的，我们可以得到「查询」的答案，例如 药物提升了糖尿病人的寿命30%+/-20%。
这样的回答，也会增加我们的科学的「知识」。如果这一答案与我们的生活常识不符，则说明我们需要对「因果模型」（3号框）做一些修正。
   
这个流程图看起来很复杂，我们在日常生活和工作中处理因果问题时使用直觉就可以，而不用按照这个流程来。
但是如果我们要教会一个机器人懂得因果推断，我们就必须审视自己的因果推断的流程，并且形成一门科学语言，先模拟自己，再教会机器。

## 深度学习 和 因果推断

1. 人工智能和大数据和因果模型：当今很多人工智能的研究者只依赖数据解决所有的认知难题。他们希望在因果问题出现时，数据能指引他们找到答案。换句话说，他们坚信数据是万能的，也可以称这类人--信仰「数据教」。这种想法通常是秘而不宣。
   
2. 作者对"数据万能"的趋势表示质疑，因为，对因果关系的知识，数据没有发言权。举个例子，关于「行动」或「干预结果」的信息，根本无法从原始数据中获取，这些信息只能从对照实验中收集。

3. 反事实问题比如"如果当时我采取了相反的行动会发生什么"，是人工智能最具挑战性的问题。想要回答反事实问题，因果模型的作用很重要。

4. 因果模型相对深度学习的特有优势--适应性。
因果模型研究的是更本质，更稳固，适用范围更广的知识，相对来说深度学习是一个肤浅的学习者，和拙劣的模仿者:
   
    - 假设我们面临一个问题，新冠疫苗的药效的评估者，通过观察印度的情况--病患注射疫苗后的存活时间，得到了关于疫苗有效性的结论；接下来想评估疫苗在中国的有效性，但是中国和印度的卫生情况，饮食习惯，工作习惯，人均寿命寿命都不一样。
    - 「深度学习流派」的做法是：重新获取中国的病患数据，重新训练模型和做预测，本质上深度学习就是将函数和数据拟合。
    - 「因果推断流派」的做法是：该研究者首先掌握疫苗的作用机制（regime），如果中国疫苗作用机制跟印度一致，那么在印度得到的估计参数仍然有效，可生成一个新的中国总体的预测函数。

## 因果之梯

1.「反事实」和「干预」（intervention）区分的关键在于「事后来看」（hindsight）。即反事实强调在对结果已知观测的基础上再对反事实的问题进行解答：“假如当时发生的与实际情况不同，结果会怎样？”，这就要求一种对虚构世界的推理能力。另一方面，Intervention关注的更多是群体的总效应或者平均因果效应。而反事实更关注特定事件或个体层面的因果关系。举个栗子，比如Intervention解决的是“吸烟是否导致肺癌”，而counterfactual研究的是“我的外公30年来每天一支烟，假如他不曾吸烟的话，他会活多久”，这两者之间是具有很大差别的。

### 概率与因果关系

1. 20世纪中期的哲学家，使用"概率提高"的概念，来定义因果关系。
   > 如果事件X提高了Y的概率，那么就说X导致了Y
   > 
   > 决策树生成算法，挑选节点的时候，有异曲同工之妙啊。
   
   ![决策树中的概率提高思想](qiantan-ai/img.png)
   
2. 

## 参考

1. [the book of why-微信读书-引言](http://bayes.cs.ucla.edu/WHY/why-intro.pdf)
2. [知乎-反事实和干预](https://zhuanlan.zhihu.com/p/269625734)