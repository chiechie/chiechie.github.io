title: 模型推断的框架
author: chiechie
mathjax: true
date: 2021-04-18 08:53:17
tags:
- 深度学习框架
- 人工智能
- 模型部署
- AI工程
categories:
- 阅读
---

> 解答了一直以来，关于模型部署的疑惑

## 关于模型部署

- 1 为什么说模型部署难？
    - 因为部署的环境不一样，所以需要许多定制化的工作
- 2. tensorflow和pytorch这两个框架不能直接用于推理吗？
    - 可以，但是性能不佳。推理阶段相对训练阶段对模型服务的性能要求更高，比如模型稳定性，响应延迟等，。
    - tensorflow和pytorch本身是训练框架，拿来兼做推理框架其实不可以。
    - 但是在推理阶段，如果业务要求模型服务 高可用，训练框架就显得过于臃肿了而不合时宜了，需要更轻量的框架，如pytorch，tensorRT等。
    ![img.png](../../deeplearning/dl-framework/img.png)
- 3. DL框架产业现状？
    - 训练框架是标准品
    - 推理框架是定制品：这里提到了一点就是使用场景没有**网络效应**，我理解就是规模效应，客观环境决定了，“推理框架”相对于“训练框架” 而言，不是一个好摘的果子
        - 客观环境（部署依赖整个生产链路的环境，包括硬件厂商，应用服务）导致了没有统一的条件



## 深度学习框架2大方向

1. 深度学习框架有两个派别：一派是从分布式系统的人来做的，另外一派是从做算法的人来做的。tensorflow属于系统派，而pytorch属于算法派。
2. 不同的人的背景不同，所以做这个事情的角度也会不同，要解决的问题也不同，从而产生不同门派。
3. 系统派聚焦于解决大数据大模型的计算问题，扩展到任意大的深度模型的框架，所以往往会把系统设计的更具可扩展性，避免重构带来的巨大成本。
   1. 系统框架的优点--适合很多领域的建模流程：系统派系统希望构建一个系统，能够把视觉，语音，语言等多种模型能够一同训练，这个就是tensorflow这样系统构造的时候的原始想法，把整个计算构成一个Tensor的Flow图。
   2. 系统框架的优点--支持大规模模型训练：因为分布式本身就很复杂，需要处理各种节点交互的数据，以及执行中的各种依赖关系。这些事情由人来写代码，太繁琐且容易出错，所以自然地，就会想到让系统来负责这种依赖关系。这也就是为什么希望整个分布式执行的计划是一个静态图，然后系统再根据用户指定的或者系统智能的决定的placement进行分图，并在这些分图中添加合适的Send-Recv的Op从而构成一个分布式的执行计划。
   3. 系统派框架的缺陷-控制流代码也要op化：同但是这样的设计理念也会带来一些困恼，在模型训练时候有些类似控制图的部分，必须要把这些控制流图的代码也op化，然后把这些op也整体串联在Tensor的Flow执行图中，这种方式会使得一些习惯单机开发的研究人员觉得比较晦涩。
   4. 系统派框架的缺陷-不好debug：同时也是因为分布式的原因，做系统的很自然会把模型的开发过程分成构图和执行两个阶段。构图的时候只是生成一个逻辑执行计划，然后通过显式方式的提交（或者execute）过程进行执行。这种方式让研究人员觉得不能一边写代码一边就能够马上看到代码片段的结果，所以这也造成很多人诟病TensorFlow的模式不太容易debug自己的模型程序，其实这也是因为分布式带来负担。但是也是因为TensorFlow是静态图的方式，其可以做到训推一体，在训练出来的模型能够导出模型图，并且在这个图上进行系统化的推理优化从而能够非常方便部署到线上。这个系统性化的方法带来另外一个优势。
4. 算法派要解决的是一个小得多的任务：基于数据并行的可提供自动梯度的框架。
   1. 因为感知类模型（图像，语音，语言类）训练，一般都是同步训练，然后“分布式训练”也不是那么复杂（tensorflow的设想是分布式执行图是异构的，即每个分布式节点的执行逻辑可以不同），然后 数据并行，这样我们就可以利用MPI的AllReduce的通讯源语来进行梯度的汇集计算。
   2. 算法同学需要是一种丰富的，可扩展的，在GPU上能够很好运行的，能够很好进行自动梯度的算子库。因为面向是数据并行的场景，这样话在神经网络部分其实都是单机程序，从而可以利用任何python的语法糖去构建任何的动态的训练控制逻辑（大家也把这种称作动态图），对于算法研究人员来讲，这种方式写代码比较随性也方便debug，所以在研究界pytorch得到大量的关注和使用。

5. TensorFlow从设计之初就在考虑可以超大模型分布式训练的场景，但是没有预想到硬件的发展也非常迅速，显存越来越大以及训练技术的发展，还有非常精细化优化显存的工作，比如DeepSpeed等把optimizer所需要的显存sharding化掉，使得除了超大规模稀疏模型训练外，感知类的SOTA模型一直可以利用数据并行的方式来进行训练。从而使得TensorFlow这种设计理念看上去有overdesign的嫌疑。
6. 随着transformer的出现，终于可以把多种数据（视觉的，文字的）合在一起训练多模态的模型，从而产生了大规模模训练的需求。所以支持模型并行的深度学习框架再度火热，比如OneFlow，MindSpore，PaddlePaddle，Mesh Tensorflow，GShard，以及阿里的Whale框架。
7. 从设计理念来看，模型并行是TensorFlow的设计初衷，只是当时模型并行的需求不够，没有必要提供比较好高层自动分布式的抽象，写模型的人可以自己精细化去构造每个计算节点的子图，整体上TensorFlow的框架只是负责把这些子图能够自动通过Send-Recv进行连接，并且在Runtime能够合法的进行计算。
8. 现在算法迭代需求增多，导致需要一种高层次的自动分布式框架，从而使得算法同学能够快速简单通过构造一个逻辑图的方式去构造神经网络，而由系统层来帮助他来进行复杂模型并行。TensorFlow的设计理念正好就是为这个考虑的，用户利用静态图以逻辑性去描述一个网络训练，然后在执行时，进行系统化的分图和分布式训练。
9. 系统派的框架和算法派的框架也在进行一定的融合：
   1. TensorFlow提出了Eager模式，通过TF.function在eager模式下可能单步执行计算，得到Tensor来提高可调式性；
   2. Pytorch通过Trace或者Parse的方式转化为TorchScript的图描述，从而能够更好支持训练到推理的工程化。但是这种动静结合其实只是在一定层次的，比如如果考虑分布式，Trace的方式去得到TorchScript就不足够。需要进一步去限制构图能够使用的API，这也是像NV的megatron以及微软DeepSpeed在Pytorch上去支持分布式所带来的一些约束。

## 参考

1. file:///Users/stellazhao/Desktop/深度学习框架-2020-0630-Qlearning分享-Turbo-PPT.pdf
2. [关于深度学习框架的一些自己见解-zhihu](https://zhuanlan.zhihu.com/p/375634204)
3. [GPT-3难以复现，为什么说PyTorch走上了一条“大弯路”？](https://mp.weixin.qq.com/s/IN281OPUEOI12ge3hOvvTw)
