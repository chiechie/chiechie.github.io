<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"chiechie.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="a reader &amp; thinker">
<meta property="og:type" content="website">
<meta property="og:title" content="Chiechie&#39;s Mini World">
<meta property="og:url" content="https://chiechie.github.io/index.html">
<meta property="og:site_name" content="Chiechie&#39;s Mini World">
<meta property="og:description" content="a reader &amp; thinker">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Chiechie">
<meta property="article:tag" content="博客, AI, 互联网">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://chiechie.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Chiechie's Mini World</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Chiechie's Mini World" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Chiechie's Mini World</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Set your course by the stars, not by the lights of passing ships. —— Omar Bradley</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chiechie.github.io/2021/07/08/deeplearning/bert/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chiechie">
      <meta itemprop="description" content="a reader & thinker">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chiechie's Mini World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/08/deeplearning/bert/" class="post-title-link" itemprop="url">深度学习7 Bert</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-07-08 11:50:30 / 修改时间：16:08:00" itemprop="dateCreated datePublished" datetime="2021-07-08T11:50:30+08:00">2021-07-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>为什么有了word2vec还不够？还需要bert干嘛？因为一词多义，同样的词在不同的上下文中表达的意思不一样，而word2vec的表示是静态的。 所以我们需要一个能对上下文编码的动态的embedding方法，bert就应运而生了。</p>
<h1 id="总结">总结</h1>
<ul>
<li>Bert也是是一个对词语生成词语向量的方法。</li>
<li>Bert可以认为是一个预训练Transformer的encoder部分</li>
<li>Bert的全称是Bidirectional Encoder Representations from Transformers，双向encoder表示</li>
<li>Bert的目的是预训练transformer模型的encoder网络，</li>
<li>Bert的学习目标是怎么设定的呢？bert用以下两个任务来预训练transformer中的encoder网络
<ul>
<li>任务1-预测遮挡词（Predict Masked Words）： 随机遮挡上下文，让encoder根据上下文来预测被遮挡的单词，大概随机遮挡挡15%的单词</li>
<li>任务2-预测下一个句子（Predict the Next Sentence）： 把两个句子放在一起，让encoder判断两句话是不是原文里面相邻的两句话，正样本摘自原文，负样本是随机选择50%。</li>
</ul></li>
<li>Bert学习的时候，把上面两个任务结合起来</li>
<li>假如有两个词被遮挡，就要训练三个任务，2个预测遮挡词任务，1个预测是否邻近的任务。前面两个是一个multi-class分类；后面一个是一个二分类。前两个任务的损失函数是cross entropy，第三个任务的损失函数是binary-entropy。</li>
<li>最终的目标函数，是上面三个损失函数的求和，把最终的目标函数关于模型参数求梯度，然后使用梯度下降来求参数。</li>
<li>Bert的优点：不需要人工标注数据，训练数据可以从wiki/网页等，长度为2.5billion单词</li>
<li>Bert可以利用海量数据训练一个超级大的模型</li>
<li>Bert想法简单有效，计算大家大，bert有两个版本
<ul>
<li>base： 1.1yi参数, 16个tpu训练4days，不算调参数，该参数是公开的</li>
<li>large：2.35yi参数，64个tpu训练4days，不算调参数，该参数是公开的</li>
</ul></li>
<li>想用transformer直接下载徐训练好的bert模型就好，拿到参数就可以对英文编码了</li>
<li>RoBERTa建议只用masking，而且是动态masking,</li>
</ul>
<h1 id="附录">附录</h1>
<h2 id="bert模型原理">bert模型原理</h2>
<p>[bert模型可视化] (https://images.prismic.io/peltarionv2/e69c6ec6-50d9-43e9-96f0-a09bb338199f_BERT_model.png?auto=compress%2Cformat&amp;rect=0%2C0%2C2668%2C3126&amp;w=1980&amp;h=2320)</p>
<h3 id="任务一--预测遮挡词">任务一--预测遮挡词</h3>
<p>任务可以描述为： 输入： “The _____ sat on the mat” 输出： What is the masked word?</p>
<figure>
<img src="img.png" alt="img.png" /><figcaption aria-hidden="true">img.png</figcaption>
</figure>
<p>如何学习？ - e：one-hot vector of the masked word “cat”. - 𝐩: output probability distribution at the masked position. - 损失函数Loss = CrossEntropy(𝐞, 𝐩 ) - • Performing one gradient descent to update the model parameters.</p>
<h3 id="任务二---predict-the-next-sentence">任务二-- Predict the Next Sentence</h3>
<p>任务可以描述为： • Given the sentence: “calculus is a branch of math”. • Is this the next sentence? “it was developed by newton and leibniz” 可以表述为一个而分类问题 • 输入: [CLS] “calculus is a branch of math” [SEP] “it was developed by newton and leibniz” • Target: true</p>
<p>• [CLS] is a token for classification. • [SEP] is for separating sentences.</p>
<p>学习过程 <img src="img_1.png" alt="img_1.png" /></p>
<h3 id="结合两个任务">结合两个任务</h3>
<p>• Input: “[CLS] calculus is a [MASK] of math [SEP] it [MASK] developed by newton and leibniz”.</p>
<p>• Targets: true, “branch”, “was”.</p>
<h2 id="bert实践todo">Bert实践【todo】</h2>
<p>如何使用BERT做迁移学习（Transfer Learning）？</p>
<ul>
<li>demo数据：https://www.kaggle.com/c/fake-news-pair-classification-challenge/data</li>
<li>预训练的中文bert模型：hugging face</li>
</ul>
<h1 id="参考">参考</h1>
<ol type="1">
<li>Bahdanau, Cho, &amp; Bengio. Neural machine translation by jointly learning to align and translate. In ICLR, 2015.</li>
<li>Cheng, Dong, &amp; Lapata. Long Short-Term Memory-Networks for Machine Reading. In EMNLP, 2016.</li>
<li>Vaswani et al. Attention Is All You Need. In NIPS, 2017.</li>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=UlC6AjQWao8&amp;t=26s">BERT (预训练Transformer模型)</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1907.11692v1.pdf">RoBERTa</a></li>
<li>Devlin, Chang, Lee, and Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In ACL, 2019.</li>
<li>https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chiechie.github.io/2021/07/07/AFML/AFML3-md/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chiechie">
      <meta itemprop="description" content="a reader & thinker">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chiechie's Mini World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/07/AFML/AFML3-md/" class="post-title-link" itemprop="url">《Advances in Financial Machine Learning》读书笔记3 回测</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-07 11:08:30" itemprop="dateCreated datePublished" datetime="2021-07-07T11:08:30+08:00">2021-07-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-07-08 15:49:20" itemprop="dateModified" datetime="2021-07-08T15:49:20+08:00">2021-07-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AFML/" itemprop="url" rel="index"><span itemprop="name">AFML</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="chapter-10-押注大小">chapter 10 押注大小</h2>
<blockquote>
<p>即使股价预测很准，但是头寸配置的不恰当，还是有可能亏钱。</p>
</blockquote>
<ol type="1">
<li>假定三期股价为 [1, 0.5, 1.25]，仓位1: [0.5, 1, 0] &amp; 仓位2: [1, 0.5, 0]，则前者挣钱而后者亏钱。</li>
<li>我们偏好这样的下注策略：建仓时保留一些现金，如果交易信号加强（股价变为0.5），就追加投资。</li>
<li>交易信号越强，下注可以越大，因为交易信号很难变得更强了。所以预测的概率 与下注之间可以构建一种函数关系. <img src="img.png" alt="img.png" /></li>
<li>如果每次预测时，如果交易信号的微小改变就要调仓，那换手率就太高了，作者建议可以对预测结果做滑动平均，或者将下注量离散化（如下图） <img src="img_1.png" alt="img_1.png" /></li>
<li>当股票的市场价格<span class="math inline">\(p_t\)</span>和预测价格<span class="math inline">\(f_t\)</span>波动时，可用如下方法动态地确定下注量<span class="math inline">\(\hat{q}_{i, t}\)</span>： <span class="math display">\[\hat{q}_{i, t}=\operatorname{int}\left[\frac{x}{\sqrt{w+x^{2}}} \cdot Q\right]\]</span>, <span class="math inline">\(x=f_{i}-p_{t}\)</span>为预测价与当前价的差价， Q为最大持仓量。 &gt; label就是交易信号，表示买或者卖, 两个label 如果是基于相同时间段的收益率 计算出来的，就说是concurrent的.</li>
<li>基于预测概率确定BET SIZING</li>
<li>平均主动BETS</li>
<li>动态BET SIZES 和 限定价格</li>
</ol>
<h2 id="chapter-11-回测有风险">chapter 11 回测有风险</h2>
<p>回测是量化中最重要但也最容易被误用的工具，本章将介绍回测时容易犯的错误。</p>
<ol type="1">
<li>一个物理实验室可以通过控制变量来探究精确的因果关系，而回测不是实验，它并不能证明一个策略好，只能证明一个策略不好。</li>
<li>要做好回测极其困难，我们至少会面临这些问题:
<ul>
<li>幸存者偏差：只用现存的股票构建投资组合回测，殊不知过去多少公司倒闭退市了；</li>
<li>Look-ahead bias：回测时用到的数据在那一刻还没发布；</li>
<li>事后诸葛亮（各种事后分析都在编故事）；</li>
<li>手续费：要模拟手续费很难，唯一准确的方式是上实盘；</li>
<li>空头：实际交易中如何找借方、空头的成本、空头的额度都需要考虑；</li>
</ul></li>
<li>即使避免了以上问题，你的回测也可能是错的——在一个数据集上回测了成百上千次才得到的漂亮结果，大概率是假的。如第八章所述，特征重要性分析帮助我们理解 ML 发现的结果，它在回测之前进行，是一种“事前“归因。相反，回测并不能帮我们理解为什么一个策略会盈利。通过回测发现的有效“因子”如同上一期彩票的中奖号码，对下一轮抽奖无益。回测前做好数据结构化、标签、加权比回测本身更重要。</li>
<li>重复回测带来的过拟合可以认为是一种选择偏差，要避免这种偏差可能是量化中最根本的问题。</li>
<li>以下步骤可以帮我们减少这种偏差:
<ul>
<li>在多种金融资产上回测：由于金融资产的多样性，如果你发现错误 只存在于债券，那该策略很可能是错的；</li>
<li>用 bagging 减少过拟合；在完成本书章节1-10 的研究之前别回测；</li>
<li>记录得到当前结果之前回测了多少次，从而推算出过拟合的可能性；</li>
<li>假如回测结果没能得到有效的策略，从头开始。千万不要在回测结果的基础上继续研究。 &gt; Backtesting while researching is like drinking and driving. &gt; Do not research under the influence of a backtest.</li>
</ul></li>
<li>如果用标准CV回测来选择策略，一些回测路径会重复出现，导致极易过拟合。所以一些随机性非常有必要，例如基于probability of backtest overfitting (PBO) 的回测。</li>
</ol>
<h2 id="chapter-12-使用交叉验证做回测">chapter 12 使用交叉验证做回测</h2>
<p>本章将介绍三种回测方法，希望能得到更准确的回测结果。</p>
<ol type="1">
<li>回测用历史数据来检验策略的样本外表现，这些历史数据有两种用法：狭义上，模拟策略的历史表现（walk-forward / WF）；广义上，模拟策略在特定市场环境（历史上不一定发生过）中的表现。前一种方式更广为人知，但两种方式各有利弊，都应掌握。WF 模拟策略在历史市场行情中的表现，如十一章所述，要正确地进行 WF 回测极为困难，没用通用方法。</li>
<li>WF的优点：
<ol type="1">
<li>WF 有清晰的历史意义，与模拟盘的结果一致；</li>
<li>WF 的测试集在训练集之后，只要正确 purging 后就不存在信息泄露（见第七章）。</li>
</ol></li>
<li>WF的缺点： 只有一种情形得到测试（即沿历史路径回测），所以容易过拟合；WF 不足以代表未来的表现，因为回测结果可能受到特定数据的影响而产生偏差；WF 回测时数据利用率不高（“most of the information is used by only a small portion of the decisions”）</li>
<li>得到一个新策略时，投资者往往想知道这个策略在“非常时期”，如08年金融危机、15年股灾中表现如何。可以将我们希望测试的时期划为测试集，其他时期划为训练集，例如将 2008年作为测试集，2009至今作为训练集。训练集在测试集之后的划分从历史角度来看并不准确（not historically accurate），但通过 CV（cross-validation）回测的目的就是检验策略在不同市场行情（scenarios）下的表现，从而推断策略在未来的表现。</li>
</ol>
<blockquote>
<p>For each period of the backtest, we simulate the performance of a classifier that knew everything except for that period.</p>
</blockquote>
<ol start="5" type="1">
<li>CV的优点：1. 能检验不同市场行情；2. 每个决定用到的信息量相同；3. 能实现最长的样本外回测。（后两点不是特别理解 ）</li>
<li>CV的缺点：1. 和 WF 一样，只有一条回测路径（尽管不是历史路径）；2. 没有明确的历史意义；3. 由于测试集可能位于训练集之前，容易发生信息泄露。</li>
<li>combinatorial purged cross-validation (CPCV)克服了WF和CV的缺点。假定将全数据集分为 N 份，其中 k 份作为测试集，其余作为训练集，则共有<span class="math inline">\(C_N^k\)</span>种划分方案。所有回测路径数 （如下图所示） <img src="img_2.png" alt="img_2.png" /></li>
<li>Assignment of testing groups to each of the 5 paths按照划分依次在训练集上训练、测试集上测试，最后可以计算<span class="math inline">\(\varphi[N, k]\)</span>条路径分别的技术指标（如夏普率），从而更全面地考察模型表现。相比 WF、CV，CPCV 得到的结果（如夏普率）方差小，从而能减少过拟合和错误回测的可能。</li>
</ol>
<h2 id="chapter-13-在合成数据上做回测">chapter 13 在合成数据上做回测</h2>
<p>本章将探究如何合成数据并进行回测。</p>
<ol type="1">
<li>使用历史数据生成一个合成数据：先从从真实数据估计得到的分布，然后从分布中采样得到合成数据。</li>
<li>使用合成数据去做回测的好处是，可以测试很多次，在unseen的情况下，因此可以减少得到一个过拟合策略的概率。</li>
<li>利用合成数据回测能减少过拟合，但合成金融数据是一个很大的课题，我们先考察一下交易规则（trading rules）。交易策略假定市场不是有效的，它们用基本面 / 技术面分析试图找到套利机会。交易策略千变万化，但交易规则大同小异：比如策略的信号强于阈值则买入，达到盈利或止损点则卖出，这里的阈值、盈利止损点就是交易规则。如果用合成数据回测来确定交易规则，则过拟合的风险将大大减小。</li>
<li>用离散OU过程（discrete O-U process）对资产价格建模，给定资产i当前价格和未来预测价格，其在 t 次交易后的盈亏<span class="math inline">\(\pi_{i,t}\)</span>服从正态分布。可以此为依据模拟价格走势进行实验，得到最佳交易规则，而无需用真实历史数据回测。</li>
<li>作者在原文中给出了详细步骤以及图文分析，这里试举一例：下图是采取不同盈利、止损点进行模拟数据回测得到的夏普率热力图。对于中性市场（上图），最好的策略是设定较宽的止损空间和较窄的盈利点；对于走高市场（下图），最好的策略是采取较宽的盈利点，而止损点的设定可以比较宽泛。</li>
<li>总而言之，通过探究引导价格波动的随机过程，而不是在真实历史数据上回测，我们得到的最佳交易规则不会在特定数据上过拟合。尽管这样得到的交易规则可能不是最优的，但也远好于过拟合的结果。本章仅以 OU 过程为例，也可以尝试其它建模方式。</li>
</ol>
<h2 id="chapter-14-回测统计">chapter 14 回测统计</h2>
<ol type="1">
<li>回测的三种范式：
<ul>
<li>历史模拟，向前游走</li>
<li>情景模拟：交叉验证</li>
<li>在模拟数据上做simulation</li>
</ul></li>
<li>回测统计量（Backtest statistics）应该帮助揭露策略的弊端（如可能的风险）、帮助投资者比较不同策略。</li>
<li>一般统计量（general characteristics）能告诉我们回测的大致特性：时间范围（回测起讫时间）、资产规模（Average AUM） ，策略的资金容量（Capacity）、杠杆率（Leverage）、平均持仓时间（Average holding period）、换手率（Annualized turnover），Maximum dollar position size/Ratio of longs/Frequency of bets</li>
<li>衡量策略表现（performance）的统计量包括：盈亏（PnL, Profit and Loss）、多头盈亏（PnL from long positions）、年化回报率（Annualized rate of return）、命中率（hit ratio）、命中回报率（Average return from hits）、失误回报率（Average return from misses）……</li>
<li>策略的回报率往往在一段时间内连续为正 / 负，称之为“周期”（Runs）。周期的存在增加了策略回撤的风险，所以需要一些统计量来衡量，包括：Returns Concentration（衡量回报的集中程度）、drawdown（回撤）、time under water。</li>
<li>某些策略错误地估计交易费用导致失败，这些需要考虑的统计量包括：Broker fees per turnover、Average slippage per turnover……</li>
<li>一些考虑到风险的统计量包括：夏普比率（Sharpe Ratio/ SR）、PSR（Probabilistic SR）、DSR（Deflated SR）、信息率（Information ratio）…… &gt; 夏普值，衡量的是一项投资在对其调整风险后，相对于无风险资产的表现。它的定义是投资收益与无风险收益之差的期望值，再除以投资标准差（即其波动性）。它代表投资者额外承受的每一单位风险所获得的额外收益。</li>
</ol>
<blockquote>
<p>Every backtest result must be reported in conjunction with all the trials involved in its production. Absent that information, it is impossible to assess the backtest’s “false discovery“ probability. —— MARCOS’ THIRD LAW OF BACKTESTING</p>
</blockquote>
<ol start="8" type="1">
<li>基金经理往往希望对模型的收益进行归因（performance attribution），可以参考多因子模型（Barra’s multi-factor method）。</li>
</ol>
<h2 id="chapter-15-了解策略风险">chapter 15 了解策略风险</h2>
<p>本章的目的是帮助你检验策略风险。</p>
<ol type="1">
<li>几乎所有策略都有盈利点和止损点，所以我们可以对策略的收益建模，检验策略对一些参数的敏感程度。</li>
<li>假定一个策略每年进行 n次 IID 决策，每一次有p的概率盈利<span class="math inline">\(\pi\)</span>，1-p的概率盈利<span class="math inline">\(-\pi\)</span>，则该策略的年化夏普比率 。（盈亏额不对称的情形可做类似讨论）</li>
<li>如果交易频率不高（ 不大），则需要较大的 才能达到高夏普比率。但即使 略大于 0.5，只要 足够大，夏普比率也可以很大，这是高频交易的思路。另一方面， 很大时， 的小幅波动会带来 的较大改变，很可能 降低 1% 就会抹去所有盈利——我们称之为策略风险（Strategy risk）。</li>
<li>策略风险不同于资产组合风险（portfolio risk）：假定 为依照上面公式计算得到的盈亏平衡点，策略风险指 ；而资产组合风险是市场中存在的风险，由首席风险官监控。策略风险过大时，即使投资标的的风险不大，这个策略也有较大概率无法超过业绩标准。所以策略研发者需要想办法减小 ，比如调节 。</li>
</ol>
<h2 id="chapter-16-基于机器学习资产配置">chapter 16 基于机器学习资产配置</h2>
<p>本章提出了基于图模型的层次风险平价方法（Hierarchical Risk Parity / HRP），其在统计性能上优于传统的资产组合优化方法。</p>
<p>资产组合可谓金融中最历久弥新的问题了。60多年前，马科维茨提出了Critical Line Algorithm（CLA）用于不等式约束下的二次规划问题，尤其是资产组合优化问题。CLA 的缺点是鲁棒性不高，因为二次规划需要对资产间协方差矩阵取逆，当该矩阵条件数很大时会带来较大误差。</p>
<p>资产组合中相关资产（多重共线性）越多，资产间协方差矩阵的条件数越大，结果越不稳定，这便是 Markowitz’s curse。此外资产越多，用于估计协方差矩阵的数据也越多，这些历史久远的数据也会造成误差。</p>
<p>作者认为，二次规划试图构建全连接图（fully connected graph），其中每个节点可能替代其他节点。当有50支资产时，一个全连接图有1225条边，这种复杂结构造成二次规划结果的不稳定。很自然地，我们会希望减少不必要的边.</p>
<p>当我们决定投资摩根大通时，下一步我们更可能考虑增/减持高盛的股票而不是一家地产公司的股票，因为摩根和高盛同属金融企业。依照这种思路，我们可以利用 ML 中的聚类算法，根据资产的特性 / 资产间相关性将所有资产建构成树状图，如下图所示。这被称为层次风险平价方法（HRP）</p>
<p>实验中 HRP 构建的投资组合比 CLA 更分散，风险也更低，同时 HRP 的样本外夏普比率更高。考虑到 HRP 不需要计算逆矩阵，其适应性和鲁棒性也更强。</p>
<p>HRP 不仅可以用于在不同资产上配置资金，还可用于在不同策略上配置资金。</p>
<h2 id="参考">参考</h2>
<ol type="1">
<li>《Advances in Financial Machine Learning》</li>
<li>https://blog.csdn.net/weixin_38753422/article/details/100179559</li>
<li>https://zhuanlan.zhihu.com/p/29208399</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/98/">98</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Chiechie</p>
  <div class="site-description" itemprop="description">a reader & thinker</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">196</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">203</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/chiechie" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;chiechie" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:328499034@qq.com" title="E-Mail → mailto:328499034@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/chiechie" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;chiechie" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chiechie</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
