---
title: 从DeepAR谈论paper到工程落地
author: chiechie
mathjax: true
date: 2021-04-18 11:56:59
tags:
- DeepAR
- AIOps
- 知识分子
categories:
- AIOps
---

## DeepAR探索

以DeepAR为例,最开始把DeepAR当黑盒用的时候，发现效果很神奇，不调参，换不同数据进去效果都还挺好，周期性和趋势性都还能学到。

后面就觉得很奇怪，按照自己构建rnn的经验，调参就要反反复复好多次，最后效果还不一定好。使用gluon-TS的代码我没有调参的，并且默认的网络结构很简单 不太可能过拟合.

看了源代码之后，有一个很大的感受就是，**完成论文demo和完成一个业界可用方案，两者的工作量 ，可能是0到1再到100的距离。**

按照paper所说，整个网络结构非常之简单，1层rnn + 1层 dense层（输出分布参数），构成2层rnn，大概十几行代码。 但是，**真正大量的代码都在做预处理以及 模型训练的一些小trick。 这些小trick，对提升模型效果非常有帮助，但是paper里面是没有的，应该随是工程团队总结出的最佳实践**。

- best practice1: 把每个样本（历史依赖）的scale 取对数，放入样本。 （因为所有的lags项在归一化之后已经丢失了scale信息，为了避免这个信息的丢失，还是把log scale 放入特征，用于区别不同的曲线的模式）
- best practice2: 在rnn中，每一层rnn后都接了一个residual和一个dropout。（原文没有提到）
- best practice3: 为了学习到数据的周期性模式，除了一定要有的context_length，代码还会跳着取lag , 类似空洞卷积。这些周期性的lag项，是被硬编码在代码里面的，比如年/月/日的周期性。

（我甚至怀疑论文的作者都不知道，因为作者自己写了一个pytorch版本，没有见到相关的处理，并且训练时长是gluon-TS的100倍以上）


## 对于AIOps建设的启发
对于根因分析，日志关联 等大部分场景，业界没有可参考的工具。只能求助学术界，那么可参考的只有论文 以及kaggle比赛等， 这些方案只是demo类型，没有在工业界的数据和真实需求上验证过，那从这个demo到落地可用还有大量的优化工作要做，所以需要预留一段时间， 来验证和优化。
