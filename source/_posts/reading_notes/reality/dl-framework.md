title: 模型推断的框架
author: chiechie
mathjax: true
date: 2021-04-18 08:53:17
tags:
- 深度学习框架
- 人工智能
- 模型部署
- AI工程
categories:
- 阅读
---

> 解答了一直以来，关于模型部署的疑惑

## 关于模型部署

- 1 为什么说模型部署难？
    - 因为部署的环境不一样，所以需要许多定制化的工作
- 2. tensorflow和pytorch这两个框架不能直接用于推理吗？
    - 可以，但是性能不佳。推理阶段相对训练阶段对模型服务的性能要求更高，比如模型稳定性，响应延迟等，。
    - tensorflow和pytorch本身是训练框架，拿来兼做推理框架其实不可以。
    - 但是在推理阶段，如果业务要求模型服务 高可用，训练框架就显得过于臃肿了而不合时宜了，需要更轻量的框架，如pytorch，tensorRT等。
    ![img.png](../../deeplearning/dl-framework/img.png)
- 3. DL框架产业现状？
    - 训练框架是标准品
    - 推理框架是定制品：这里提到了一点就是使用场景没有**网络效应**，我理解就是规模效应，客观环境决定了，“推理框架”相对于“训练框架” 而言，不是一个好摘的果子
        - 客观环境（部署依赖整个生产链路的环境，包括硬件厂商，应用服务）导致了没有统一的条件



## 深度学习框架2大方向

1. 深度学习框架有两个派别：一派是从分布式系统的人来做的，另外一派是从做算法的人来做的。tensorflow属于系统派，而pytorch属于算法派。
2. 不同的人的背景不同，所以做这个事情的角度也会不同，要解决的问题也不同，从而产生不同门派。
3. 系统派聚焦于解决大数据大模型的计算问题，扩展到任意大的深度模型的框架，所以往往会把系统设计的更具可扩展性，避免重构带来的巨大成本。
   1. 系统框架的优点--适合很多领域的建模流程：系统派系统希望构建一个系统，能够把视觉，语音，语言等多种模型能够一同训练，这个就是tensorflow这样系统构造的时候的原始想法，把整个计算构成一个Tensor的Flow图。
   2. 系统框架的优点--支持大规模模型训练：因为分布式本身就很复杂，需要处理各种节点交互的数据，以及执行中的各种依赖关系。这些事情由人来写代码，太繁琐且容易出错，所以自然地，就会想到让系统来负责这种依赖关系。这也就是为什么希望整个分布式执行的计划是一个静态图，然后系统再根据用户指定的或者系统智能的决定的placement进行分图，并在这些分图中添加合适的Send-Recv的Op从而构成一个分布式的执行计划。
   3. 系统派框架的缺陷-控制流代码也要op化：同但是这样的设计理念也会带来一些困恼，在模型训练时候有些类似控制图的部分，必须要把这些控制流图的代码也op化，然后把这些op也整体串联在Tensor的Flow执行图中，这种方式会使得一些习惯单机开发的研究人员觉得比较晦涩。
   4. 系统派框架的缺陷-不好debug：同时也是因为分布式的原因，做系统的很自然会把模型的开发过程分成构图和执行两个阶段。构图的时候只是生成一个逻辑执行计划，然后通过显式方式的提交（或者execute）过程进行执行。这种方式让研究人员觉得不能一边写代码一边就能够马上看到代码片段的结果，所以这也造成很多人诟病TensorFlow的模式不太容易debug自己的模型程序，其实这也是因为分布式带来负担。但是也是因为TensorFlow是静态图的方式，其可以做到训推一体，在训练出来的模型能够导出模型图，并且在这个图上进行系统化的推理优化从而能够非常方便部署到线上。这个系统性化的方法带来另外一个优势。
4. 算法派要解决的是一个小得多的任务：基于数据并行的可提供自动梯度的框架。
   1. 因为特别是感知类模型（图像，语音，语言类）训练，因为这类训练一般都是同步训练，然后“分布式训练”也不像前者那样设想是任意异构的分布式执行图（即每个分布式节点的执行逻辑可以不同），因为是数据并行，这样我们就可以利用MPI的AllReduce的通讯源语来进行梯度的汇集计算。算法同学需要是一种丰富的可扩展的在GPU上能够很好运行的，并且能够很好进行自动梯度的算子库，并且因为面向是数据并行的场景，这样话在神经网络部分其实都是单机程序，从而可以利用任何python的语法糖去构建任何的动态的训练控制逻辑（大家也把这种称作动态图），对于算法研究人员来讲，这种方式写代码比较随性也方便debug，所以在研究界pytorch得到大量的关注和使用。

5. TensorFlow从设计之初就在考虑可以超大模型分布式训练的场景，但是没有预想到硬件的发展也非常迅速，显存越来越大以及训练技术的发展，还有非常精细化优化显存的工作，比如DeepSpeed等把optimizer所需要的显存sharding化掉，使得除了超大规模稀疏模型训练外，感知类的SOTA模型一直可以利用数据并行的方式来进行训练。从而使得TensorFlow这种设计理念看上去有overdesign的嫌疑。
6. 并且就算超大规模稀疏模型训练，因为TensorFlow整体化的设计理念，不把Parameter Server作为游离在Flow图之外，使得他在超大规模场景下的scalability上出现了问题，从而催生一堆自建PS+深度学习框架的（稀疏）模型训练框架。

## 参考

1. file:///Users/stellazhao/Desktop/深度学习框架-2020-0630-Qlearning分享-Turbo-PPT.pdf
2. [关于深度学习框架的一些自己见解-zhihu](https://zhuanlan.zhihu.com/p/375634204)
